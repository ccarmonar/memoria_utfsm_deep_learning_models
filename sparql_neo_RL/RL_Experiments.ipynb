{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fe9b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import json, ast, sys, csv, random\n",
    "import plotly.express as px\n",
    "import math\n",
    "import datetime\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Implement training process\n",
    "from model_trees_algebra import NeoRegression\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functions.tree_format import IterateBuildTree, InnerJoinsIntraBGPS, \\\n",
    "                                IterateBuildTreeBetweenBGPS, TreeFormat\n",
    "from functions.RL_functions import GetTriplesSubtree, \\\n",
    "                                        GetTreeSize, \\\n",
    "                                        GetAllJoins, \\\n",
    "                                        GetIter, \\\n",
    "                                        GetTotalBgp, \\\n",
    "                                        GetDataframe\n",
    "\n",
    "from functions.aux import MetricTotalAccuraccy\n",
    "\n",
    "\n",
    "class BaoTrainingException(Exception):\n",
    "    pass\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "URL = \"/media/data/ccarmona/memoria/dataset/rl_csvs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b11caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_rl = pd.read_csv(URL + \"ds_rl.csv\", engine='python', encoding='utf-8')\n",
    "n = 4\n",
    "#neo_df = pd.read_csv(URL + \"neo_df.csv\", engine='python', encoding='utf-8')\n",
    "neo_df_no_history = pd.read_csv(URL + \"neo_df_no_history\" + str(n) +\".csv\", engine='python', encoding='utf-8')\n",
    "neo_df_final = pd.read_csv(URL + \"neo_df_final\"+ str(n) +\".csv\", engine='python', encoding='utf-8')\n",
    "\n",
    "#ql_df = pd.read_csv(URL + \"ql_df.csv\", engine='python', encoding='utf-8')\n",
    "ql_df_no_history = pd.read_csv(URL + \"ql_df_no_history\"+ str(n) +\".csv\", engine='python', encoding='utf-8')\n",
    "ql_df_final = pd.read_csv(URL + \"ql_df_final\"+ str(n) +\".csv\", engine='python', encoding='utf-8')\n",
    "\n",
    "#sarsa_df = pd.read_csv(URL + \"sarsa_df.csv\", engine='python', encoding='utf-8')\n",
    "sarsa_df_no_history = pd.read_csv(URL + \"sarsa_df_no_history\"+ str(n) +\".csv\", engine='python', encoding='utf-8')\n",
    "sarsa_df_final = pd.read_csv(URL + \"sarsa_df_final\"+ str(n) +\".csv\", engine='python', encoding='utf-8')\n",
    "\n",
    "#exsarsa_df = pd.read_csv(URL + \"exsarsa_df.csv\", engine='python', encoding='utf-8')\n",
    "exsarsa_df_no_history = pd.read_csv(URL + \"exsarsa_df_no_history\"+ str(n) +\".csv\", engine='python', encoding='utf-8')\n",
    "exsarsa_df_final = pd.read_csv(URL + \"exsarsa_df_final\"+ str(n) +\".csv\", engine='python', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc97fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarsa_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exsarsa_df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb6bb9",
   "metadata": {},
   "source": [
    "### Latencia promedio de cada algoritmo + promedio real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06240e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "========\n",
    "Barchart\n",
    "========\n",
    "\n",
    "A bar plot with errorbars and height labels on individual bars\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "ind = np.arange(4)*0.4\n",
    "real_value = [np.mean(ql_df_final['real_new']) for i in range(4)]\n",
    "old_pred = [np.mean(ql_df_final['pred_old']) for i in range(4)]\n",
    "h = [\n",
    "    np.mean(neo_df_final['pred_new']),\n",
    "    np.mean(ql_df_final['pred_new']),\n",
    "    np.mean(sarsa_df_final['pred_new']),\n",
    "    np.mean(exsarsa_df_final['pred_new']),\n",
    "]\n",
    "c = ['lightgreen','lightblue','yellow','orange']\n",
    "names = ('Neo','Q-Learning','Sarsa','Expected Sarsa')\n",
    "\n",
    "width = 0.2      # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "rects = ax.bar(ind, h, width, color=c, edgecolor = 'black')\n",
    "line1 = ax.plot(ind, real_value);\n",
    "line2 = ax.plot(ind, old_pred);\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Latencia')\n",
    "ax.set_title('Promedio de Latencia por Algoritmo de RL')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 0.75*height,\n",
    "                str(round(float(height),3)),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "ax.text(ind[1]+0.05,real_value[0] + 0.55,'Promedio de latencia real')\n",
    "ax.text(ind[1]+0.05,old_pred[0] + 0.55,'Promedio de latencia red neuronal')\n",
    "ax.text(ind[3]+0.01,real_value[0] - 0.1,str(round(real_value[0],3)))\n",
    "ax.text(ind[3]+0.01,old_pred[0] - 0.1,str(round(old_pred[0],2)))\n",
    "autolabel(rects)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21512ce",
   "metadata": {},
   "source": [
    "### Latencia promedio por iteración de  cada consulta para cada algoritmo + promedio real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PromedioPorIteracionFormato(df, num_iter):\n",
    "    aux_dict = {}\n",
    "    values_pred = []\n",
    "    for i in range(num_iter):\n",
    "        aux_dict[str(i)] = {\"index\" : 0, \"preds\" : [], \"mean_preds\" : []}\n",
    "    for i in range(len(df)):\n",
    "        a = [df['index'][i],df['iteration'][i],df['pred_new'][i]]\n",
    "        aux_dict[str(a[1])][\"index\"] = a[0]\n",
    "        aux_dict[str(a[1])][\"preds\"].append(float(a[2]))\n",
    "    for k,v in aux_dict.items():\n",
    "        aux_dict[k][\"mean_preds\"] = np.mean(aux_dict[k][\"preds\"])\n",
    "        values_pred.append(np.mean(aux_dict[k][\"preds\"]))\n",
    "    index_list = [int(x) for x in list(aux_dict.keys())]\n",
    "    return index_list, values_pred\n",
    "def PromedioPorIteracion(df):\n",
    "    index_list, values_pred = PromedioPorIteracionFormato(df)\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    ax.plot(index_list, values_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ecc5c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_list_ql, values_pred_ql = PromedioPorIteracionFormato(ql_df_no_history,200)\n",
    "index_list_neo, values_pred_neo = PromedioPorIteracionFormato(neo_df_no_history,200)\n",
    "index_list_sarsa, values_pred_sarsa = PromedioPorIteracionFormato(sarsa_df_no_history,200)\n",
    "index_list_exsarsa, values_pred_exsarsa = PromedioPorIteracionFormato(exsarsa_df_no_history,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_value = np.ones(len(index_list_ql))*np.mean(ql_df_final['real_new'])\n",
    "old_predict = np.ones(len(index_list_ql))*np.mean(ql_df_final['pred_old'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ql_df_final['pred_old'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Some example data to display\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15,15))\n",
    "fig.suptitle('Promedio de latencia por iteración para cada algoritmo')\n",
    "c = ['green','blue','yellow','orange','grey','black']\n",
    "ax1.set_title('Neo')\n",
    "ax1.plot(index_list_neo, values_pred_neo, color=c[0])\n",
    "#ax1.plot(index_list_neo, real_value, color=c[5], linestyle='dashed')\n",
    "ax1.plot(index_list_neo, old_predict, color=c[4], linestyle='dashed')\n",
    "\n",
    "ax2.set_title('Q-Learning')\n",
    "ax2.plot(index_list_ql, values_pred_ql, color=c[1])\n",
    "#ax2.plot(index_list_ql, real_value, color=c[5], linestyle='dashed')\n",
    "ax2.plot(index_list_ql, old_predict, color=c[4], linestyle='dashed')\n",
    "\n",
    "ax3.set_title('Sarsa')\n",
    "ax3.plot(index_list_sarsa, values_pred_sarsa, color=c[2])\n",
    "#ax3.plot(index_list_sarsa, real_value, color=c[5], linestyle='dashed')\n",
    "ax3.plot(index_list_sarsa, old_predict, color=c[4], linestyle='dashed')\n",
    "\n",
    "ax4.set_title('Expected Sarsa')\n",
    "ax4.plot(index_list_exsarsa, values_pred_exsarsa, color=c[3])\n",
    "#ax4.plot(index_list_exsarsa, real_value, color=c[5], linestyle='dashed')\n",
    "ax4.plot(index_list_exsarsa, old_predict, color=c[4], linestyle='dashed')\n",
    "#for ax in fig.get_axes():\n",
    "#ax.label_outer()\n",
    "\n",
    "# set labels\n",
    "plt.setp(ax1, xlabel='Iteraciones', ylabel='Latencia promedio')\n",
    "plt.setp(ax2, xlabel='Iteraciones', ylabel='Latencia promedio')\n",
    "plt.setp(ax3, xlabel='Iteraciones', ylabel='Latencia promedio')\n",
    "plt.setp(ax4, xlabel='Iteraciones', ylabel='Latencia promedio')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e81415",
   "metadata": {},
   "source": [
    "### Consultas mejoradas, consultas iguales, consultas empeoradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c66eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_points(x):\n",
    "    \"\"\"Add quality tags of predictions. Used to plot with plotly\"\"\"\n",
    "    difference = x['time'] - x['y_pred'][0]\n",
    "    abs_diff = np.abs(difference)\n",
    "    x['y_pred'] = x['y_pred'][0]\n",
    "    x['query2'] = x['query'].replace(\" . \", ' . <br>').replace(\" FILTER\", '<br> FILTER').replace(\" { \", ' { <br>').replace(\" } \", ' <br> }').replace(\" ; \", ' ; <br>') \n",
    "    p20 = x['time'] * 0.2\n",
    "    p40 = x['time'] * 0.4\n",
    "    if abs_diff < p20:\n",
    "        x['color'] = \"good prediction\"\n",
    "    elif abs_diff < p40:\n",
    "        x['color'] = \"aceptable prediction\"\n",
    "    else:\n",
    "        x['color'] = \"bad prediction\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98aa573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_best_worst_equal(x, tol):\n",
    "    difference = x['pred_old'] - x['pred_new']\n",
    "    if difference < -tol:\n",
    "        x['tag'] = \"peor\"\n",
    "    elif difference >= -tol and difference <= tol:\n",
    "        x['tag'] = \"igual\"\n",
    "    else:\n",
    "        x['tag'] = \"mejor\"\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64713d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_df_final = neo_df_final.apply(lambda x: tag_best_worst_equal(x,0), axis=1)\n",
    "ql_df_final = ql_df_final.apply(lambda x: tag_best_worst_equal(x,0), axis=1)\n",
    "sarsa_df_final = sarsa_df_final.apply(lambda x: tag_best_worst_equal(x,0), axis=1)\n",
    "exsarsa_df_final = exsarsa_df_final.apply(lambda x: tag_best_worst_equal(x,0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab23f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(ql_df_final)):\n",
    "#    print(neo_df_final['pred_old'][i],neo_df_final['pred_new'][i],neo_df_final['tag'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f640a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neo_igual = int(neo_df_final.groupby('tag').count()['index']['igual'])\n",
    "neo_mejor = int(neo_df_final.groupby('tag').count()['index']['mejor'])\n",
    "neo_peor = int(neo_df_final.groupby('tag').count()['index']['peor'])\n",
    "\n",
    "ql_igual = int(ql_df_final.groupby('tag').count()['index']['igual'])\n",
    "ql_mejor = int(ql_df_final.groupby('tag').count()['index']['mejor'])\n",
    "ql_peor = int(ql_df_final.groupby('tag').count()['index']['peor'])\n",
    "\n",
    "sarsa_igual = int(sarsa_df_final.groupby('tag').count()['index']['igual'])\n",
    "sarsa_mejor = int(sarsa_df_final.groupby('tag').count()['index']['mejor'])\n",
    "sarsa_peor = int(sarsa_df_final.groupby('tag').count()['index']['peor'])\n",
    "\n",
    "exsarsa_igual = int(exsarsa_df_final.groupby('tag').count()['index']['igual'])\n",
    "exsarsa_mejor = int(exsarsa_df_final.groupby('tag').count()['index']['mejor'])\n",
    "exsarsa_peor = int(exsarsa_df_final.groupby('tag').count()['index']['peor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f6167",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "# data to plot\n",
    "n_groups = 4\n",
    "igual = (neo_igual, ql_igual, sarsa_igual, exsarsa_igual)\n",
    "mejor = (neo_mejor, ql_mejor, sarsa_mejor, exsarsa_mejor)\n",
    "peor = (neo_peor, ql_peor, sarsa_peor, exsarsa_peor)\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.25\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, mejor, bar_width,\n",
    "alpha=opacity,\n",
    "color='lightgreen',\n",
    "label='Mejor',\n",
    "edgecolor = 'black')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, igual, bar_width,\n",
    "alpha=opacity,\n",
    "color='khaki',\n",
    "label='Igual',\n",
    "edgecolor = 'black')\n",
    "\n",
    "rects3 = plt.bar(index + 2*bar_width, peor, bar_width,\n",
    "alpha=opacity,\n",
    "color='darksalmon',\n",
    "label='Peor',\n",
    "edgecolor = 'black')\n",
    "\n",
    "plt.xlabel('Algorítmo')\n",
    "plt.ylabel('Número de Errores')\n",
    "plt.title('Número de errores por Algoritmo')\n",
    "plt.xticks(index + bar_width, ('Neo', 'Q-Learning', 'Sarsa', 'Expected Sarsa'))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "for i in index:\n",
    "    ax.text(index[i], \n",
    "             mejor[i]*0.75,\n",
    "             str(mejor[i]),\n",
    "             ha='center', va='bottom',\n",
    "            )\n",
    "    ax.text(index[i] + bar_width, \n",
    "             igual[i]*0.75,\n",
    "             str(igual[i]),\n",
    "             ha='center', va='bottom',\n",
    "            )\n",
    "    ax.text(index[i] + 2*bar_width, \n",
    "             peor[i]*0.75,\n",
    "             str(peor[i]),\n",
    "             ha='center', va='bottom',\n",
    "            )\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a6948",
   "metadata": {},
   "source": [
    "##### Por tipo rango de latencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_latency(df_final):\n",
    "    df = df_final.copy()\n",
    "    #df_0_10 = df[df['pred_new'] < 10]\n",
    "    #df_10_20 = df[(df['pred_new'] >= 10) & (df['pred_new'] < 20)]\n",
    "    #df_20_30 = df[(df['pred_new'] >= 20) & (df['pred_new'] < 30)]\n",
    "    #df_30_40 = df[(df['pred_new'] >= 30) & (df['pred_new'] < 40)]\n",
    "    #df_40_50 = df[(df['pred_new'] >= 40) & (df['pred_new'] < 50)]\n",
    "    #df_50_60 = df[(df['pred_new'] >= 50) & (df['pred_new'] < 60)]\n",
    "    #df_60 = df[df['pred_new'] >= 60]\n",
    "    df_0_20 = df[df['real_old'] < 20]\n",
    "    df_20_30 = df[(df['real_old'] >= 20) & (df['real_old'] < 30)]\n",
    "    df_30_40 = df[(df['real_old'] >= 30) & (df['real_old'] < 40)]\n",
    "    df_40_50 = df[(df['real_old'] >= 40) & (df['real_old'] < 50)]\n",
    "    df_50_60 = df[(df['real_old'] >= 50) & (df['real_old'] < 60)]\n",
    "    df_60 = df[df['real_old'] >= 60]\n",
    "    #return df_0_10, df_10_20 ,df_20_30, df_30_40, df_40_50, df_50_60, df_60\n",
    "    return df_0_20,df_20_30,df_30_40,df_40_50,df_50_60,df_60\n",
    "\n",
    "def count_igual_mejor_peor(df):\n",
    "    try:\n",
    "        igual = int(df.groupby('tag').count()['index']['igual'])\n",
    "    except:\n",
    "        igual = 0\n",
    "    try:\n",
    "        mejor = int(df.groupby('tag').count()['index']['mejor'])\n",
    "    except:\n",
    "        mejor = 0\n",
    "    try:\n",
    "        peor = int(df.groupby('tag').count()['index']['peor'])\n",
    "    except:\n",
    "        peor = 0\n",
    "    return igual,mejor,peor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eadd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errores_rango(df_final,nombre_algoritmo):\n",
    "    igual = []\n",
    "    mejor = []\n",
    "    peor = []\n",
    "    for df in split_by_latency(df_final):\n",
    "        i, m, p = count_igual_mejor_peor(df)\n",
    "        igual.append(i)\n",
    "        mejor.append(m)\n",
    "        peor.append(p)\n",
    "    plt.rcParams.update({'font.size': 13})\n",
    "    # data to plot\n",
    "    n_groups = len(igual)\n",
    "    #igual = (neo_igual, ql_igual, sarsa_igual, exsarsa_igual)\n",
    "    #mejor = (neo_mejor, ql_mejor, sarsa_mejor, exsarsa_mejor)\n",
    "    #peor = (neo_peor, ql_peor, sarsa_peor, exsarsa_peor)\n",
    "\n",
    "    # create plot\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.15\n",
    "    opacity = 0.8\n",
    "\n",
    "    rects1 = plt.bar(index, mejor, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='lightgreen',\n",
    "    label='Mejor',\n",
    "    edgecolor = 'black')\n",
    "\n",
    "    rects2 = plt.bar(index + bar_width, igual, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='khaki',\n",
    "    label='Igual',\n",
    "    edgecolor = 'black')\n",
    "\n",
    "    rects3 = plt.bar(index + 2*bar_width, peor, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='darksalmon',\n",
    "    label='Peor',\n",
    "    edgecolor = 'black')\n",
    "\n",
    "    plt.xlabel('Rango de latencia')\n",
    "    plt.ylabel('Número de Errores')\n",
    "    plt.title(f'Número de errores {nombre_algoritmo} por rangos de latencia')\n",
    "    plt.xticks(index + bar_width, ('[0-20)','[20-30)','[30-40)','[40-50)','[50-60)','60+'))\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    for i in index:\n",
    "        ax.text(index[i], \n",
    "                 mejor[i]*0.75,\n",
    "                 str(mejor[i]),\n",
    "                 ha='center', va='bottom',\n",
    "                )\n",
    "        ax.text(index[i] + bar_width, \n",
    "                 igual[i]*0.75,\n",
    "                 str(igual[i]),\n",
    "                 ha='center', va='bottom',\n",
    "                )\n",
    "        ax.text(index[i] + 2*bar_width, \n",
    "                 peor[i]*0.75,\n",
    "                 str(peor[i]),\n",
    "                 ha='center', va='bottom',\n",
    "                )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51028e41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_errores_rango(neo_df_final,'Neo')\n",
    "plot_errores_rango(ql_df_final,'Q-Learning')\n",
    "plot_errores_rango(sarsa_df_final,'Sarsa')\n",
    "plot_errores_rango(exsarsa_df_final,'Expected Sarsa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3aac4",
   "metadata": {},
   "source": [
    "### Latencia promedio de cada consulta diferenciado por numero de JOINs para cada algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_joins(df, val):\n",
    "    joins_1_p, joins_1_e =[],[]\n",
    "    joins_2_p, joins_2_e =[],[]\n",
    "    joins_3_p, joins_3_e =[],[]\n",
    "    joins_4_p, joins_4_e =[],[]\n",
    "    joins_5_p, joins_5_e =[],[]\n",
    "    joins_6_p, joins_6_e =[],[]\n",
    "    #<\n",
    "    #>\n",
    "    columns = 'tag'\n",
    "    for i in range(len(df)):\n",
    "        count_joins = df['new_tree'][i].count('JOIN') \n",
    "        if count_joins == 1:\n",
    "            joins_1_p.append(df[val][i])\n",
    "            joins_1_e.append(df['tag'][i])\n",
    "        elif count_joins == 2:\n",
    "            joins_2_p.append(df[val][i])\n",
    "            joins_2_e.append(df['tag'][i])       \n",
    "        elif count_joins == 3:\n",
    "            joins_3_p.append(df[val][i])\n",
    "            joins_3_e.append(df['tag'][i])       \n",
    "        elif count_joins == 4:\n",
    "            joins_4_p.append(df[val][i])\n",
    "            joins_4_e.append(df['tag'][i])       \n",
    "        elif count_joins == 5:\n",
    "            joins_5_p.append(df[val][i])\n",
    "            joins_5_e.append(df['tag'][i])       \n",
    "        else:\n",
    "            joins_6_p.append(df[val][i])\n",
    "            joins_6_e.append(df['tag'][i])       \n",
    "    promedio = [joins_1_p, joins_2_p, joins_3_p, joins_4_p, joins_5_p, joins_6_p]\n",
    "    errores = [joins_1_e, joins_2_e, joins_3_e, joins_4_e, joins_5_e, joins_6_e]\n",
    "    return promedio, errores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_p_joins, original_e_joins = split_by_joins(neo_df_final, 'real_old')\n",
    "neo_p_joins, neo_e_joins = split_by_joins(neo_df_final,'pred_new')\n",
    "ql_p_joins, ql_e_joins = split_by_joins(ql_df_final, 'pred_new')\n",
    "sarsa_p_joins, sarsa_e_joins = split_by_joins(sarsa_df_final, 'pred_new')\n",
    "exsarsa_p_joins, exsarsa_e_joins = split_by_joins(exsarsa_df_final, 'pred_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebc140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(exsarsa_p_joins[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb400a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "# data to plot\n",
    "n_groups = len(neo_p_joins)\n",
    "    #igual = (neo_igual, ql_igual, sarsa_igual, exsarsa_igual)\n",
    "    #mejor = (neo_mejor, ql_mejor, sarsa_mejor, exsarsa_mejor)\n",
    "    #peor = (neo_peor, ql_peor, sarsa_peor, exsarsa_peor)\n",
    "\n",
    " # create plot\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.15\n",
    "opacity = 0.8\n",
    "c = ['blue','lightgreen','lightblue','yellow','orange']\n",
    "\n",
    "\n",
    "mean_original = np.array([np.mean(val) for val in original_p_joins])\n",
    "mean_neo = np.array([np.mean(val) for val in neo_p_joins])\n",
    "mean_ql = np.array([np.mean(val) for val in ql_p_joins])\n",
    "mean_sarsa = np.array([np.mean(val) for val in sarsa_p_joins])\n",
    "mean_exsarsa = np.array([np.mean(val) for val in exsarsa_p_joins])\n",
    "\n",
    "\n",
    "rects_original = plt.bar(index, mean_original, bar_width,\n",
    "alpha=opacity,\n",
    "color=c[0],\n",
    "edgecolor = 'black',\n",
    "label='VOS')\n",
    "rects_neo = plt.bar(index+bar_width, mean_neo, bar_width,\n",
    "alpha=opacity,\n",
    "color=c[1],\n",
    "edgecolor = 'black',\n",
    "label='Neo')\n",
    "rects_ql = plt.bar(index+bar_width*2, mean_ql, bar_width,\n",
    "alpha=opacity,\n",
    "color=c[2],\n",
    "edgecolor = 'black',\n",
    "label='Q-Learning')\n",
    "rects_sarsa = plt.bar(index+bar_width*3, mean_sarsa, bar_width,\n",
    "alpha=opacity,\n",
    "color=c[3],\n",
    "edgecolor = 'black',\n",
    "label='Sarsa')\n",
    "rects_exsarsa = plt.bar(index+bar_width*4, mean_exsarsa, bar_width,\n",
    "alpha=opacity,\n",
    "color=c[4],\n",
    "edgecolor = 'black',\n",
    "label='Expected Sarsa')\n",
    "\n",
    "\n",
    "plt.xlabel('Número de JOINS')\n",
    "plt.ylabel('Promedio de latencia')\n",
    "plt.title(f'Latencia promedio con cierta cantidad de número de Joins para cada algoritmo')\n",
    "plt.xticks(index+bar_width*2, ('1','2','3','4','5','6+'))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2c6d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2083c5f1",
   "metadata": {},
   "source": [
    "### Consultas mejoradas, consultas iguales, consultas empeoradas diferenciados por numero de JOINs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errores_join(lista_e_join,nombre_algoritmo):\n",
    "    igual = []\n",
    "    mejor = []\n",
    "    peor = []\n",
    "    for j in lista_e_join:\n",
    "        i, m, p = j.count('igual'), j.count('mejor'), j.count('peor')\n",
    "        igual.append(i)\n",
    "        mejor.append(m)\n",
    "        peor.append(p)\n",
    "    plt.rcParams.update({'font.size': 13})\n",
    "    # data to plot\n",
    "    n_groups = len(igual)\n",
    "    #igual = (neo_igual, ql_igual, sarsa_igual, exsarsa_igual)\n",
    "    #mejor = (neo_mejor, ql_mejor, sarsa_mejor, exsarsa_mejor)\n",
    "    #peor = (neo_peor, ql_peor, sarsa_peor, exsarsa_peor)\n",
    "\n",
    "    # create plot\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.15\n",
    "    opacity = 0.8\n",
    "\n",
    "    rects1 = plt.bar(index, mejor, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='lightgreen',\n",
    "    label='Mejor',\n",
    "    edgecolor = 'black')\n",
    "\n",
    "    rects2 = plt.bar(index + bar_width, igual, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='khaki',\n",
    "    label='Igual',\n",
    "    edgecolor = 'black')\n",
    "\n",
    "    rects3 = plt.bar(index + 2*bar_width, peor, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='darksalmon',\n",
    "    label='Peor',\n",
    "    edgecolor = 'black')\n",
    "\n",
    "    plt.xlabel('Número de JOINS')\n",
    "    plt.ylabel('Promedio de latencia')\n",
    "    plt.title(f'Número de errores por número de JOINS para algoritmo {nombre_algoritmo}')\n",
    "    plt.xticks(index + bar_width, ('1','2','3','4','5','6+'))\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    for i in index:\n",
    "        ax.text(index[i], \n",
    "                 mejor[i]*0.7,\n",
    "                 str(mejor[i]),\n",
    "                 ha='center', va='bottom',\n",
    "                )\n",
    "        ax.text(index[i] + bar_width, \n",
    "                 igual[i]*0.75,\n",
    "                 str(igual[i]),\n",
    "                 ha='center', va='bottom',\n",
    "                )\n",
    "        ax.text(index[i] + 2*bar_width, \n",
    "                 peor[i]*0.75,\n",
    "                 str(peor[i]),\n",
    "                 ha='center', va='bottom',\n",
    "                )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184cc626",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_errores_join(neo_e_joins,'NEO')\n",
    "plot_errores_join(ql_e_joins,'Q-Learning')\n",
    "plot_errores_join(sarsa_e_joins,'Sarsa')\n",
    "plot_errores_join(exsarsa_e_joins,'Expected Sarsa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9f42a",
   "metadata": {},
   "source": [
    "### RMSE y MAE Por iteración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edefe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_rl\n",
    "#neo_df_final\n",
    "#ql_df_final\n",
    "#sarsa_df_final\n",
    "#exsarsa_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_df_no_history[['mse_new','mse_old']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef151e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b91dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637917a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e425dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e562b7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7db09d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
