{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRERIAS y CONSTANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS CUDA AVAILABLE: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import plotly.express as px\n",
    "\n",
    "#Implement training process\n",
    "from model_trees_algebra import NeoRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class BaoTrainingException(Exception):\n",
    "    pass\n",
    "\n",
    "URL = \"/media/data/ccarmona/memoria/dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: train_val data (21703, 84)\n",
      "Shapes : Train: (17357, 84) Val: (4346, 84)\n",
      "Error in data ignored! [bgp \"VAR_URI_VARᶲhttp://www.wikidata.org/prop/direct/P685\"]\n",
      "Error in data ignored! [datasetnames ?var1]\n",
      "Error in data ignored! [reduced   [\"VAR_VAR_VARᶲNONE\"]]\n",
      "Error in data ignored! [reduced   [\"VAR_VAR_VARᶲNONE\"]]\n",
      "Error in data ignored! [reduced   [\"VAR_VAR_VARᶲNONE\"]]\n",
      "Error in data ignored! [reduced   [\"VAR_VAR_VARᶲNONE\"]]\n",
      "[ \"JOINᶲhttp://www.wikidata.org/prop/direct/P31ᶲhttp://schema.org/description\" ,   [ \"VAR_URI_URIᶲhttp://www.wikidata.org/prop/direct/P31\" ] ,   [ \"VAR_URI_LITERALᶲhttp://schema.org/description\" ] ] \n",
      "['JOINᶲhttp://www.wikidata.org/prop/direct/P31ᶲhttp://schema.org/description', ['VAR_URI_URIᶲhttp://www.wikidata.org/prop/direct/P31'], ['VAR_URI_LITERALᶲhttp://schema.org/description']]\n"
     ]
    }
   ],
   "source": [
    "def split_ds(all_data, val_rate, seed):\n",
    "    \"\"\"\n",
    "    Used  to keep a balance of sets with respect to runtime of queries. \n",
    "    test_rate is a rate of the total,\n",
    "    val_rate is a rate of the (total - test_rate)\n",
    "    :param all_data: Pandas dataframe with data\n",
    "    :param val_rate: Rate of the (total - test_rate)\n",
    "    :param seed: For replication of results, this fixes the seed of split method. \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    ranges = {}\n",
    "    ranges['1_2'] = all_data[(all_data[\"time\"] > 0)    & (all_data[\"time\"] <= 2)]\n",
    "    ranges['2_3'] = all_data[(all_data[\"time\"] > 2)    & (all_data[\"time\"] <= 3)]\n",
    "    ranges['3_4'] = all_data[(all_data[\"time\"] > 3)    & (all_data[\"time\"] <= 4)]\n",
    "    ranges['4_5'] = all_data[(all_data[\"time\"] > 4)    & (all_data[\"time\"] <= 5)]\n",
    "    ranges['5_8'] = all_data[(all_data[\"time\"] > 5)    & (all_data[\"time\"] <= 8)]\n",
    "    ranges['8_10'] = all_data[(all_data[\"time\"] > 8)   & (all_data[\"time\"] <= 10)]\n",
    "    ranges['10_20'] =   all_data[(all_data[\"time\"] > 10) & (all_data[\"time\"] <= 20)]\n",
    "    ranges['20_30'] =   all_data[(all_data[\"time\"] > 20) & (all_data[\"time\"] <= 30)]\n",
    "    ranges['30_40'] =   all_data[(all_data[\"time\"] > 30) & (all_data[\"time\"] <= 40)]\n",
    "    ranges['40_50'] =   all_data[(all_data[\"time\"] > 40) & (all_data[\"time\"] <= 50)]\n",
    "    ranges['50_60'] =   all_data[(all_data[\"time\"] > 50) & (all_data[\"time\"] <= 60)]\n",
    "    ranges['60_80'] =   all_data[(all_data[\"time\"] > 60) & (all_data[\"time\"] <= 80)]\n",
    "    ranges['80_100'] =  all_data[(all_data[\"time\"] > 80) & (all_data[\"time\"] <= 100)]\n",
    "    ranges['100_150'] = all_data[(all_data[\"time\"] > 100) & (all_data[\"time\"] <= 150)]\n",
    "    ranges['150_200'] = all_data[(all_data[\"time\"] > 150) & (all_data[\"time\"] <= 200)]\n",
    "    ranges['200_250'] = all_data[(all_data[\"time\"] > 200) & (all_data[\"time\"] <= 250)]\n",
    "    ranges['250_last'] = all_data[(all_data[\"time\"] > 250)]\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    for rang in ranges.values():\n",
    "        if rang.shape[0] >= 3:\n",
    "            X_train, X_val = train_test_split(\n",
    "                rang, test_size=val_rate, shuffle=True,random_state=seed)\n",
    "\n",
    "            train_data.append(X_train)\n",
    "            val_data.append(X_val)\n",
    "    train_data_list = pd.concat(train_data)\n",
    "    val_data_list = pd.concat(val_data)\n",
    "    print(\"Shapes : Train: {} Val: {}\".format(train_data_list.shape, val_data_list.shape))\n",
    "    return train_data_list, val_data_list\n",
    "\n",
    "data_train_val_raw = pd.read_csv(URL + \"ds_trainval_pred_filtered.csv\", delimiter=\"ᶶ\", engine='python')\n",
    "ds_test_raw = pd.read_csv(URL + \"ds_test_pred_filtered.csv\", delimiter=\"ᶶ\", engine='python')\n",
    "\n",
    "data_train_val_prev = data_train_val_raw[data_train_val_raw['time'] <=65]\n",
    "ds_test_prev = ds_test_raw[ds_test_raw['time'] <=65]\n",
    "\n",
    "print(\"Shape: train_val data\" , data_train_val_prev.shape)\n",
    "def clear_error_tuples(x):\n",
    "    try:\n",
    "        #if x == '[\"VAR_URI_LITERALᶲhttp://www.wikidata.org/prop/direct/P2529\"]':\n",
    "         #   print(x)\n",
    "        #print(type(x))\n",
    "        json.loads(x)\n",
    "        return True\n",
    "    except:\n",
    "        print(\"Error in data ignored!\", x)\n",
    "        return False\n",
    "\n",
    "#Split Dataset\n",
    "ds_train_prev, ds_val_prev = split_ds(data_train_val_prev, 0.2,seed=None)\n",
    "#Remove bad rows\n",
    "ds_train  = ds_train_prev[ds_train_prev['trees'].apply(lambda x: clear_error_tuples(x))]\n",
    "ds_val  = ds_val_prev[ds_val_prev['trees'].apply(lambda x: clear_error_tuples(x))]\n",
    "ds_test  = ds_test_prev[ds_test_prev['trees'].apply(lambda x: clear_error_tuples(x))]\n",
    "\n",
    "\n",
    "x = ds_test_prev['trees'][20]\n",
    "print(x)\n",
    "x = json.loads(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21703\n"
     ]
    }
   ],
   "source": [
    "data_train_val_prev = data_train_val_prev.reset_index(drop=True)\n",
    "f = open(\"old_queries.txt\", \"a\")\n",
    "c = 0\n",
    "for i in range(len(data_train_val_prev)):\n",
    "    f.write(str(data_train_val_prev['query'][i])+\"\\n\")\n",
    "    c += 1\n",
    "print(c)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2963\n"
     ]
    }
   ],
   "source": [
    "ds_test_prev = ds_test_prev.reset_index(drop=True)\n",
    "f2 = open(\"old_queries2.txt\", \"a\")\n",
    "c = 0\n",
    "for i in range(len(ds_test_prev)):\n",
    "    f2.write(str(data_train_val_prev['query'][i]) + \"\\n\")\n",
    "    c += 1\n",
    "print(c)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SHAPES-----------\n",
      "----------RAW-----------\n",
      "shape data_train_val_raw: (25805, 84)\n",
      "shape ds_test_raw: (3528, 84)\n",
      "----------PREV----------\n",
      "shape ds_train_prev: (17357, 84)\n",
      "shape ds_val_prev: (4346, 84)\n",
      "shape ds_test_prev: (2963, 84)\n",
      "----------CLEAN----------\n",
      "shape ds_train: (17351, 84)\n",
      "shape ds_val: (4346, 84)\n",
      "shape ds_test: (2963, 84)\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------SHAPES-----------\")\n",
    "print(\"----------RAW-----------\")\n",
    "print(f'shape data_train_val_raw: {data_train_val_raw.shape}')\n",
    "print(f'shape ds_test_raw: {ds_test_raw.shape}')\n",
    "print(\"----------PREV----------\")\n",
    "print(f'shape ds_train_prev: {ds_train_prev.shape}')\n",
    "print(f'shape ds_val_prev: {ds_val_prev.shape}')\n",
    "print(f'shape ds_test_prev: {ds_test_prev.shape}')\n",
    "print(\"----------CLEAN----------\")\n",
    "print(f'shape ds_train: {ds_train.shape}')\n",
    "print(f'shape ds_val: {ds_val.shape}')\n",
    "print(f'shape ds_test: {ds_test.shape}')\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25805.000000\n",
       "mean        33.088488\n",
       "std         55.198294\n",
       "min          1.392783\n",
       "25%          2.066000\n",
       "50%          5.527993\n",
       "75%         41.633546\n",
       "max        307.183215\n",
       "Name: time, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_val_raw['time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3528.000000\n",
       "mean       33.105443\n",
       "std        55.097697\n",
       "min         1.839000\n",
       "25%         2.063000\n",
       "50%         5.629112\n",
       "75%        41.445001\n",
       "max       305.150172\n",
       "Name: time, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test_raw['time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    17351.000000\n",
       "mean        12.972844\n",
       "std         17.050058\n",
       "min          1.392783\n",
       "25%          2.045000\n",
       "50%          2.290000\n",
       "75%         18.915900\n",
       "max         64.962858\n",
       "Name: time, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train['time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4346.000000\n",
       "mean       13.028326\n",
       "std        17.077475\n",
       "min         1.829000\n",
       "25%         2.047000\n",
       "50%         2.308500\n",
       "75%        19.255744\n",
       "max        64.673409\n",
       "Name: time, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val_prev['time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2963.000000\n",
       "mean       12.878044\n",
       "std        16.911206\n",
       "min         1.839000\n",
       "25%         2.042000\n",
       "50%         2.291000\n",
       "75%        18.995694\n",
       "max        64.915283\n",
       "Name: time, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test['time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getpredictions_info(x_val_tree, x_val_query, y_val):\n",
    "    \"\"\"\n",
    "    Get statistics by a set of data. Need the previous trained model(availablre  form reg object).\n",
    "    :param x_val_tree: Plan level features.\n",
    "    :param x_val_query: Query level features.\n",
    "    :param y_val: Real execution time\n",
    "    :return: Dict with predictions and metrics (mae, rmse, mse)\n",
    "    \"\"\"\n",
    "    Xt, Xq, Yv = reg.json_loads(x_val_tree, x_val_query.values, y_val)\n",
    "    Xt = [reg.fix_tree(x) for x in Xt]\n",
    "    Xt = reg.tree_transform.transform(Xt)\n",
    "\n",
    "    pairs_val = list(zip(list(zip(Xt, Xq)), Yv))\n",
    "    dataset_val = DataLoader(pairs_val, batch_size=64, num_workers=0, shuffle=False, collate_fn=reg.collate_with_card)\n",
    "    results_val = reg.predict_best(dataset_val)\n",
    "    y_pred_val, y_real_val = zip(*results_val)\n",
    "    mseval = mean_squared_error(y_real_val, y_pred_val)\n",
    "    maeval = mean_absolute_error(y_real_val, y_pred_val)\n",
    "    rmseval = np.sqrt(mseval)\n",
    "    return {\"pred\": y_pred_val, \"real\" : y_real_val, \"mse\": mseval, \"mae\": maeval, \"rmse\": rmseval, \"history\": reg.history}\n",
    "\n",
    "def getmax(x):\n",
    "    lista=  list(x.values())\n",
    "    maximo = 0\n",
    "    for el in lista:\n",
    "        if (maximo < float(el)):\n",
    "            maximo = float(el)\n",
    "    return maximo\n",
    "\n",
    "def pred2index_dict(x, pred_to_index, maxcardinality):\n",
    "    \"\"\"\n",
    "    get histogram from cardinality features. the values is normalized using the max cardinality of predicate in dataset.\n",
    "    :param x: Tree data from x row sample.\n",
    "    :param pred_to_index: dict with predicates and their index.\n",
    "    :param maxcardinality: Max cardiniality in the dataset.\n",
    "    :return: dictionary with feature json_cardinality.\n",
    "    \"\"\"\n",
    "    resp = {}\n",
    "    x = json.loads(x)\n",
    "    for el in x.keys():\n",
    "        if el in pred_to_index:\n",
    "            resp[pred_to_index[el]] = float(x[el])/maxcardinality\n",
    "    return resp\n",
    "\n",
    "def prepare_query_level_data(x_train_query, x_val_query, x_test_query):\n",
    "    \"\"\" Apply StandardScaller to columns except for json_cardinality that need other proccess\"\"\"\n",
    "    maxcardinality =  x_train_query['json_cardinality'].apply(lambda x: json.loads(x)).apply(lambda x: getmax(x)).max()\n",
    "    #Scale x_query data.\n",
    "    xqtrain = x_train_query.drop(columns=['json_cardinality'])\n",
    "    xqval   = x_val_query.drop(columns=['json_cardinality'])\n",
    "    xqtest   = x_test_query.drop(columns=['json_cardinality'])\n",
    "\n",
    "    scalerx = StandardScaler()\n",
    "    x_train_scaled = scalerx.fit_transform(xqtrain)\n",
    "    x_val_scaled = scalerx.transform(xqval)\n",
    "    x_test_scaled = scalerx.transform(xqtest)\n",
    "\n",
    "    x_train_query =pd.concat([pd.DataFrame(x_train_scaled, index=xqtrain.index, columns=xqtrain.columns),x_train_query[['json_cardinality']]], axis=1)\n",
    "    x_val_query =  pd.concat([pd.DataFrame(x_val_scaled,   index=xqval.index, columns=xqval.columns),x_val_query[['json_cardinality']]], axis=1)\n",
    "    x_test_query =  pd.concat([pd.DataFrame(x_test_scaled,   index=xqtest.index, columns=xqtest.columns),x_test_query[['json_cardinality']]], axis=1)\n",
    "\n",
    "    x_train_query['json_cardinality'] = x_train_query['json_cardinality'].apply(lambda x: pred2index_dict(x, reg.get_pred(),maxcardinality))\n",
    "    x_val_query['json_cardinality'] = x_val_query['json_cardinality'].apply(lambda x: pred2index_dict(x, reg.get_pred(), maxcardinality))\n",
    "    x_test_query['json_cardinality'] = x_test_query['json_cardinality'].apply(lambda x: pred2index_dict(x, reg.get_pred(), maxcardinality))\n",
    "\n",
    "    return x_train_query, x_val_query, x_test_query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### TreeConv Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Train: 17351, Val 4346\n"
     ]
    }
   ],
   "source": [
    "# Columns to use.\n",
    "list_columns = ['bgp', 'distinct', 'extend', 'join', 'leftjoin', 'triple', 'union' ,\n",
    "                'max_slice_start']\n",
    "folds_execution = {}\n",
    "\n",
    "print(\"Size Train: {}, Val {}\".format(ds_train.shape[0], ds_val.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get query level data\n",
    "x_train_query = ds_train[list_columns]\n",
    "x_val_query   = ds_val[list_columns]\n",
    "\n",
    "# get plan level data\n",
    "x_train_tree = ds_train['trees'].values\n",
    "x_val_tree = ds_val['trees'].values\n",
    "\n",
    "y_train = ds_train['time'].values\n",
    "y_val = ds_val['time'].values\n",
    "\n",
    "x_test_tree = ds_test['trees'].values\n",
    "y_test = ds_test['time'].values\n",
    "x_test_query   = ds_test[list_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SHAPES-----------\n",
      "----------CLEAN-----------\n",
      "shape ds_train: (17351, 84)\n",
      "shape ds_val  : (4346, 84)\n",
      "shape ds_test : (2963, 84)\n",
      "\n",
      "-----TRAIN AND VAL DATA-----\n",
      "----------x_query_data----------\n",
      "shape x_val_query  : (4346, 8)\n",
      "shape x_train_query: (17351, 8)\n",
      "----------x_plan_level_data----------\n",
      "shape x_val_tree  : (4346,)\n",
      "shape x_train_tree: (17351,)\n",
      "----------y_data------------\n",
      "shape y_val  : (4346,)\n",
      "shape y_train: (17351,)\n",
      "\n",
      "----------TEST DATA----------\n",
      "shape x_test_tree : (2963,)\n",
      "shape x_test_query: (2963, 8)\n",
      "shape y_test      : (2963,)\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------SHAPES-----------\")\n",
    "print(\"----------CLEAN-----------\")\n",
    "print(f'shape ds_train: {ds_train.shape}')\n",
    "print(f'shape ds_val  : {ds_val.shape}')\n",
    "print(f'shape ds_test : {ds_test.shape}')\n",
    "print(\"\")\n",
    "print(\"-----TRAIN AND VAL DATA-----\")\n",
    "print(\"----------x_query_data----------\")\n",
    "print(f'shape x_val_query  : {x_val_query.shape}')\n",
    "print(f'shape x_train_query: {x_train_query.shape}')\n",
    "print(\"----------x_plan_level_data----------\")\n",
    "print(f'shape x_val_tree  : {x_val_tree.shape}')\n",
    "print(f'shape x_train_tree: {x_train_tree.shape}')\n",
    "print(\"----------y_data------------\")\n",
    "print(f'shape y_val  : {y_val.shape}')\n",
    "print(f'shape y_train: {y_train.shape}')\n",
    "print(\"\")\n",
    "print(\"----------TEST DATA----------\")\n",
    "print(f'shape x_test_tree : {x_test_tree.shape}')\n",
    "print(f'shape x_test_query: {x_test_query.shape}')\n",
    "print(f'shape y_test      : {y_test.shape}')\n",
    "print(\"-----------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'json_cardinality'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'json_cardinality'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_85778/659956956.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaxcardinality\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mx_train_query\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'json_cardinality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmaxcardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'json_cardinality'"
     ]
    }
   ],
   "source": [
    "maxcardinality =  x_train_query['json_cardinality'].apply(lambda x: json.loads(x)).apply(lambda x: getmax(x)).max()\n",
    "maxcardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeoRegression\n",
    "Esta en model_trees_algebra.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aec_dir = ''\n",
    "\n",
    "verbose=True\n",
    "reg = NeoRegression(\n",
    "     aec={'train_aec': False, 'use_aec': True,'aec_file': '', 'aec_epochs': 200},\n",
    "     epochs=400,\n",
    "     maxcardinality=maxcardinality,\n",
    "     in_channels_neo_net=512,\n",
    "     tree_units=[512, 256, 128],\n",
    "     tree_units_dense=[64, 32],\n",
    "     early_stop_patience=10,\n",
    "     early_stop_initial_patience=180,\n",
    "     tree_activation_tree=nn.LeakyReLU,\n",
    "     tree_activation_dense=nn.ReLU,\n",
    "    optimizer={'optimizer': \"Adam\",'args':{\"lr\":0.00015}},\n",
    "    figimage_size=(18,18),\n",
    "    start_history_from_epoch=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fit the transformer tree data\n",
    "    ### Esto en el fondo mapea tanto  JOINS ,LEFT JOINS, los tipos de triple como VAR_URI_VAR, VAR_VAR_LITERAL ETC.. \n",
    "    ### ASI COMO TAMBIEN MAPEA LOS PREDICADOS a un indice\n",
    "with io.capture_output() as captured:\n",
    "    reg.fit_transform_tree_data_no_ds_rl(ds_train, ds_val, ds_test)\n",
    "print(\"Trees tranformed!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.capture_output() as captured:\n",
    "    x_train_query, x_val_query, x_test_query =  prepare_query_level_data(x_train_query, x_val_query, x_test_query)\n",
    "print(\"END PREPARE QUERY LEVEL DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"--------------dtype--------------------\")\n",
    "print(\"x_train_tree\",x_train_tree.dtype)\n",
    "print(\"x_train_query.values\",x_train_query.values.dtype)\n",
    "print(\"y_train\",y_train.dtype)\n",
    "print(\"x_val_tree\",x_val_tree.dtype)\n",
    "print(\"x_val_query.values\",x_val_query.values.dtype)\n",
    "print(\"y_val\",y_val.dtype)\n",
    "print(\"--------------TYPE--------------------\")\n",
    "print(\"x_train_tree\",type(x_train_tree))\n",
    "print(\"x_train_query.values\",type(x_train_query.values))\n",
    "print(\"y_train\",type(y_train))\n",
    "print(\"x_val_tree\",type(x_val_tree))\n",
    "print(\"x_val_query.values\",type(x_val_query.values))\n",
    "print(\"y_val\",type(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Fit model\n",
    "reg.fit(x_train_tree, x_train_query.values, y_train, x_val_tree, x_val_query.values, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save best model\n",
    "import torch\n",
    "torch.save(reg.best_model.state_dict(), \"./best_model.pt\")\n",
    "#Save stats in val set\n",
    "file_to_store = open(\"./execution_model_stats.pickle\", \"wb\")\n",
    "pickle.dump(getpredictions_info(x_val_tree, x_val_query, y_val), file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_stats = getpredictions_info(x_val_tree, x_val_query, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "ds_val['y_pred'] = val_stats['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "test_stats = getpredictions_info(x_test_tree, x_test_query, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "ds_test['y_pred'] = test_stats['pred']\n",
    "ds_test['y_realcheck'] = test_stats['real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def tag_points(x):\n",
    "    \"\"\"Add quality tags of predictions. Used to plot with plotly\"\"\"\n",
    "    difference = x['time'] - x['y_pred'][0]\n",
    "    abs_diff = np.abs(difference)\n",
    "    x['y_pred'] = x['y_pred'][0]\n",
    "    x['query2'] = x['query'].replace(\" . \", ' . <br>').replace(\" FILTER\", '<br> FILTER').replace(\" { \", ' { <br>').replace(\" } \", ' <br> }').replace(\" ; \", ' ; <br>') \n",
    "    p20 = x['time'] * 0.2\n",
    "    p40 = x['time'] * 0.4\n",
    "    if abs_diff < p20:\n",
    "        x['color'] = \"good prediction\"\n",
    "    elif abs_diff < p40:\n",
    "        x['color'] = \"aceptable prediction\"\n",
    "    else:\n",
    "        x['color'] = \"bad prediction\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "other = ds_test.apply(lambda x: tag_points(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "other.to_pickle(\"./predictions_test.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "otherval = ds_val.apply(lambda x: tag_points(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "otherval.to_pickle(\"./predictions_val.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(otherval[['id','query','query2','time','y_pred','color']], x=\"y_pred\", y=\"time\", color=\"color\", hover_data=['id', 'query2'])\n",
    "fig.update_layout(height=800, width=1000, title_text=\"Predictions on Val Set\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(other[['id','query','query2','time','y_pred','color']], x=\"y_pred\", y=\"time\", color=\"color\", hover_data=['id', 'query2'])\n",
    "fig.update_layout(height=800, width=1000, title_text=\"Predictions on Test Set\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MetricTotalAccuraccy(ds_final, validation=True):\n",
    "    copy_ds_final = ds_final.copy()\n",
    "    copy_ds_final = copy_ds_final.reset_index(drop=True)\n",
    "    bad_pred = []\n",
    "    accep_pred = []\n",
    "    good_pred = []\n",
    "    try:\n",
    "        if validation:\n",
    "            for i in range(len(copy_ds_final)):\n",
    "               # print(i)\n",
    "                if copy_ds_final['color'][i] == 'bad prediction':\n",
    "                    bad_pred.append((copy_ds_final['time'][i],copy_ds_final['y_pred'][i]))\n",
    "                if copy_ds_final['color'][i] == 'aceptable prediction':\n",
    "                    accep_pred.append((copy_ds_final['time'][i],copy_ds_final['y_pred'][i]))\n",
    "                if copy_ds_final['color'][i] == 'good prediction':\n",
    "                    good_pred.append((copy_ds_final['time'][i],copy_ds_final['y_pred'][i]))\n",
    "        else:\n",
    "            for i in range(len(copy_ds_final)):\n",
    "               # print(i)\n",
    "                if copy_ds_final['color'][i] == 'bad prediction':\n",
    "                    bad_pred.append((copy_ds_final['time'][i],copy_ds_final['y_realcheck'][i]))\n",
    "                if copy_ds_final['color'][i] == 'aceptable prediction':\n",
    "                    accep_pred.append((copy_ds_final['time'][i],copy_ds_final['y_realcheck'][i]))\n",
    "                if copy_ds_final['color'][i] == 'good prediction':\n",
    "                    good_pred.append((copy_ds_final['time'][i],copy_ds_final['y_realcheck'][i]))\n",
    "    except:\n",
    "        print(\"Its not ds_final\")\n",
    "        return 0,0,0,0,0,0,0\n",
    "    b = len(bad_pred)\n",
    "    a = len(accep_pred)\n",
    "    g = len(good_pred)\n",
    "    tot = b+a+g\n",
    "    \n",
    "    bp = (b/tot)*100\n",
    "    ap = (a/tot)*100\n",
    "    gp = (g/tot)*100\n",
    "    \n",
    "    return tot,b,a,g,bp,ap,gp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_val,b_val,a_val,g_val,bp_val,ap_val,gp_val = MetricTotalAccuraccy(otherval)\n",
    "print(f\"Total predictions: {tot_val}\")\n",
    "print(f\"Bad predictions: {b_val}, percentage {bp_val}%\")\n",
    "print(f\"Acceptable predictions: {a_val}, percentage {ap_val}%\")\n",
    "print(f\"Good predictions: {g_val}, percentage {gp_val}%\")\n",
    "\n",
    "print(f\"Accuraccy: {100*(a_val+g_val)/tot_val}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_val,b_val,a_val,g_val,bp_val,ap_val,gp_val = MetricTotalAccuraccy(other)\n",
    "print(f\"Total predictions: {tot_val}\")\n",
    "print(f\"Bad predictions: {b_val}, percentage {bp_val}%\")\n",
    "print(f\"Acceptable predictions: {a_val}, percentage {ap_val}%\")\n",
    "print(f\"Good predictions: {g_val}, percentage {gp_val}%\")\n",
    "\n",
    "print(f\"Accuraccy: {100*(a_val+g_val)/tot_val}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
