{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import StandardScaler #para escalar caracteristicas\n",
    "from sklearn.model_selection import train_test_split # separar mas facil la data de train y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOFTMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: [0.65900114 0.24243297 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x),axis=0)\n",
    "\n",
    "x = np.array([2.0,1.0,0.1])\n",
    "outputs = softmax(x)\n",
    "print('softmax numpy:', outputs)\n",
    "# Observar q el mayor valor es el de mayor probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch\n",
    "Los resultados seran practicamente iguales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0,1.0,0.1])\n",
    "outputs = torch.softmax(x, dim=0) # DEBEMOS ESPECIFICAR LAS DIMENSIONES\n",
    "print('softmax numpy:', outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS ENTROPY\n",
    "Mide el rendimneot de modelo de clasificacion cuya salida esta entre 0 y 1. Se puede combinar con softmax.\n",
    "A medida que la probabilidad predicha diverge de lo real, significa q este valor es muy alto. Por tanto se espera que una buena prediccion tenga una cross entropy bajo.\n",
    "Utiliza vectores one-hot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 numpy: 0.3567\n",
      "Loss 2 numpy: 2.3026\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual*np.log(predicted)) #SUMA SOBRE EL PRODUCTO DE LOS TARGETS REALES * PREDECIDOS\n",
    "    return loss #/ flaot(predicted.shape[0]) #en caso de no ser unidimensional\n",
    "# y debe ser un vector one hot\n",
    "# si es clase 0: [1 0 0]\n",
    "# si es clase 1: [0 1 0]\n",
    "# si es clase 2: [0 0 1]\n",
    "Y = np.array([1,0,0])\n",
    "\n",
    "Y_pred_good = np.array([0.7,0.2,0.1])#SEGUN ESTA PREDICCION\n",
    "                                    #lA CLASE 1 ES BASTANTE LA PROBABILIDAD, POR TANTO MAS CERCA Y MENOS \n",
    "                                    # ENTROPIA CRUZADA, Y SERA BAJA LA PERDIDA\n",
    "Y_pred_bad = np.array([0.1,0.3,0.6]) #SEGUN ESTA PREDICCION\n",
    "                                    #lA CLASE 0 ES MUY BAJA LA PROBABILIDAD SIENDO Q ES CORRECTA\n",
    "                                    # LA ENTROPIA CRUZADA AUMENTA! MUCHA PERDIDA!\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "\n",
    "print(f'Loss 1 numpy: {l1:.4f}')\n",
    "print(f'Loss 2 numpy: {l2:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch\n",
    "Los resultados seran igual de correcto aunque pueden variar\n",
    "Pero OJO, el metodo de aqui ya aplica una funcion de softmax y tambn el negativa, por lo tanto hay que tener consideraciones.\n",
    "* LOS Y TARGETS TIENEN CLASS LABELS = NO USAR ONE HOT, solo  colocar la label correcta\n",
    "* SI LAS Y PREDICCIONES EN \"RAW\" (LOGITS), EN BRUTO... = NO  HAY QUE APLICAR SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 numpy: 0.4170\n",
      "Loss 2 numpy: 1.8406\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([0]) #Solo colocamos el class label, NO ONE HOT\n",
    "#nsamples x nclasses = 1x3\n",
    "Y_pred_good = torch.tensor([[2.0,1.0,0.1]]) # OJO VALORES EN BRUTOS, SIN SOFTMAX\n",
    "# Como la clase 0 es mas alta, es una buena prediccion\n",
    "Y_pred_bad = torch.tensor([[0.5,2.0,0.3]]) #Como la clase 0 es mas baja, es una MALA prediccion\n",
    "\n",
    "l1 = loss(Y_pred_good,Y)\n",
    "l2 = loss(Y_pred_bad,Y)\n",
    "\n",
    "print(f'Loss 1 numpy: {l1.item():.4f}')\n",
    "print(f'Loss 2 numpy: {l2.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos obtener las predicciones reales, se puede ahcer lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions1: tensor([0])\n",
      "predictions2: tensor([1])\n"
     ]
    }
   ],
   "source": [
    "_,predictions1 = torch.max(Y_pred_good, 1)\n",
    "_,predictions2 = torch.max(Y_pred_bad, 1)\n",
    "\n",
    "print(f'predictions1: {predictions1}')\n",
    "print(f'predictions2: {predictions2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahi se puede ver cual es la mejor opcion de cada una, asi se obtiene el resultado real de tu prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo con multiples samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 numpy: 0.3018\n",
      "Loss 2 numpy: 1.6242\n",
      "predictions1: tensor([2, 0, 1])\n",
      "predictions2: tensor([0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([2,0,1]) # aqui diremos que la clase 2 del primer sample es el mejor, la clase 0 de la segunda es la mejor, etc..\n",
    "#nsamples x nclasses = 3x3 EN ESTE CASO CAMBIA\n",
    "Y_pred_good = torch.tensor([[0.1,1.0,2.1],[2.0,1.0,0.1],[0.1,3.0,0.1]])\n",
    "# Como es una buena prediccion, calza con el de arriba. El primer sample el mayor es el 2.1 de la posicion 2, \n",
    "# El segundo el mayor es 2.0 de la posicion 0, etc...\n",
    "Y_pred_bad = torch.tensor([[2.1,1.0,0.1],[0.1,1.0,2.1],[0.1,3.0,0.1]]) \n",
    "# Lo mismo de arriba pero alreves (NO ES el mejor resultado\n",
    "# Aunque por ejemplo el tercer sample si es una buena prediccion, los otros dos no\n",
    "\n",
    "l1 = loss(Y_pred_good,Y)\n",
    "l2 = loss(Y_pred_bad,Y)\n",
    "\n",
    "print(f'Loss 1 numpy: {l1.item():.4f}')\n",
    "print(f'Loss 2 numpy: {l2.item():.4f}')\n",
    "\n",
    "_,predictions1 = torch.max(Y_pred_good, 1)\n",
    "_,predictions2 = torch.max(Y_pred_bad, 1)\n",
    "\n",
    "print(f'predictions1: {predictions1}')\n",
    "print(f'predictions2: {predictions2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver como la primera prediccion es buena y acierta la prediccion, mientras que la segunda prediccion es mala pues tiene alta entropia cruzada y se equivoca en la prediccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
