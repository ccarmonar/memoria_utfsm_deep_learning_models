{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import StandardScaler #para escalar caracteristicas\n",
    "from sklearn.model_selection import train_test_split # separar mas facil la data de train y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions\n",
    "En resumidas cuentas es una aplicar una transformacionNO lineal a la SALIDA de una capa y basicamente decidir si el \"neuron\" debe activarse o no.\n",
    "¿Por que se usa?\n",
    "Si no usaramos funciones de activacion, solo podriamos tener transformaciones lineales sobre otras transformaciones lineales lineales, transformando el modelo solo en una transformación lineal, el cual no es muy adecuado para tareas complejas. Por tanto es necesario para algunos problemas (la mayoria) aplicar ciertas funciones no lineales.\n",
    "\n",
    "## Funciones de activaciones mas comunes\n",
    "1. Step function (aunque se usa poco en la practica)\n",
    "2. Sigmoid (usado por ejemplo en regresion logistica, en problemas de clasificacion binaria (ultima capa))\n",
    "3. Tanh (similar a sigmoid, buena opcion dentro de capas ocultas)\n",
    "4. ReLU (opcion más popular en la mayoria de las redes, muy util, si no se sabe que usar es la mejor opción por defecto)\n",
    "5. Leaky ReLU (version levemente medificada de ReLU. Usado si se quiere resolver el problema de \"desaparición de gradiente\", esto es cuando la gradiente es extremadamente cercano a cero y los pesos no aprenden nada. Si los pesos no se actualizan es buena opción utilizar esto en vez de ReLU normal)\n",
    "6. Softmax (Bueno para la ultima capa en un problema de multiclasificación)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Foward Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Esto garantiza que se ejecutara en GPU si esta disponible\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # Esto es porque las imagenes de entrada son 28x28 => un tensor de tamaño de entrada 784\n",
    "hidden_size = 10000\n",
    "num_classes = 10 # Ya que hay 10 diferentes clases\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                          transform =transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                          transform =transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False) #Aqui no es importante el shuffle\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1) #2 rows 3 columns\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000002CED09795F8>\n"
     ]
    }
   ],
   "source": [
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de la muestra:\n",
      "Numero de muestras en el lote:  100\n",
      "Canales:  1\n",
      "Filas:  28\n",
      "Columnas:  28\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño de la muestra:\")\n",
    "print(\"Numero de muestras en el lote: \",samples.shape[0])\n",
    "print(\"Canales: \",samples.shape[1])\n",
    "print(\"Filas: \",samples.shape[2])\n",
    "print(\"Columnas: \",samples.shape[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Neuronal Network\n",
    "Queremos clasificar estos digitos, para esto haremos una red neuronal completamente conectada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        # Aquí creamos las capas con sus respectivas funciones de activacion\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) # Capa/Layer 1\n",
    "        self.relu = nn.ReLU() # Se aplica funcion de activacion ReLu\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes) # Capa2, \n",
    "        #observar que ahora la entrada tendra tamaño hidden_size\n",
    "        # mientras que la salida tendra tamaño del número de clases, \n",
    "        # eso indica que es nuestra última capa\n",
    "        # Teoricamente vendria el softmax pero no se aplicara ya que se hara entropia cruzada y recordar que\n",
    "        # esta la aplica AUTOMATICAMENTE,, por ende PARA ESTE CASO\n",
    "        # NO ES NECESARIA APLICAR LA FUNCIÓN DE ACTIVACIÓN SOFTMAX\n",
    "        \n",
    "    # Se aplica el modelo construido arriba en el forward    \n",
    "    def forward(self,x):\n",
    "        out=self.l1(x)\n",
    "        out=self.relu(out)\n",
    "        out=self.l2(out)\n",
    "        # OJO cuidado que aquí no quiero aplicar nuevamente la función de activacion como se explico arriba\n",
    "        return out\n",
    "        \n",
    "# Definimos el modelo con la clase\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss y optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # De paso aplica la funcion softmax por nosotros\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate) # Se usara el optimizador ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5, step 100/600, loss = 0.1577\n",
      "epoch 1/5, step 200/600, loss = 0.4576\n",
      "epoch 1/5, step 300/600, loss = 0.1385\n",
      "epoch 1/5, step 400/600, loss = 0.1497\n",
      "epoch 1/5, step 500/600, loss = 0.0519\n",
      "epoch 1/5, step 600/600, loss = 0.0665\n",
      "epoch 2/5, step 100/600, loss = 0.1131\n",
      "epoch 2/5, step 200/600, loss = 0.0278\n",
      "epoch 2/5, step 300/600, loss = 0.0050\n",
      "epoch 2/5, step 400/600, loss = 0.0654\n",
      "epoch 2/5, step 500/600, loss = 0.1458\n",
      "epoch 2/5, step 600/600, loss = 0.0791\n",
      "epoch 3/5, step 100/600, loss = 0.0817\n",
      "epoch 3/5, step 200/600, loss = 0.0200\n",
      "epoch 3/5, step 300/600, loss = 0.0569\n",
      "epoch 3/5, step 400/600, loss = 0.0289\n",
      "epoch 3/5, step 500/600, loss = 0.0810\n",
      "epoch 3/5, step 600/600, loss = 0.0618\n",
      "epoch 4/5, step 100/600, loss = 0.0275\n",
      "epoch 4/5, step 200/600, loss = 0.0165\n",
      "epoch 4/5, step 300/600, loss = 0.0256\n",
      "epoch 4/5, step 400/600, loss = 0.0300\n",
      "epoch 4/5, step 500/600, loss = 0.1547\n",
      "epoch 4/5, step 600/600, loss = 0.0050\n",
      "epoch 5/5, step 100/600, loss = 0.0016\n",
      "epoch 5/5, step 200/600, loss = 0.0071\n",
      "epoch 5/5, step 300/600, loss = 0.0163\n",
      "epoch 5/5, step 400/600, loss = 0.0211\n",
      "epoch 5/5, step 500/600, loss = 0.0921\n",
      "epoch 5/5, step 600/600, loss = 0.0465\n"
     ]
    }
   ],
   "source": [
    "n_total_step = len(train_loader) \n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Aplicar reshape\n",
    "        # Las imaenes estan 100,1,28,28 (el 100 solo especifica cantidad, y el 1 numero de canales lo cual solo es relevante en CNN))\n",
    "        # Volverlos un tensor de entrada 100, 784\n",
    "        images = images.reshape(-1, 28*28) #Se envia el GPU si esta disponible...\n",
    "        labels = labels.to(device)\n",
    "        # forward\n",
    "        outputs = model(images).to(device)\n",
    "        loss = criterion(outputs, labels)\n",
    "    \n",
    "        # backwar\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Vaciar los grads\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Print progreso\n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_step}, loss = {loss.item():.4f}')\n",
    "\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 97.63\n"
     ]
    }
   ],
   "source": [
    "# SIEMPRE EVITAR CONSIDERAR LOS GRADIENTES\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        # Debemos hacer nuevamente el reshape OJO\n",
    "        images = images.reshape(-1, 28*28).to(device) #Se envia el GPU si esta disponible...\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value, index\n",
    "        _, predictions = torch.max(outputs, 1) # obtener el max posible valor\n",
    "        n_samples += labels.shape[0] # numero de muestras por lote actual\n",
    "        n_correct += (predictions == labels).sum().item() #ver cuantas acertaron, si acerto suma 1 si no 0\n",
    "    # Medir % precision\n",
    "    acc = 100.0 * n_correct/n_samples\n",
    "    \n",
    "    print(f'accuracy = {acc}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
