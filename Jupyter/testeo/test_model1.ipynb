{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import StandardScaler #para escalar caracteristicas\n",
    "from sklearn.model_selection import train_test_split # separar mas facil la data de train y test\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Esto garantiza que se ejecutara en GPU si esta disponible\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape df_raw: (3711, 21)\n",
      "shape df_clean: (2253, 15)\n",
      "-----------------------\n",
      "shape X_numpy_train: (1810, 14)\n",
      "shape X_numpy_test: (443, 14)\n",
      "shape y_numpy_train: (1810,)\n",
      "shape y_numpy_test: (443,)\n",
      "-----------------------\n",
      "shape X_train: torch.Size([1810, 14])\n",
      "shape X_test: torch.Size([443, 14])\n",
      "shape y_train: torch.Size([1810, 1])\n",
      "shape y_test: torch.Size([443, 1])\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('D:/.Memoria/Test/Jupyter/test_example.csv')\n",
    "columns = list(df_raw.columns)\n",
    "#  Eliminar los con tiempos de ejecución 0 o muy altos\n",
    "df_clean = shuffle(df_raw[(df_raw['ql_rt_msec'] > 0) & (df_raw['ql_rt_msec'] < 1e4)])\n",
    "#df_clean = shuffle(df_raw)\n",
    "\n",
    "df_clean.to_csv('D:/.Memoria/Test/Jupyter/test_example_clean.csv',index=False)\n",
    "\n",
    "### HAY QUE CONVERTIR ALGUNAS COLUMNAS Q ESTAN EN PORCENTAJE A FLOAT\n",
    "df_clean['ql_rt_clocks'] = df_clean['ql_rt_clocks'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_same_seg'] = df_clean['ql_same_seg'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_same_page'] = df_clean['ql_same_page'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_cl_wait_clocks'] = df_clean['ql_cl_wait_clocks'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_c_clocks'] = df_clean['ql_c_clocks'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_c_cl_wait'] = df_clean['ql_c_cl_wait'].apply(lambda x: float(x.strip('%'))/100)\n",
    "\n",
    "\n",
    "print(f'shape df_raw: {df_raw.shape}')\n",
    "\n",
    "df_clean = df_clean[['limit', 'ql_rt_clocks', 'ql_rnd_rows', 'ql_seq_rows', 'ql_same_seg', 'ql_same_page', 'ql_disk_reads', 'ql_spec_disk_reads', 'ql_cl_wait_clocks', 'ql_c_msec', 'ql_c_disk', 'ql_c_clocks', 'ql_cl_messages', 'ql_c_cl_wait','ql_rt_msec']]\n",
    "print(f'shape df_clean: {df_clean.shape}')\n",
    "\n",
    "\n",
    "msk = np.random.rand(len(df_clean)) <= 0.8\n",
    "df_train = df_clean[msk]\n",
    "df_test = df_clean[~msk]\n",
    "\n",
    "df_train.to_csv('D:/.Memoria/Test/Jupyter/test_example_clean_train.csv',index=False)\n",
    "df_test.to_csv('D:/.Memoria/Test/Jupyter/test_example_clean_test.csv',index=False)\n",
    "\n",
    "#print(f'shape df_train: {df_train.shape}')\n",
    "#print(f'shape df_test: {df_test.shape}')\n",
    "\n",
    "\n",
    "## FEATURES - TRAIN Y TEST\n",
    "X_df_train = df_train[['limit', 'ql_rt_clocks', 'ql_rnd_rows', 'ql_seq_rows', 'ql_same_seg', 'ql_same_page', 'ql_disk_reads', 'ql_spec_disk_reads', 'ql_cl_wait_clocks', 'ql_c_msec', 'ql_c_disk', 'ql_c_clocks', 'ql_cl_messages', 'ql_c_cl_wait']]\n",
    "X_df_test = df_test[['limit', 'ql_rt_clocks', 'ql_rnd_rows', 'ql_seq_rows', 'ql_same_seg', 'ql_same_page', 'ql_disk_reads', 'ql_spec_disk_reads', 'ql_cl_wait_clocks', 'ql_c_msec', 'ql_c_disk', 'ql_c_clocks', 'ql_cl_messages', 'ql_c_cl_wait']]\n",
    "\n",
    "X_numpy_train = X_df_train.to_numpy().astype(np.float32)\n",
    "X_numpy_test = X_df_test.to_numpy().astype(np.float32)\n",
    "\n",
    "###SOLO PA COMPARAR NO SIRVEN DE NADA DESPUES BORRAR\n",
    "X_numpy_train_old =  X_numpy_train\n",
    "X_numpy_test_old = X_numpy_test\n",
    "\n",
    "######\n",
    "\n",
    "X_numpy_train = preprocessing.normalize(X_numpy_train)\n",
    "X_numpy_test = preprocessing.normalize(X_numpy_test)\n",
    "\n",
    "#X_numpy_train = preprocessing.scale(X)\n",
    "\n",
    "\n",
    "## TARGETS - TRAIN Y TEST\n",
    "y_df_train = df_train['ql_rt_msec']\n",
    "y_df_test = df_test['ql_rt_msec']\n",
    "\n",
    "y_numpy_train = y_df_train.to_numpy().astype(np.float32)\n",
    "y_numpy_test = y_df_test.to_numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "# Pasarlos a Torch. \n",
    "X_train = torch.from_numpy(X_numpy_train)\n",
    "X_test = torch.from_numpy(X_numpy_test)\n",
    "y_train = torch.from_numpy(y_numpy_train)\n",
    "y_test = torch.from_numpy(y_numpy_test)\n",
    "# También pasar los targets de vector fila a vector columna\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "\n",
    "print(\"-----------------------\")\n",
    "print(f'shape X_numpy_train: {X_numpy_train.shape}')\n",
    "print(f'shape X_numpy_test: {X_numpy_test.shape}')\n",
    "print(f'shape y_numpy_train: {y_numpy_train.shape}')\n",
    "print(f'shape y_numpy_test: {y_numpy_test.shape}')\n",
    "print(\"-----------------------\")\n",
    "print(f'shape X_train: {X_train.shape}')\n",
    "print(f'shape X_test: {X_test.shape}')\n",
    "print(f'shape y_train: {y_train.shape}')\n",
    "print(f'shape y_test: {y_test.shape}')\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000e+00 1.00000e-02 5.64000e+02 ... 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00]\n",
      " [0.00000e+00 6.20000e-01 2.62600e+03 ... 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00]\n",
      " [0.00000e+00 6.60000e-01 8.23000e+02 ... 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00]\n",
      " ...\n",
      " [0.00000e+00 9.50000e-01 4.00000e+00 ... 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00]\n",
      " [0.00000e+00 1.00000e-02 1.74000e+02 ... 9.57169e-01 0.00000e+00\n",
      "  0.00000e+00]\n",
      " [0.00000e+00 7.30000e-01 5.03000e+02 ... 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_numpy_train_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 1.6036898e-05 9.0448111e-01 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 6.7112829e-05 2.8425533e-01 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 2.0092716e-04 2.5055006e-01 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [0.0000000e+00 2.0299098e-01 8.5469890e-01 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 5.0514012e-05 8.7894380e-01 ... 4.8350445e-03\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.4530216e-05 6.5135203e-02 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_numpy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_train, n_features_train = X_train.shape\n",
    "n_samples_test, n_features_test = X_test.shape\n",
    "learning_rate = 0.001\n",
    "hidden_size = 10000\n",
    "input_size = n_features_train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    # Se aplica el modelo construido arriba en el forward    \n",
    "    def forward(self,x):\n",
    "        x=self.l1(x)\n",
    "        x=F.relu(x)\n",
    "        x=self.l2(x)\n",
    "        return x\n",
    "        \n",
    "# Definimos el modelo con la clase\n",
    "model = NeuralNet(input_size,hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss y optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 500, loss = 504454.96875\n",
      "epoch: 1000, loss = 491001.625\n",
      "epoch: 1500, loss = 480281.5625\n",
      "epoch: 2000, loss = 471798.0625\n",
      "epoch: 2500, loss = 466057.71875\n",
      "epoch: 3000, loss = 462178.84375\n",
      "epoch: 3500, loss = 459196.78125\n",
      "epoch: 4000, loss = 456698.875\n",
      "epoch: 4500, loss = 454375.28125\n",
      "epoch: 5000, loss = 452153.625\n",
      "epoch: 5500, loss = 449987.34375\n",
      "epoch: 6000, loss = 447947.84375\n",
      "epoch: 6500, loss = 446006.90625\n",
      "epoch: 7000, loss = 444139.125\n",
      "epoch: 7500, loss = 442365.84375\n",
      "epoch: 8000, loss = 440497.71875\n",
      "epoch: 8500, loss = 438198.96875\n",
      "epoch: 9000, loss = 436104.78125\n",
      "epoch: 9500, loss = 434113.90625\n",
      "epoch: 10000, loss = 432115.59375\n",
      "epoch: 10500, loss = 430098.46875\n",
      "epoch: 11000, loss = 428191.46875\n",
      "epoch: 11500, loss = 426229.4375\n",
      "epoch: 12000, loss = 424371.125\n",
      "epoch: 12500, loss = 422617.75\n",
      "epoch: 13000, loss = 420888.71875\n",
      "epoch: 13500, loss = 419130.4375\n",
      "epoch: 14000, loss = 417473.78125\n",
      "epoch: 14500, loss = 415792.84375\n",
      "epoch: 15000, loss = 414197.0\n",
      "epoch: 15500, loss = 412629.5625\n",
      "epoch: 16000, loss = 411018.96875\n",
      "epoch: 16500, loss = 409474.1875\n",
      "epoch: 17000, loss = 407947.8125\n",
      "epoch: 17500, loss = 406380.3125\n",
      "epoch: 18000, loss = 404856.0\n",
      "epoch: 18500, loss = 403334.5625\n",
      "epoch: 19000, loss = 401886.46875\n",
      "epoch: 19500, loss = 400452.5\n",
      "epoch: 20000, loss = 398998.125\n",
      "epoch: 20500, loss = 397490.5\n",
      "epoch: 21000, loss = 396088.96875\n",
      "epoch: 21500, loss = 394678.53125\n",
      "epoch: 22000, loss = 393304.21875\n",
      "epoch: 22500, loss = 391919.90625\n",
      "epoch: 23000, loss = 390503.625\n",
      "epoch: 23500, loss = 389103.0625\n",
      "epoch: 24000, loss = 387700.4375\n",
      "epoch: 24500, loss = 386375.4375\n",
      "epoch: 25000, loss = 385053.40625\n",
      "epoch: 25500, loss = 383766.65625\n",
      "epoch: 26000, loss = 382448.25\n",
      "epoch: 26500, loss = 381189.3125\n",
      "epoch: 27000, loss = 379886.6875\n",
      "epoch: 27500, loss = 378650.1875\n",
      "epoch: 28000, loss = 377405.84375\n",
      "epoch: 28500, loss = 376217.375\n",
      "epoch: 29000, loss = 375006.3125\n",
      "epoch: 29500, loss = 373823.53125\n",
      "epoch: 30000, loss = 372619.34375\n",
      "epoch: 30500, loss = 371412.5\n",
      "epoch: 31000, loss = 370207.1875\n",
      "epoch: 31500, loss = 369044.6875\n",
      "epoch: 32000, loss = 367824.125\n",
      "epoch: 32500, loss = 366652.40625\n",
      "epoch: 33000, loss = 365558.125\n",
      "epoch: 33500, loss = 364493.53125\n",
      "epoch: 34000, loss = 363451.71875\n",
      "epoch: 34500, loss = 362449.25\n",
      "epoch: 35000, loss = 361462.5625\n",
      "epoch: 35500, loss = 360472.1875\n",
      "epoch: 36000, loss = 359513.4375\n",
      "epoch: 36500, loss = 358563.1875\n",
      "epoch: 37000, loss = 357616.21875\n",
      "epoch: 37500, loss = 356657.375\n",
      "epoch: 38000, loss = 355719.8125\n",
      "epoch: 38500, loss = 354750.5\n",
      "epoch: 39000, loss = 353842.46875\n",
      "epoch: 39500, loss = 352933.34375\n",
      "epoch: 40000, loss = 352042.84375\n",
      "epoch: 40500, loss = 351175.6875\n",
      "epoch: 41000, loss = 350368.34375\n",
      "epoch: 41500, loss = 349516.0\n",
      "epoch: 42000, loss = 348700.9375\n",
      "epoch: 42500, loss = 347899.25\n",
      "epoch: 43000, loss = 347111.0625\n",
      "epoch: 43500, loss = 346309.125\n",
      "epoch: 44000, loss = 345522.3125\n",
      "epoch: 44500, loss = 344765.53125\n",
      "epoch: 45000, loss = 343977.5\n",
      "epoch: 45500, loss = 343222.78125\n",
      "epoch: 46000, loss = 342507.0\n",
      "epoch: 46500, loss = 341736.96875\n",
      "epoch: 47000, loss = 340997.9375\n",
      "epoch: 47500, loss = 340295.6875\n",
      "epoch: 48000, loss = 339559.6875\n",
      "epoch: 48500, loss = 338872.6875\n",
      "epoch: 49000, loss = 338149.8125\n",
      "epoch: 49500, loss = 337443.125\n",
      "epoch: 50000, loss = 336772.90625\n",
      "epoch: 50500, loss = 336095.25\n",
      "epoch: 51000, loss = 335468.4375\n",
      "epoch: 51500, loss = 334782.0\n",
      "epoch: 52000, loss = 334130.46875\n",
      "epoch: 52500, loss = 333460.0\n",
      "epoch: 53000, loss = 332820.125\n",
      "epoch: 53500, loss = 332149.34375\n",
      "epoch: 54000, loss = 331490.3125\n",
      "epoch: 54500, loss = 330853.4375\n",
      "epoch: 55000, loss = 330235.21875\n",
      "epoch: 55500, loss = 329621.25\n",
      "epoch: 56000, loss = 329047.9375\n",
      "epoch: 56500, loss = 328427.5625\n",
      "epoch: 57000, loss = 327837.21875\n",
      "epoch: 57500, loss = 327313.1875\n",
      "epoch: 58000, loss = 326714.1875\n",
      "epoch: 58500, loss = 326102.59375\n",
      "epoch: 59000, loss = 325555.9375\n",
      "epoch: 59500, loss = 324990.21875\n",
      "epoch: 60000, loss = 324413.0625\n",
      "epoch: 60500, loss = 323854.5625\n",
      "epoch: 61000, loss = 323320.21875\n",
      "epoch: 61500, loss = 322723.8125\n",
      "epoch: 62000, loss = 322184.5\n",
      "epoch: 62500, loss = 321655.03125\n",
      "epoch: 63000, loss = 321144.53125\n",
      "epoch: 63500, loss = 320597.03125\n",
      "epoch: 64000, loss = 320089.0\n",
      "epoch: 64500, loss = 319533.75\n",
      "epoch: 65000, loss = 319010.34375\n",
      "epoch: 65500, loss = 318490.09375\n",
      "epoch: 66000, loss = 318022.21875\n",
      "epoch: 66500, loss = 317456.40625\n",
      "epoch: 67000, loss = 316930.21875\n",
      "epoch: 67500, loss = 316442.09375\n",
      "epoch: 68000, loss = 315936.875\n",
      "epoch: 68500, loss = 315460.0625\n",
      "epoch: 69000, loss = 314944.4375\n",
      "epoch: 69500, loss = 314455.21875\n",
      "epoch: 70000, loss = 313975.875\n",
      "epoch: 70500, loss = 313488.375\n",
      "epoch: 71000, loss = 313000.90625\n",
      "epoch: 71500, loss = 312469.875\n",
      "epoch: 72000, loss = 311945.9375\n",
      "epoch: 72500, loss = 311438.96875\n",
      "epoch: 73000, loss = 310926.40625\n",
      "epoch: 73500, loss = 310435.21875\n",
      "epoch: 74000, loss = 309969.65625\n",
      "epoch: 74500, loss = 309475.125\n",
      "epoch: 75000, loss = 308986.40625\n",
      "epoch: 75500, loss = 308570.46875\n",
      "epoch: 76000, loss = 308041.09375\n",
      "epoch: 76500, loss = 307580.75\n",
      "epoch: 77000, loss = 307115.84375\n",
      "epoch: 77500, loss = 306613.6875\n",
      "epoch: 78000, loss = 306191.90625\n",
      "epoch: 78500, loss = 305712.78125\n",
      "epoch: 79000, loss = 305280.5\n",
      "epoch: 79500, loss = 304840.4375\n",
      "epoch: 80000, loss = 304409.3125\n",
      "epoch: 80500, loss = 303979.78125\n",
      "epoch: 81000, loss = 303554.78125\n",
      "epoch: 81500, loss = 303139.25\n",
      "epoch: 82000, loss = 302758.71875\n",
      "epoch: 82500, loss = 302295.03125\n",
      "epoch: 83000, loss = 301928.375\n",
      "epoch: 83500, loss = 301469.3125\n",
      "epoch: 84000, loss = 301055.375\n",
      "epoch: 84500, loss = 300676.375\n",
      "epoch: 85000, loss = 300257.1875\n",
      "epoch: 85500, loss = 299873.0625\n",
      "epoch: 86000, loss = 299466.21875\n",
      "epoch: 86500, loss = 299063.46875\n",
      "epoch: 87000, loss = 298729.6875\n",
      "epoch: 87500, loss = 298326.0625\n",
      "epoch: 88000, loss = 297904.21875\n",
      "epoch: 88500, loss = 297539.96875\n",
      "epoch: 89000, loss = 297177.5\n",
      "epoch: 89500, loss = 296791.5\n",
      "epoch: 90000, loss = 296405.1875\n",
      "epoch: 90500, loss = 296045.1875\n",
      "epoch: 91000, loss = 295691.875\n",
      "epoch: 91500, loss = 295309.125\n",
      "epoch: 92000, loss = 294889.78125\n",
      "epoch: 92500, loss = 294525.4375\n",
      "epoch: 93000, loss = 294156.34375\n",
      "epoch: 93500, loss = 293854.09375\n",
      "epoch: 94000, loss = 293432.21875\n",
      "epoch: 94500, loss = 293022.71875\n",
      "epoch: 95000, loss = 292636.84375\n",
      "epoch: 95500, loss = 292296.90625\n",
      "epoch: 96000, loss = 291887.03125\n",
      "epoch: 96500, loss = 291517.4375\n",
      "epoch: 97000, loss = 291110.90625\n",
      "epoch: 97500, loss = 290669.28125\n",
      "epoch: 98000, loss = 290286.15625\n",
      "epoch: 98500, loss = 289889.71875\n",
      "epoch: 99000, loss = 289573.3125\n",
      "epoch: 99500, loss = 289152.59375\n",
      "epoch: 100000, loss = 288832.21875\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    y_hat = model(X_train)\n",
    "    loss = criterion(y_hat,y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if (epoch+1)%500==0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([443, 14])\n",
      "tensor([0.0000e+00, 8.5845e-05, 8.3591e-02, 9.9650e-01, 0.0000e+00, 1.5455e-05,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4685e-04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(X_test.shape)\n",
    "    print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([839.]) tensor([176.0281])\n",
      "tensor([2204.]) tensor([198.2200])\n",
      "tensor([26.]) tensor([4527.6665])\n",
      "tensor([1.]) tensor([12.7244])\n",
      "tensor([4.]) tensor([-24.3109])\n",
      "tensor([3.]) tensor([64.6655])\n",
      "tensor([1558.]) tensor([217.8521])\n",
      "tensor([240.]) tensor([43.8811])\n",
      "tensor([1.]) tensor([95.2469])\n",
      "tensor([2.]) tensor([175.0770])\n",
      "tensor([3.]) tensor([-4.8499])\n",
      "tensor([49.]) tensor([315.7921])\n",
      "tensor([41.]) tensor([351.1689])\n",
      "tensor([2.]) tensor([-7.3975])\n",
      "tensor([8.]) tensor([494.1892])\n",
      "tensor([65.]) tensor([66.1805])\n",
      "tensor([1.]) tensor([121.1951])\n",
      "tensor([8596.]) tensor([222.6588])\n",
      "tensor([381.]) tensor([360.2102])\n",
      "tensor([37.]) tensor([210.6599])\n",
      "tensor([1.]) tensor([-13.3906])\n",
      "tensor([712.]) tensor([845.6531])\n",
      "tensor([2.]) tensor([2.0464])\n",
      "tensor([17.]) tensor([183.3707])\n",
      "tensor([13.]) tensor([62.1664])\n",
      "tensor([162.]) tensor([168.9139])\n",
      "tensor([29.]) tensor([475.5084])\n",
      "tensor([26.]) tensor([-296.6458])\n",
      "tensor([274.]) tensor([83.3003])\n",
      "tensor([2.]) tensor([20.8392])\n",
      "tensor([33.]) tensor([194.4866])\n",
      "tensor([168.]) tensor([64.0775])\n",
      "tensor([1.]) tensor([36.2297])\n",
      "tensor([1.]) tensor([-40.4416])\n",
      "tensor([1.]) tensor([0.7969])\n",
      "tensor([2.]) tensor([-93.7742])\n",
      "tensor([4.]) tensor([-10.3827])\n",
      "tensor([3.]) tensor([52.6935])\n",
      "tensor([55.]) tensor([41.5226])\n",
      "tensor([11.]) tensor([-357.1725])\n",
      "tensor([1.]) tensor([43.9384])\n",
      "tensor([2.]) tensor([176.7620])\n",
      "tensor([1.]) tensor([169.4568])\n",
      "tensor([1.]) tensor([-398.6699])\n",
      "tensor([404.]) tensor([220.0674])\n",
      "tensor([58.]) tensor([528.6334])\n",
      "tensor([1.]) tensor([-23.9338])\n",
      "tensor([160.]) tensor([347.3374])\n",
      "tensor([3.]) tensor([47.1304])\n",
      "tensor([3.]) tensor([-6.9868])\n",
      "tensor([1108.]) tensor([1045.8922])\n",
      "tensor([549.]) tensor([1385.2423])\n",
      "tensor([52.]) tensor([178.8218])\n",
      "tensor([2.]) tensor([121.9521])\n",
      "tensor([1.]) tensor([153.0485])\n",
      "tensor([1.]) tensor([-16.4688])\n",
      "tensor([4.]) tensor([-10.7105])\n",
      "tensor([14.]) tensor([847.6735])\n",
      "tensor([2.]) tensor([-183.6876])\n",
      "tensor([2.]) tensor([320.7524])\n",
      "tensor([32.]) tensor([-932.3831])\n",
      "tensor([55.]) tensor([564.3226])\n",
      "tensor([296.]) tensor([113.1764])\n",
      "tensor([1.]) tensor([-78.6122])\n",
      "tensor([2921.]) tensor([456.5944])\n",
      "tensor([309.]) tensor([-670.3997])\n",
      "tensor([4.]) tensor([80.2667])\n",
      "tensor([267.]) tensor([987.8066])\n",
      "tensor([2.]) tensor([-2.6505])\n",
      "tensor([1.]) tensor([47.0037])\n",
      "tensor([28.]) tensor([-0.7957])\n",
      "tensor([68.]) tensor([-933.2380])\n",
      "tensor([2.]) tensor([1.4393])\n",
      "tensor([1.]) tensor([-4.1759])\n",
      "tensor([3.]) tensor([-19.3196])\n",
      "tensor([1.]) tensor([-14.5066])\n",
      "tensor([151.]) tensor([189.7156])\n",
      "tensor([3.]) tensor([176.7941])\n",
      "tensor([24.]) tensor([168.7522])\n",
      "tensor([6.]) tensor([98.3115])\n",
      "tensor([2.]) tensor([-19.8814])\n",
      "tensor([1.]) tensor([-173.0144])\n",
      "tensor([36.]) tensor([176.1490])\n",
      "tensor([70.]) tensor([381.1713])\n",
      "tensor([4.]) tensor([47.5046])\n",
      "tensor([8.]) tensor([61.6046])\n",
      "tensor([46.]) tensor([124.5394])\n",
      "tensor([1.]) tensor([-103.3923])\n",
      "tensor([4.]) tensor([63.9615])\n",
      "tensor([4.]) tensor([4.3712])\n",
      "tensor([1.]) tensor([-185.2867])\n",
      "tensor([35.]) tensor([214.3406])\n",
      "tensor([3.]) tensor([-20.8377])\n",
      "tensor([2.]) tensor([53.5741])\n",
      "tensor([2.]) tensor([-38.2620])\n",
      "tensor([4.]) tensor([140.6676])\n",
      "tensor([1.]) tensor([-7.5609])\n",
      "tensor([1.]) tensor([34.7283])\n",
      "tensor([1.]) tensor([1311.1843])\n",
      "tensor([82.]) tensor([185.2688])\n",
      "tensor([1.]) tensor([-42.1653])\n",
      "tensor([160.]) tensor([30.7808])\n",
      "tensor([1.]) tensor([-80.4134])\n",
      "tensor([4.]) tensor([302.2083])\n",
      "tensor([2.]) tensor([48.5618])\n",
      "tensor([12.]) tensor([246.])\n",
      "tensor([3.]) tensor([-93.3102])\n",
      "tensor([9.]) tensor([151.9276])\n",
      "tensor([1.]) tensor([-16.2297])\n",
      "tensor([9.]) tensor([505.1779])\n",
      "tensor([5.]) tensor([46.2335])\n",
      "tensor([171.]) tensor([-138.8669])\n",
      "tensor([4.]) tensor([-7.4735])\n",
      "tensor([1.]) tensor([1.0813])\n",
      "tensor([70.]) tensor([377.7837])\n",
      "tensor([3.]) tensor([-10.1885])\n",
      "tensor([1.]) tensor([-19.8562])\n",
      "tensor([4697.]) tensor([184.7622])\n",
      "tensor([3.]) tensor([7.1246])\n",
      "tensor([41.]) tensor([179.6168])\n",
      "tensor([3.]) tensor([-3.5872])\n",
      "tensor([42.]) tensor([-19.5308])\n",
      "tensor([11.]) tensor([1292.5342])\n",
      "tensor([3.]) tensor([7.8052])\n",
      "tensor([1.]) tensor([-17.2870])\n",
      "tensor([23.]) tensor([1244.9592])\n",
      "tensor([1.]) tensor([40.1399])\n",
      "tensor([5.]) tensor([-7.6249])\n",
      "tensor([1.]) tensor([-87.3707])\n",
      "tensor([1.]) tensor([153.1270])\n",
      "tensor([3.]) tensor([0.0497])\n",
      "tensor([9.]) tensor([80.8341])\n",
      "tensor([23.]) tensor([-599.0933])\n",
      "tensor([34.]) tensor([211.3807])\n",
      "tensor([2.]) tensor([-2.5846])\n",
      "tensor([4.]) tensor([79.4790])\n",
      "tensor([5.]) tensor([241.6948])\n",
      "tensor([28.]) tensor([180.9871])\n",
      "tensor([13.]) tensor([166.0588])\n",
      "tensor([325.]) tensor([4454.5156])\n",
      "tensor([3.]) tensor([44.4709])\n",
      "tensor([1.]) tensor([43.6022])\n",
      "tensor([28.]) tensor([157.3744])\n",
      "tensor([1.]) tensor([-407.4482])\n",
      "tensor([153.]) tensor([603.1884])\n",
      "tensor([4.]) tensor([-67.4976])\n",
      "tensor([1.]) tensor([184.2440])\n",
      "tensor([3647.]) tensor([-2532.4229])\n",
      "tensor([6.]) tensor([14.6666])\n",
      "tensor([3.]) tensor([-6.1105])\n",
      "tensor([12.]) tensor([81.2347])\n",
      "tensor([3.]) tensor([-0.6630])\n",
      "tensor([91.]) tensor([234.1832])\n",
      "tensor([1.]) tensor([569.7119])\n",
      "tensor([4.]) tensor([-29.0402])\n",
      "tensor([4.]) tensor([46.2335])\n",
      "tensor([2766.]) tensor([88.6917])\n",
      "tensor([4.]) tensor([-10.7476])\n",
      "tensor([1.]) tensor([-255.5240])\n",
      "tensor([837.]) tensor([342.7539])\n",
      "tensor([4.]) tensor([-29.4421])\n",
      "tensor([31.]) tensor([1124.6082])\n",
      "tensor([650.]) tensor([1077.3512])\n",
      "tensor([1.]) tensor([46.7485])\n",
      "tensor([3038.]) tensor([1238.5763])\n",
      "tensor([29.]) tensor([13.2444])\n",
      "tensor([1.]) tensor([-124.7073])\n",
      "tensor([13.]) tensor([461.7152])\n",
      "tensor([273.]) tensor([262.5516])\n",
      "tensor([286.]) tensor([524.0554])\n",
      "tensor([2.]) tensor([130.9476])\n",
      "tensor([51.]) tensor([522.4955])\n",
      "tensor([11.]) tensor([262.7681])\n",
      "tensor([4.]) tensor([-4.7932])\n",
      "tensor([1.]) tensor([-2011.2814])\n",
      "tensor([2.]) tensor([-2.6218])\n",
      "tensor([18.]) tensor([54.3833])\n",
      "tensor([1.]) tensor([-137.5936])\n",
      "tensor([4.]) tensor([-0.8980])\n",
      "tensor([3.]) tensor([-2.4606])\n",
      "tensor([2.]) tensor([-4.5011])\n",
      "tensor([90.]) tensor([4070.1975])\n",
      "tensor([1.]) tensor([-124.4753])\n",
      "tensor([2.]) tensor([-2.4468])\n",
      "tensor([29.]) tensor([315.7991])\n",
      "tensor([1.]) tensor([-25.3311])\n",
      "tensor([2.]) tensor([-7.9558])\n",
      "tensor([1.]) tensor([-42.8731])\n",
      "tensor([3.]) tensor([3.5019])\n",
      "tensor([5.]) tensor([81.8552])\n",
      "tensor([51.]) tensor([95.7410])\n",
      "tensor([1.]) tensor([52.9309])\n",
      "tensor([63.]) tensor([371.6273])\n",
      "tensor([2.]) tensor([-21.4629])\n",
      "tensor([4.]) tensor([2347.0740])\n",
      "tensor([2.]) tensor([35.1584])\n",
      "tensor([4.]) tensor([-23.8191])\n",
      "tensor([28.]) tensor([222.7661])\n",
      "tensor([1.]) tensor([3.8409])\n",
      "tensor([3.]) tensor([-19.4379])\n",
      "tensor([3.]) tensor([-2.6218])\n",
      "tensor([508.]) tensor([222.8903])\n",
      "tensor([25.]) tensor([11.7761])\n",
      "tensor([2.]) tensor([-20.8624])\n",
      "tensor([24.]) tensor([321.0405])\n",
      "tensor([61.]) tensor([123.8010])\n",
      "tensor([7.]) tensor([-30.3882])\n",
      "tensor([2.]) tensor([16.6674])\n",
      "tensor([5.]) tensor([68.4814])\n",
      "tensor([7.]) tensor([-0.3021])\n",
      "tensor([16.]) tensor([1067.4373])\n",
      "tensor([1590.]) tensor([250.0291])\n",
      "tensor([71.]) tensor([37.6711])\n",
      "tensor([35.]) tensor([19.9448])\n",
      "tensor([1.]) tensor([6.8782])\n",
      "tensor([2.]) tensor([145.7532])\n",
      "tensor([4.]) tensor([52.3650])\n",
      "tensor([9.]) tensor([350.7698])\n",
      "tensor([1.]) tensor([-7.8366])\n",
      "tensor([2.]) tensor([-3.1877])\n",
      "tensor([1699.]) tensor([1201.1108])\n",
      "tensor([49.]) tensor([275.6937])\n",
      "tensor([10.]) tensor([174.3403])\n",
      "tensor([1.]) tensor([-11.5919])\n",
      "tensor([47.]) tensor([659.1567])\n",
      "tensor([1.]) tensor([114.6660])\n",
      "tensor([5.]) tensor([-3.2809])\n",
      "tensor([1.]) tensor([23.3589])\n",
      "tensor([3.]) tensor([-8.8970])\n",
      "tensor([5.]) tensor([-3.3977])\n",
      "tensor([72.]) tensor([12.0864])\n",
      "tensor([1.]) tensor([1.0813])\n",
      "tensor([8.]) tensor([228.4465])\n",
      "tensor([1.]) tensor([77.6827])\n",
      "tensor([24.]) tensor([135.5957])\n",
      "tensor([6.]) tensor([5.5171])\n",
      "tensor([1.]) tensor([-14.3252])\n",
      "tensor([66.]) tensor([95.1655])\n",
      "tensor([2.]) tensor([-2.5118])\n",
      "tensor([5.]) tensor([37.9056])\n",
      "tensor([2.]) tensor([75.3473])\n",
      "tensor([2.]) tensor([-4.7640])\n",
      "tensor([1.]) tensor([26.8600])\n",
      "tensor([1.]) tensor([115.2771])\n",
      "tensor([2.]) tensor([92.6232])\n",
      "tensor([3.]) tensor([-13.4211])\n",
      "tensor([162.]) tensor([167.5819])\n",
      "tensor([2.]) tensor([220.3510])\n",
      "tensor([4.]) tensor([16.3798])\n",
      "tensor([2.]) tensor([-22.6578])\n",
      "tensor([1.]) tensor([70.5515])\n",
      "tensor([1.]) tensor([-3300.7419])\n",
      "tensor([7.]) tensor([57.0359])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2651.]) tensor([1685.8665])\n",
      "tensor([4.]) tensor([-21.3320])\n",
      "tensor([3.]) tensor([-3.9547])\n",
      "tensor([2.]) tensor([-14.8564])\n",
      "tensor([6.]) tensor([41.9734])\n",
      "tensor([5.]) tensor([44.6682])\n",
      "tensor([4.]) tensor([37.9402])\n",
      "tensor([140.]) tensor([192.4915])\n",
      "tensor([16.]) tensor([-28.3960])\n",
      "tensor([1704.]) tensor([184.0295])\n",
      "tensor([16.]) tensor([455.9210])\n",
      "tensor([1.]) tensor([-40.0374])\n",
      "tensor([1532.]) tensor([3691.3772])\n",
      "tensor([3694.]) tensor([251.3917])\n",
      "tensor([1.]) tensor([-22.2206])\n",
      "tensor([2.]) tensor([-5.8857])\n",
      "tensor([6.]) tensor([154.9349])\n",
      "tensor([1.]) tensor([-3.6027])\n",
      "tensor([474.]) tensor([213.7139])\n",
      "tensor([6.]) tensor([309.8810])\n",
      "tensor([1.]) tensor([-1.6361])\n",
      "tensor([3.]) tensor([-1.1993])\n",
      "tensor([841.]) tensor([3364.8674])\n",
      "tensor([3.]) tensor([-9.6318])\n",
      "tensor([1.]) tensor([-40.0935])\n",
      "tensor([2.]) tensor([47.0781])\n",
      "tensor([2.]) tensor([-13.5872])\n",
      "tensor([81.]) tensor([206.4850])\n",
      "tensor([191.]) tensor([381.2124])\n",
      "tensor([4.]) tensor([-8.4587])\n",
      "tensor([4.]) tensor([-6.6046])\n",
      "tensor([5.]) tensor([54.4457])\n",
      "tensor([36.]) tensor([-525.4244])\n",
      "tensor([2028.]) tensor([129.0830])\n",
      "tensor([526.]) tensor([140.0605])\n",
      "tensor([7.]) tensor([80.5605])\n",
      "tensor([3.]) tensor([29.1742])\n",
      "tensor([172.]) tensor([348.9041])\n",
      "tensor([47.]) tensor([-794.6382])\n",
      "tensor([4.]) tensor([289.4437])\n",
      "tensor([6.]) tensor([336.1714])\n",
      "tensor([906.]) tensor([549.8178])\n",
      "tensor([2.]) tensor([-11.6108])\n",
      "tensor([1097.]) tensor([707.3948])\n",
      "tensor([3.]) tensor([-8.3593])\n",
      "tensor([1.]) tensor([-11.6747])\n",
      "tensor([2.]) tensor([11.8990])\n",
      "tensor([1.]) tensor([109.6300])\n",
      "tensor([34.]) tensor([568.7715])\n",
      "tensor([2.]) tensor([-645.4700])\n",
      "tensor([447.]) tensor([185.4460])\n",
      "tensor([2.]) tensor([-7.4196])\n",
      "tensor([3.]) tensor([29.1219])\n",
      "tensor([1800.]) tensor([1064.8234])\n",
      "tensor([1.]) tensor([-13.0870])\n",
      "tensor([5.]) tensor([52.5858])\n",
      "tensor([2.]) tensor([-4.2524])\n",
      "tensor([505.]) tensor([324.1571])\n",
      "tensor([183.]) tensor([950.0964])\n",
      "tensor([1.]) tensor([-3.5671])\n",
      "tensor([1.]) tensor([-112.8923])\n",
      "tensor([1.]) tensor([471.8118])\n",
      "tensor([2.]) tensor([-6.5883])\n",
      "tensor([1.]) tensor([-104.7344])\n",
      "tensor([6.]) tensor([113.6495])\n",
      "tensor([4.]) tensor([-96.5793])\n",
      "tensor([3.]) tensor([-3.4109])\n",
      "tensor([38.]) tensor([-1967.8105])\n",
      "tensor([4.]) tensor([-9.3411])\n",
      "tensor([2.]) tensor([-9.7449])\n",
      "tensor([136.]) tensor([114.1208])\n",
      "tensor([82.]) tensor([-107.3800])\n",
      "tensor([3.]) tensor([7.7624])\n",
      "tensor([4.]) tensor([8.2273])\n",
      "tensor([1.]) tensor([-10.4930])\n",
      "tensor([4.]) tensor([43.9633])\n",
      "tensor([2.]) tensor([-3.7427])\n",
      "tensor([29.]) tensor([195.8494])\n",
      "tensor([10.]) tensor([361.1281])\n",
      "tensor([2.]) tensor([-0.3481])\n",
      "tensor([444.]) tensor([-23.9420])\n",
      "tensor([43.]) tensor([385.3975])\n",
      "tensor([2525.]) tensor([436.1976])\n",
      "tensor([36.]) tensor([345.9905])\n",
      "tensor([1.]) tensor([71.6562])\n",
      "tensor([6.]) tensor([-10.6505])\n",
      "tensor([2.]) tensor([41.4989])\n",
      "tensor([225.]) tensor([142.1307])\n",
      "tensor([2.]) tensor([-7.9957])\n",
      "tensor([263.]) tensor([170.9587])\n",
      "tensor([4.]) tensor([-3.8673])\n",
      "tensor([1.]) tensor([21.6750])\n",
      "tensor([1.]) tensor([-16.2048])\n",
      "tensor([151.]) tensor([4243.5498])\n",
      "tensor([2.]) tensor([-23.7907])\n",
      "tensor([35.]) tensor([139.7865])\n",
      "tensor([49.]) tensor([1325.8333])\n",
      "tensor([31.]) tensor([2361.9182])\n",
      "tensor([674.]) tensor([220.5001])\n",
      "tensor([58.]) tensor([-701.1179])\n",
      "tensor([1.]) tensor([-425.2780])\n",
      "tensor([1.]) tensor([17.5145])\n",
      "tensor([1.]) tensor([-0.8123])\n",
      "tensor([22.]) tensor([451.0457])\n",
      "tensor([3.]) tensor([1.7240])\n",
      "tensor([3.]) tensor([18.9600])\n",
      "tensor([27.]) tensor([-41.6238])\n",
      "tensor([24.]) tensor([438.7114])\n",
      "tensor([1.]) tensor([2543.0305])\n",
      "tensor([3.]) tensor([-1.5267])\n",
      "tensor([2.]) tensor([18.6508])\n",
      "tensor([52.]) tensor([174.9716])\n",
      "tensor([15.]) tensor([19.0679])\n",
      "tensor([3.]) tensor([178.2404])\n",
      "tensor([9.]) tensor([-14.1752])\n",
      "tensor([1.]) tensor([-35.1143])\n",
      "tensor([2.]) tensor([26.9836])\n",
      "tensor([2.]) tensor([12.7446])\n",
      "tensor([3.]) tensor([55.5767])\n",
      "tensor([1.]) tensor([14.5271])\n",
      "tensor([17.]) tensor([189.6954])\n",
      "tensor([24.]) tensor([1549.9810])\n",
      "tensor([122.]) tensor([1180.2190])\n",
      "tensor([2.]) tensor([-10.6636])\n",
      "tensor([2.]) tensor([-9.7074])\n",
      "tensor([3.]) tensor([80.1478])\n",
      "tensor([2.]) tensor([-15.5326])\n",
      "tensor([4966.]) tensor([1700.6396])\n",
      "tensor([1.]) tensor([-427.2661])\n",
      "tensor([1.]) tensor([1091.0627])\n",
      "tensor([1.]) tensor([-25.4607])\n",
      "tensor([5.]) tensor([423.2987])\n",
      "tensor([1.]) tensor([-1150.8071])\n",
      "tensor([9702.]) tensor([877.2308])\n",
      "tensor([1.]) tensor([33.4807])\n",
      "tensor([3.]) tensor([-12.0951])\n",
      "tensor([1.]) tensor([-333.6616])\n",
      "tensor([4.]) tensor([53.0823])\n",
      "tensor([2.]) tensor([115.5455])\n",
      "tensor([1568.]) tensor([1425.3450])\n",
      "tensor([1.]) tensor([-259.9188])\n",
      "tensor([174.]) tensor([58.5915])\n",
      "tensor([2.]) tensor([19.0118])\n",
      "tensor([5.]) tensor([452.8851])\n",
      "tensor([1.]) tensor([-11.6747])\n",
      "tensor([1.]) tensor([897.7351])\n",
      "tensor([2.]) tensor([-51.1982])\n",
      "tensor([1.]) tensor([481.3088])\n",
      "tensor([1.]) tensor([-7.5442])\n",
      "tensor([3.]) tensor([20.5333])\n",
      "tensor([2.]) tensor([396.6472])\n",
      "tensor([2.]) tensor([53.5957])\n",
      "tensor([1.]) tensor([-777.8665])\n",
      "tensor([7.]) tensor([-18.5199])\n",
      "tensor([6.]) tensor([1174.4805])\n",
      "tensor([804.]) tensor([175.7059])\n",
      "tensor([2.]) tensor([0.3480])\n",
      "tensor([20.]) tensor([163.3242])\n",
      "tensor([2230.]) tensor([191.9803])\n",
      "tensor([2.]) tensor([150.8674])\n",
      "tensor([1.]) tensor([-184.5802])\n",
      "tensor([19.]) tensor([164.1045])\n",
      "tensor([10.]) tensor([67.1974])\n",
      "tensor([4.]) tensor([-16.9785])\n",
      "tensor([1.]) tensor([-11.0592])\n",
      "tensor([6.]) tensor([30.7247])\n",
      "tensor([99.]) tensor([273.5442])\n",
      "tensor([145.]) tensor([1575.5066])\n",
      "tensor([1.]) tensor([-54.0095])\n",
      "tensor([3.]) tensor([0.7788])\n",
      "tensor([5.]) tensor([-1.3013])\n",
      "tensor([4.]) tensor([-3.3658])\n",
      "tensor([1.]) tensor([26.9861])\n",
      "tensor([1.]) tensor([148.2747])\n",
      "tensor([178.]) tensor([184.4812])\n",
      "tensor([5.]) tensor([121.0176])\n",
      "tensor([1.]) tensor([204.3453])\n",
      "tensor([12.]) tensor([364.2759])\n",
      "tensor([1.]) tensor([-21.9755])\n",
      "tensor([9.]) tensor([-376.1730])\n",
      "tensor([5.]) tensor([127.1213])\n",
      "tensor([1.]) tensor([936.9714])\n",
      "tensor([370.]) tensor([209.7699])\n",
      "tensor([5.]) tensor([-36.9314])\n",
      "tensor([5.]) tensor([124.3961])\n",
      "tensor([5.]) tensor([193.8370])\n",
      "tensor([1.]) tensor([32.7179])\n",
      "tensor([2.]) tensor([-33.9136])\n",
      "tensor([1.]) tensor([114.6660])\n",
      "tensor([22.]) tensor([26.9531])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    for i in range(0,outputs.shape[0]):\n",
    "        print(y_test[i],outputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SIEMPRE EVITAR CONSIDERAR LOS GRADIENTES\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        # Debemos hacer nuevamente el reshape OJO\n",
    "        images = images.reshape(-1, 28*28).to(device) #Se envia el GPU si esta disponible...\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value, index\n",
    "        _, predictions = torch.max(outputs, 1) # obtener el max posible valor\n",
    "        n_samples += labels.shape[0] # numero de muestras por lote actual\n",
    "        n_correct += (predictions == labels).sum().item() #ver cuantas acertaron, si acerto suma 1 si no 0\n",
    "    # Medir % precision\n",
    "    acc = 100.0 * n_correct/n_samples\n",
    "    \n",
    "    print(f'accuracy = {acc}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
