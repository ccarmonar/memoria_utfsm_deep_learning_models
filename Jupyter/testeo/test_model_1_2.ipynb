{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import StandardScaler #para escalar caracteristicas\n",
    "from sklearn.model_selection import train_test_split # separar mas facil la data de train y test\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Esto garantiza que se ejecutara en GPU si esta disponible\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape df_raw: (3711, 21)\n",
      "shape df_clean: (2253, 15)\n",
      "-----------------------\n",
      "shape X_numpy_train: (1805, 14)\n",
      "shape X_numpy_test: (448, 14)\n",
      "shape y_numpy_train: (1805,)\n",
      "shape y_numpy_test: (448,)\n",
      "-----------------------\n",
      "shape X_train: torch.Size([1805, 14])\n",
      "shape X_test: torch.Size([448, 14])\n",
      "shape y_train: torch.Size([1805, 1])\n",
      "shape y_test: torch.Size([448, 1])\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('D:/.Memoria/Test/Jupyter/test_example.csv')\n",
    "columns = list(df_raw.columns)\n",
    "#  Eliminar los con tiempos de ejecución 0 o muy altos\n",
    "df_clean = shuffle(df_raw[(df_raw['ql_rt_msec'] > 0) & (df_raw['ql_rt_msec'] < 1e4)])\n",
    "#df_clean = shuffle(df_raw)\n",
    "\n",
    "df_clean.to_csv('D:/.Memoria/Test/Jupyter/test_example_clean.csv',index=False)\n",
    "\n",
    "### HAY QUE CONVERTIR ALGUNAS COLUMNAS Q ESTAN EN PORCENTAJE A FLOAT\n",
    "df_clean['ql_rt_clocks'] = df_clean['ql_rt_clocks'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_same_seg'] = df_clean['ql_same_seg'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_same_page'] = df_clean['ql_same_page'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_cl_wait_clocks'] = df_clean['ql_cl_wait_clocks'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_c_clocks'] = df_clean['ql_c_clocks'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_c_cl_wait'] = df_clean['ql_c_cl_wait'].apply(lambda x: float(x.strip('%'))/100)\n",
    "\n",
    "\n",
    "print(f'shape df_raw: {df_raw.shape}')\n",
    "\n",
    "df_clean = df_clean[['limit', 'ql_rt_clocks', 'ql_rnd_rows', 'ql_seq_rows', 'ql_same_seg', 'ql_same_page', 'ql_disk_reads', 'ql_spec_disk_reads', 'ql_cl_wait_clocks', 'ql_c_msec', 'ql_c_disk', 'ql_c_clocks', 'ql_cl_messages', 'ql_c_cl_wait','ql_rt_msec']]\n",
    "print(f'shape df_clean: {df_clean.shape}')\n",
    "\n",
    "\n",
    "msk = np.random.rand(len(df_clean)) <= 0.8\n",
    "df_train = df_clean[msk]\n",
    "df_test = df_clean[~msk]\n",
    "\n",
    "df_train.to_csv('D:/.Memoria/Test/Jupyter/test_example_clean_train.csv',index=False)\n",
    "df_test.to_csv('D:/.Memoria/Test/Jupyter/test_example_clean_test.csv',index=False)\n",
    "\n",
    "#print(f'shape df_train: {df_train.shape}')\n",
    "#print(f'shape df_test: {df_test.shape}')\n",
    "\n",
    "\n",
    "## FEATURES - TRAIN Y TEST\n",
    "X_df_train = df_train[['limit', 'ql_rt_clocks', 'ql_rnd_rows', 'ql_seq_rows', 'ql_same_seg', 'ql_same_page', 'ql_disk_reads', 'ql_spec_disk_reads', 'ql_cl_wait_clocks', 'ql_c_msec', 'ql_c_disk', 'ql_c_clocks', 'ql_cl_messages', 'ql_c_cl_wait']]\n",
    "X_df_test = df_test[['limit', 'ql_rt_clocks', 'ql_rnd_rows', 'ql_seq_rows', 'ql_same_seg', 'ql_same_page', 'ql_disk_reads', 'ql_spec_disk_reads', 'ql_cl_wait_clocks', 'ql_c_msec', 'ql_c_disk', 'ql_c_clocks', 'ql_cl_messages', 'ql_c_cl_wait']]\n",
    "\n",
    "X_numpy_train = X_df_train.to_numpy().astype(np.float32)\n",
    "X_numpy_test = X_df_test.to_numpy().astype(np.float32)\n",
    "\n",
    "###SOLO PA COMPARAR NO SIRVEN DE NADA DESPUES BORRAR\n",
    "X_numpy_train_old =  X_numpy_train\n",
    "X_numpy_test_old = X_numpy_test\n",
    "\n",
    "######\n",
    "\n",
    "X_numpy_train = preprocessing.normalize(X_numpy_train)\n",
    "X_numpy_test = preprocessing.normalize(X_numpy_test)\n",
    "\n",
    "#X_numpy_train = preprocessing.scale(X)\n",
    "\n",
    "\n",
    "## TARGETS - TRAIN Y TEST\n",
    "y_df_train = df_train['ql_rt_msec']\n",
    "y_df_test = df_test['ql_rt_msec']\n",
    "\n",
    "y_numpy_train = y_df_train.to_numpy().astype(np.float32)\n",
    "y_numpy_test = y_df_test.to_numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "# Pasarlos a Torch. \n",
    "X_train = torch.from_numpy(X_numpy_train)\n",
    "X_test = torch.from_numpy(X_numpy_test)\n",
    "y_train = torch.from_numpy(y_numpy_train)\n",
    "y_test = torch.from_numpy(y_numpy_test)\n",
    "# También pasar los targets de vector fila a vector columna\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "\n",
    "print(\"-----------------------\")\n",
    "print(f'shape X_numpy_train: {X_numpy_train.shape}')\n",
    "print(f'shape X_numpy_test: {X_numpy_test.shape}')\n",
    "print(f'shape y_numpy_train: {y_numpy_train.shape}')\n",
    "print(f'shape y_numpy_test: {y_numpy_test.shape}')\n",
    "print(\"-----------------------\")\n",
    "print(f'shape X_train: {X_train.shape}')\n",
    "print(f'shape X_test: {X_test.shape}')\n",
    "print(f'shape y_train: {y_train.shape}')\n",
    "print(f'shape y_test: {y_test.shape}')\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000e+00 9.4000e-01 2.8717e+04 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.0000e+01 6.9000e-01 3.0141e+04 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 4.6000e-01 3.8700e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [0.0000e+00 6.9000e-01 8.5400e+02 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 6.6000e-01 9.0500e+02 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 5.3000e-01 1.3600e+02 ... 0.0000e+00 0.0000e+00 0.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_numpy_train_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 2.9594916e-05 9.0412468e-01 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [4.0425008e-04 1.3946628e-05 6.0922509e-01 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 8.4397070e-05 7.1003622e-01 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [0.0000000e+00 2.1210554e-04 2.6251903e-01 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 7.4172793e-05 1.0170663e-01 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 2.1920496e-04 5.6248821e-02 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_numpy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_train, n_features_train = X_train.shape\n",
    "n_samples_test, n_features_test = X_test.shape\n",
    "learning_rate = 0.01\n",
    "hidden_size = 10000\n",
    "input_size = n_features_train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    # Se aplica el modelo construido arriba en el forward    \n",
    "    def forward(self,x):\n",
    "        x=self.l1(x)\n",
    "        x=F.relu(x)\n",
    "        x=self.l2(x)\n",
    "        return x\n",
    "        \n",
    "# Definimos el modelo con la clase\n",
    "model = NeuralNet(input_size,hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss y optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 500, loss = 531971.0625\n",
      "epoch: 1000, loss = 509506.40625\n",
      "epoch: 1500, loss = 493023.25\n",
      "epoch: 2000, loss = 479328.46875\n",
      "epoch: 2500, loss = 466792.0\n",
      "epoch: 3000, loss = 455479.25\n",
      "epoch: 3500, loss = 445508.625\n",
      "epoch: 4000, loss = 437506.53125\n",
      "epoch: 4500, loss = 430225.4375\n",
      "epoch: 5000, loss = 423965.71875\n",
      "epoch: 5500, loss = 418345.4375\n",
      "epoch: 6000, loss = 414298.96875\n",
      "epoch: 6500, loss = 409855.90625\n",
      "epoch: 7000, loss = 406538.15625\n",
      "epoch: 7500, loss = 402214.4375\n",
      "epoch: 8000, loss = 399180.75\n",
      "epoch: 8500, loss = 395798.96875\n",
      "epoch: 9000, loss = 392430.40625\n",
      "epoch: 9500, loss = 390519.8125\n",
      "epoch: 10000, loss = 387629.625\n",
      "epoch: 10500, loss = 384515.0\n",
      "epoch: 11000, loss = 382565.90625\n",
      "epoch: 11500, loss = 378975.09375\n",
      "epoch: 12000, loss = 376774.9375\n",
      "epoch: 12500, loss = 374723.5\n",
      "epoch: 13000, loss = 373153.5\n",
      "epoch: 13500, loss = 371407.0\n",
      "epoch: 14000, loss = 369442.3125\n",
      "epoch: 14500, loss = 366950.8125\n",
      "epoch: 15000, loss = 365412.0\n",
      "epoch: 15500, loss = 362755.78125\n",
      "epoch: 16000, loss = 360870.15625\n",
      "epoch: 16500, loss = 358937.53125\n",
      "epoch: 17000, loss = 358623.6875\n",
      "epoch: 17500, loss = 355631.84375\n",
      "epoch: 18000, loss = 355075.15625\n",
      "epoch: 18500, loss = 352464.75\n",
      "epoch: 19000, loss = 352615.53125\n",
      "epoch: 19500, loss = 349535.03125\n",
      "epoch: 20000, loss = 348835.0\n",
      "epoch: 20500, loss = 348221.09375\n",
      "epoch: 21000, loss = 345455.65625\n",
      "epoch: 21500, loss = 344081.1875\n",
      "epoch: 22000, loss = 343177.0\n",
      "epoch: 22500, loss = 342828.28125\n",
      "epoch: 23000, loss = 341368.6875\n",
      "epoch: 23500, loss = 339346.6875\n",
      "epoch: 24000, loss = 339300.6875\n",
      "epoch: 24500, loss = 336246.5625\n",
      "epoch: 25000, loss = 335181.6875\n",
      "epoch: 25500, loss = 334095.75\n",
      "epoch: 26000, loss = 333016.25\n",
      "epoch: 26500, loss = 332718.84375\n",
      "epoch: 27000, loss = 330521.5\n",
      "epoch: 27500, loss = 329744.9375\n",
      "epoch: 28000, loss = 329241.25\n",
      "epoch: 28500, loss = 327032.53125\n",
      "epoch: 29000, loss = 327928.59375\n",
      "epoch: 29500, loss = 327033.84375\n",
      "epoch: 30000, loss = 324283.75\n",
      "epoch: 30500, loss = 322788.15625\n",
      "epoch: 31000, loss = 323547.46875\n",
      "epoch: 31500, loss = 320765.96875\n",
      "epoch: 32000, loss = 320316.8125\n",
      "epoch: 32500, loss = 319262.3125\n",
      "epoch: 33000, loss = 318486.46875\n",
      "epoch: 33500, loss = 318887.71875\n",
      "epoch: 34000, loss = 316232.90625\n",
      "epoch: 34500, loss = 315295.0\n",
      "epoch: 35000, loss = 316247.15625\n",
      "epoch: 35500, loss = 314218.375\n",
      "epoch: 36000, loss = 313878.65625\n",
      "epoch: 36500, loss = 312294.25\n",
      "epoch: 37000, loss = 310783.5625\n",
      "epoch: 37500, loss = 310263.3125\n",
      "epoch: 38000, loss = 309332.125\n",
      "epoch: 38500, loss = 308462.4375\n",
      "epoch: 39000, loss = 307593.1875\n",
      "epoch: 39500, loss = 306875.59375\n",
      "epoch: 40000, loss = 307137.125\n",
      "epoch: 40500, loss = 307594.15625\n",
      "epoch: 41000, loss = 305772.0625\n",
      "epoch: 41500, loss = 304529.5625\n",
      "epoch: 42000, loss = 305618.90625\n",
      "epoch: 42500, loss = 302516.0625\n",
      "epoch: 43000, loss = 303233.40625\n",
      "epoch: 43500, loss = 301733.21875\n",
      "epoch: 44000, loss = 300459.125\n",
      "epoch: 44500, loss = 301056.59375\n",
      "epoch: 45000, loss = 300284.53125\n",
      "epoch: 45500, loss = 300813.28125\n",
      "epoch: 46000, loss = 298892.3125\n",
      "epoch: 46500, loss = 297165.96875\n",
      "epoch: 47000, loss = 297960.84375\n",
      "epoch: 47500, loss = 296761.375\n",
      "epoch: 48000, loss = 296901.21875\n",
      "epoch: 48500, loss = 296042.875\n",
      "epoch: 49000, loss = 296615.3125\n",
      "epoch: 49500, loss = 295247.1875\n",
      "epoch: 50000, loss = 293233.28125\n",
      "epoch: 50500, loss = 292503.3125\n",
      "epoch: 51000, loss = 294330.90625\n",
      "epoch: 51500, loss = 293773.25\n",
      "epoch: 52000, loss = 290686.0625\n",
      "epoch: 52500, loss = 290878.4375\n",
      "epoch: 53000, loss = 291914.34375\n",
      "epoch: 53500, loss = 289725.28125\n",
      "epoch: 54000, loss = 291464.34375\n",
      "epoch: 54500, loss = 288387.84375\n",
      "epoch: 55000, loss = 290253.75\n",
      "epoch: 55500, loss = 288690.40625\n",
      "epoch: 56000, loss = 287194.15625\n",
      "epoch: 56500, loss = 288901.125\n",
      "epoch: 57000, loss = 285584.25\n",
      "epoch: 57500, loss = 285487.3125\n",
      "epoch: 58000, loss = 286246.1875\n",
      "epoch: 58500, loss = 286380.4375\n",
      "epoch: 59000, loss = 283700.1875\n",
      "epoch: 59500, loss = 284767.125\n",
      "epoch: 60000, loss = 283075.53125\n",
      "epoch: 60500, loss = 283325.625\n",
      "epoch: 61000, loss = 281995.28125\n",
      "epoch: 61500, loss = 284274.28125\n",
      "epoch: 62000, loss = 282733.84375\n",
      "epoch: 62500, loss = 282452.0625\n",
      "epoch: 63000, loss = 281498.15625\n",
      "epoch: 63500, loss = 281307.25\n",
      "epoch: 64000, loss = 282249.5\n",
      "epoch: 64500, loss = 278869.90625\n",
      "epoch: 65000, loss = 278947.90625\n",
      "epoch: 65500, loss = 278203.5\n",
      "epoch: 66000, loss = 277824.3125\n",
      "epoch: 66500, loss = 277726.96875\n",
      "epoch: 67000, loss = 277023.3125\n",
      "epoch: 67500, loss = 276523.6875\n",
      "epoch: 68000, loss = 278303.09375\n",
      "epoch: 68500, loss = 278023.03125\n",
      "epoch: 69000, loss = 276590.8125\n",
      "epoch: 69500, loss = 275017.90625\n",
      "epoch: 70000, loss = 277701.8125\n",
      "epoch: 70500, loss = 274272.96875\n",
      "epoch: 71000, loss = 277424.71875\n",
      "epoch: 71500, loss = 277229.9375\n",
      "epoch: 72000, loss = 275359.375\n",
      "epoch: 72500, loss = 274157.65625\n",
      "epoch: 73000, loss = 272456.28125\n",
      "epoch: 73500, loss = 273624.09375\n",
      "epoch: 74000, loss = 272691.96875\n",
      "epoch: 74500, loss = 273032.125\n",
      "epoch: 75000, loss = 271537.75\n",
      "epoch: 75500, loss = 270980.3125\n",
      "epoch: 76000, loss = 273162.46875\n",
      "epoch: 76500, loss = 270485.0625\n",
      "epoch: 77000, loss = 269769.34375\n",
      "epoch: 77500, loss = 272168.0625\n",
      "epoch: 78000, loss = 272573.875\n",
      "epoch: 78500, loss = 272105.53125\n",
      "epoch: 79000, loss = 269281.28125\n",
      "epoch: 79500, loss = 271557.625\n",
      "epoch: 80000, loss = 271147.5625\n",
      "epoch: 80500, loss = 270286.28125\n",
      "epoch: 81000, loss = 267251.71875\n",
      "epoch: 81500, loss = 266950.46875\n",
      "epoch: 82000, loss = 266718.25\n",
      "epoch: 82500, loss = 267083.59375\n",
      "epoch: 83000, loss = 266816.1875\n",
      "epoch: 83500, loss = 268248.5625\n",
      "epoch: 84000, loss = 265544.0625\n",
      "epoch: 84500, loss = 265345.03125\n",
      "epoch: 85000, loss = 265996.15625\n",
      "epoch: 85500, loss = 265628.25\n",
      "epoch: 86000, loss = 264962.15625\n",
      "epoch: 86500, loss = 265519.25\n",
      "epoch: 87000, loss = 264019.03125\n",
      "epoch: 87500, loss = 263493.21875\n",
      "epoch: 88000, loss = 266881.65625\n",
      "epoch: 88500, loss = 266285.34375\n",
      "epoch: 89000, loss = 265181.0\n",
      "epoch: 89500, loss = 263119.625\n",
      "epoch: 90000, loss = 262587.5625\n",
      "epoch: 90500, loss = 263962.625\n",
      "epoch: 91000, loss = 262079.25\n",
      "epoch: 91500, loss = 261927.265625\n",
      "epoch: 92000, loss = 261137.40625\n",
      "epoch: 92500, loss = 263823.84375\n",
      "epoch: 93000, loss = 263466.9375\n",
      "epoch: 93500, loss = 260902.84375\n",
      "epoch: 94000, loss = 263197.3125\n",
      "epoch: 94500, loss = 260894.96875\n",
      "epoch: 95000, loss = 259611.46875\n",
      "epoch: 95500, loss = 261185.671875\n",
      "epoch: 96000, loss = 261162.796875\n",
      "epoch: 96500, loss = 258764.515625\n",
      "epoch: 97000, loss = 259985.546875\n",
      "epoch: 97500, loss = 260492.5625\n",
      "epoch: 98000, loss = 258155.703125\n",
      "epoch: 98500, loss = 260451.328125epoch: 99000, loss = 261156.984375\n",
      "epoch: 99500, loss = 259119.421875\n",
      "epoch: 100000, loss = 257179.390625\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    y_hat = model(X_train)\n",
    "    loss = criterion(y_hat,y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if (epoch+1)%500==0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([448, 14])\n",
      "tensor([9.6300e-01, 4.0928e-05, 2.4075e-01, 1.2110e-01, 1.1917e-04, 9.6252e-07,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4075e-04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(X_test.shape)\n",
    "    print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.]) tensor([15.6625])\n",
      "tensor([1.]) tensor([16.3378])\n",
      "tensor([2.]) tensor([-20.5837])\n",
      "tensor([1.]) tensor([-20.1050])\n",
      "tensor([1.]) tensor([41.7896])\n",
      "tensor([1.]) tensor([-63.6677])\n",
      "tensor([1.]) tensor([-1501.9828])\n",
      "tensor([370.]) tensor([3192.5928])\n",
      "tensor([1.]) tensor([10.7945])\n",
      "tensor([24.]) tensor([106.6537])\n",
      "tensor([16.]) tensor([-223.8991])\n",
      "tensor([82.]) tensor([332.0003])\n",
      "tensor([2.]) tensor([42.1116])\n",
      "tensor([87.]) tensor([52.5320])\n",
      "tensor([2.]) tensor([-32.9929])\n",
      "tensor([20.]) tensor([2.9611])\n",
      "tensor([1.]) tensor([16.1994])\n",
      "tensor([22.]) tensor([59.5294])\n",
      "tensor([776.]) tensor([-1023.7979])\n",
      "tensor([57.]) tensor([1470.5153])\n",
      "tensor([17.]) tensor([374.5022])\n",
      "tensor([1.]) tensor([-65.7557])\n",
      "tensor([3.]) tensor([-4.2853])\n",
      "tensor([2.]) tensor([-237.0142])\n",
      "tensor([200.]) tensor([546.8312])\n",
      "tensor([12.]) tensor([133.6403])\n",
      "tensor([51.]) tensor([492.7062])\n",
      "tensor([1.]) tensor([2.1632])\n",
      "tensor([1.]) tensor([-22.3209])\n",
      "tensor([1.]) tensor([-27.2620])\n",
      "tensor([8.]) tensor([3.5528])\n",
      "tensor([60.]) tensor([-20.6004])\n",
      "tensor([4.]) tensor([1576.3053])\n",
      "tensor([2.]) tensor([8.0522])\n",
      "tensor([79.]) tensor([314.7570])\n",
      "tensor([1.]) tensor([182.2944])\n",
      "tensor([1.]) tensor([16.1344])\n",
      "tensor([2.]) tensor([-27.1799])\n",
      "tensor([3.]) tensor([9.4394])\n",
      "tensor([5.]) tensor([4.5463])\n",
      "tensor([3.]) tensor([5.7761])\n",
      "tensor([3239.]) tensor([311.4880])\n",
      "tensor([1.]) tensor([-33.9347])\n",
      "tensor([107.]) tensor([3907.3044])\n",
      "tensor([1.]) tensor([170.7180])\n",
      "tensor([14.]) tensor([120.1880])\n",
      "tensor([1.]) tensor([-705.0865])\n",
      "tensor([3.]) tensor([-23.3648])\n",
      "tensor([1.]) tensor([12.3649])\n",
      "tensor([448.]) tensor([234.1823])\n",
      "tensor([2.]) tensor([-6.7730])\n",
      "tensor([94.]) tensor([381.3811])\n",
      "tensor([3.]) tensor([-24.3853])\n",
      "tensor([1.]) tensor([225.2649])\n",
      "tensor([54.]) tensor([769.4473])\n",
      "tensor([1.]) tensor([11.9755])\n",
      "tensor([1.]) tensor([314.6320])\n",
      "tensor([10.]) tensor([181.6477])\n",
      "tensor([1.]) tensor([-371.4955])\n",
      "tensor([1.]) tensor([-81.1165])\n",
      "tensor([4.]) tensor([58.8937])\n",
      "tensor([5.]) tensor([54.6720])\n",
      "tensor([4.]) tensor([131.2336])\n",
      "tensor([4.]) tensor([42.7626])\n",
      "tensor([1.]) tensor([-2.0326])\n",
      "tensor([1.]) tensor([182.2944])\n",
      "tensor([14.]) tensor([-459.4447])\n",
      "tensor([1.]) tensor([-3.3786])\n",
      "tensor([1.]) tensor([-3.5334])\n",
      "tensor([1.]) tensor([-536.9891])\n",
      "tensor([4.]) tensor([30.2231])\n",
      "tensor([8.]) tensor([161.5856])\n",
      "tensor([6.]) tensor([-56.8027])\n",
      "tensor([4.]) tensor([-24.7176])\n",
      "tensor([9.]) tensor([-315.8407])\n",
      "tensor([4.]) tensor([38.9837])\n",
      "tensor([1.]) tensor([41.0000])\n",
      "tensor([352.]) tensor([769.0019])\n",
      "tensor([1344.]) tensor([546.8886])\n",
      "tensor([4.]) tensor([114.3088])\n",
      "tensor([1.]) tensor([-422.7183])\n",
      "tensor([3.]) tensor([-40.3426])\n",
      "tensor([3.]) tensor([0.6516])\n",
      "tensor([1593.]) tensor([949.8389])\n",
      "tensor([2.]) tensor([2.1157])\n",
      "tensor([1.]) tensor([8.4457])\n",
      "tensor([7.]) tensor([86.5752])\n",
      "tensor([3.]) tensor([39.7580])\n",
      "tensor([81.]) tensor([2188.5715])\n",
      "tensor([1.]) tensor([191.2952])\n",
      "tensor([27.]) tensor([1531.3414])\n",
      "tensor([1.]) tensor([37.3153])\n",
      "tensor([1.]) tensor([47.8180])\n",
      "tensor([87.]) tensor([165.7063])\n",
      "tensor([4.]) tensor([104.9688])\n",
      "tensor([1.]) tensor([11.0569])\n",
      "tensor([15.]) tensor([243.0417])\n",
      "tensor([8.]) tensor([-38.5662])\n",
      "tensor([5.]) tensor([-80.6254])\n",
      "tensor([425.]) tensor([260.3926])\n",
      "tensor([1.]) tensor([-157.8710])\n",
      "tensor([2.]) tensor([-2.7365])\n",
      "tensor([252.]) tensor([260.7771])\n",
      "tensor([8.]) tensor([104.4698])\n",
      "tensor([17.]) tensor([30.0339])\n",
      "tensor([3.]) tensor([0.5670])\n",
      "tensor([5.]) tensor([14.4088])\n",
      "tensor([24.]) tensor([-8.2666])\n",
      "tensor([2.]) tensor([-38.3786])\n",
      "tensor([555.]) tensor([-143.2769])\n",
      "tensor([808.]) tensor([369.5029])\n",
      "tensor([12.]) tensor([67.1613])\n",
      "tensor([55.]) tensor([293.7805])\n",
      "tensor([3.]) tensor([-35.5353])\n",
      "tensor([7.]) tensor([85.6844])\n",
      "tensor([1.]) tensor([-73.0713])\n",
      "tensor([1.]) tensor([161.1824])\n",
      "tensor([35.]) tensor([-4.6799])\n",
      "tensor([502.]) tensor([331.0044])\n",
      "tensor([22.]) tensor([40.8586])\n",
      "tensor([91.]) tensor([339.0305])\n",
      "tensor([1.]) tensor([225.6789])\n",
      "tensor([3.]) tensor([-25.0584])\n",
      "tensor([24.]) tensor([12.4667])\n",
      "tensor([1622.]) tensor([1748.7023])\n",
      "tensor([48.]) tensor([365.6216])\n",
      "tensor([24.]) tensor([31.7765])\n",
      "tensor([356.]) tensor([243.3844])\n",
      "tensor([1.]) tensor([-61.7329])\n",
      "tensor([1156.]) tensor([146.7979])\n",
      "tensor([1.]) tensor([4.9102])\n",
      "tensor([2.]) tensor([172.1910])\n",
      "tensor([22.]) tensor([360.6375])\n",
      "tensor([3214.]) tensor([15518.4590])\n",
      "tensor([43.]) tensor([777.1702])\n",
      "tensor([7.]) tensor([119.7837])\n",
      "tensor([3.]) tensor([-46.2919])\n",
      "tensor([5.]) tensor([6.9630])\n",
      "tensor([17.]) tensor([237.9856])\n",
      "tensor([1558.]) tensor([-161.2103])\n",
      "tensor([1.]) tensor([-1.8868])\n",
      "tensor([1.]) tensor([250.1484])\n",
      "tensor([6.]) tensor([1037.6068])\n",
      "tensor([1.]) tensor([619.2975])\n",
      "tensor([1.]) tensor([538.6725])\n",
      "tensor([59.]) tensor([206.5209])\n",
      "tensor([49.]) tensor([512.6494])\n",
      "tensor([1.]) tensor([150.9069])\n",
      "tensor([1.]) tensor([-62.0623])\n",
      "tensor([2.]) tensor([-61.3044])\n",
      "tensor([3.]) tensor([11.1716])\n",
      "tensor([65.]) tensor([66.0006])\n",
      "tensor([2.]) tensor([-15.9141])\n",
      "tensor([1.]) tensor([-4.4212])\n",
      "tensor([3.]) tensor([3.2879])\n",
      "tensor([1.]) tensor([-10.7370])\n",
      "tensor([74.]) tensor([368.7342])\n",
      "tensor([3.]) tensor([-8.6960])\n",
      "tensor([1.]) tensor([-448.3343])\n",
      "tensor([184.]) tensor([2432.0554])\n",
      "tensor([5.]) tensor([-18.1167])\n",
      "tensor([3.]) tensor([105.6031])\n",
      "tensor([7736.]) tensor([883.9858])\n",
      "tensor([2.]) tensor([-10.0013])\n",
      "tensor([6.]) tensor([133.3739])\n",
      "tensor([142.]) tensor([1484.7139])\n",
      "tensor([37.]) tensor([36.9955])\n",
      "tensor([2.]) tensor([-135.2678])\n",
      "tensor([450.]) tensor([266.7564])\n",
      "tensor([5.]) tensor([-11.0098])\n",
      "tensor([1.]) tensor([1428.8927])\n",
      "tensor([1.]) tensor([42.3801])\n",
      "tensor([2.]) tensor([100.0587])\n",
      "tensor([5.]) tensor([-8.5411])\n",
      "tensor([1699.]) tensor([-3208.5476])\n",
      "tensor([2230.]) tensor([363.9810])\n",
      "tensor([238.]) tensor([-2746.3911])\n",
      "tensor([28.]) tensor([351.5890])\n",
      "tensor([17.]) tensor([2155.5061])\n",
      "tensor([2.]) tensor([-6.4614])\n",
      "tensor([2.]) tensor([-42.1006])\n",
      "tensor([5.]) tensor([97.2309])\n",
      "tensor([13.]) tensor([122.6090])\n",
      "tensor([3.]) tensor([-32.2906])\n",
      "tensor([3.]) tensor([-3.0471])\n",
      "tensor([1.]) tensor([0.7575])\n",
      "tensor([4.]) tensor([42.4516])\n",
      "tensor([4.]) tensor([7.7586])\n",
      "tensor([5.]) tensor([68.8856])\n",
      "tensor([1.]) tensor([5.2984])\n",
      "tensor([995.]) tensor([53.0148])\n",
      "tensor([1.]) tensor([9284.5703])\n",
      "tensor([2.]) tensor([-44.4961])\n",
      "tensor([1.]) tensor([-36.0364])\n",
      "tensor([6.]) tensor([-80.8124])\n",
      "tensor([23.]) tensor([-16.5578])\n",
      "tensor([32.]) tensor([652.2855])\n",
      "tensor([7.]) tensor([173.5380])\n",
      "tensor([1.]) tensor([16.9259])\n",
      "tensor([2.]) tensor([6.6223])\n",
      "tensor([23.]) tensor([298.8649])\n",
      "tensor([86.]) tensor([21.9609])\n",
      "tensor([35.]) tensor([3027.9104])\n",
      "tensor([148.]) tensor([242.1413])\n",
      "tensor([2.]) tensor([-131.0722])\n",
      "tensor([233.]) tensor([3164.6741])\n",
      "tensor([52.]) tensor([-109.8558])\n",
      "tensor([7.]) tensor([273.6941])\n",
      "tensor([1.]) tensor([-19.8333])\n",
      "tensor([3.]) tensor([22.1459])\n",
      "tensor([106.]) tensor([420.1389])\n",
      "tensor([4.]) tensor([-31.3780])\n",
      "tensor([2.]) tensor([-36.2987])\n",
      "tensor([1.]) tensor([14.7875])\n",
      "tensor([15.]) tensor([133.0529])\n",
      "tensor([70.]) tensor([169.7964])\n",
      "tensor([3.]) tensor([-8.6674])\n",
      "tensor([5.]) tensor([-17.8955])\n",
      "tensor([27.]) tensor([737.7609])\n",
      "tensor([5.]) tensor([114.7600])\n",
      "tensor([3.]) tensor([7.8817])\n",
      "tensor([2.]) tensor([5.2924])\n",
      "tensor([2.]) tensor([38.1661])\n",
      "tensor([1.]) tensor([0.2140])\n",
      "tensor([23.]) tensor([391.0290])\n",
      "tensor([1.]) tensor([-111.8010])\n",
      "tensor([1.]) tensor([0.6162])\n",
      "tensor([57.]) tensor([126.3847])\n",
      "tensor([127.]) tensor([937.6684])\n",
      "tensor([2.]) tensor([-396.6187])\n",
      "tensor([6.]) tensor([227.7064])\n",
      "tensor([16.]) tensor([91.3225])\n",
      "tensor([7.]) tensor([85.6556])\n",
      "tensor([3.]) tensor([-825.8564])\n",
      "tensor([2.]) tensor([223.8929])\n",
      "tensor([70.]) tensor([1601.7736])\n",
      "tensor([2.]) tensor([-62.9867])\n",
      "tensor([1.]) tensor([16.5962])\n",
      "tensor([31.]) tensor([3739.4973])\n",
      "tensor([2.]) tensor([-27.2064])\n",
      "tensor([5.]) tensor([226.0656])\n",
      "tensor([5.]) tensor([52.0791])\n",
      "tensor([275.]) tensor([372.0247])\n",
      "tensor([26.]) tensor([-1376.6888])\n",
      "tensor([731.]) tensor([824.3298])\n",
      "tensor([257.]) tensor([-115.3972])\n",
      "tensor([2.]) tensor([-39.8720])\n",
      "tensor([4.]) tensor([0.6798])\n",
      "tensor([4.]) tensor([41.3371])\n",
      "tensor([1.]) tensor([15.5271])\n",
      "tensor([14.]) tensor([-95.7567])\n",
      "tensor([4.]) tensor([-49.8042])\n",
      "tensor([124.]) tensor([261.9793])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.]) tensor([45.8637])\n",
      "tensor([1153.]) tensor([876.4673])\n",
      "tensor([36.]) tensor([101.9665])\n",
      "tensor([1.]) tensor([-20.7757])\n",
      "tensor([1.]) tensor([-6.8080])\n",
      "tensor([3.]) tensor([57.5037])\n",
      "tensor([3.]) tensor([-34.7802])\n",
      "tensor([75.]) tensor([171.0341])\n",
      "tensor([2.]) tensor([31.7254])\n",
      "tensor([4.]) tensor([295.1380])\n",
      "tensor([1.]) tensor([-1.9683])\n",
      "tensor([3.]) tensor([-4.5226])\n",
      "tensor([5.]) tensor([6.0291])\n",
      "tensor([415.]) tensor([367.4075])\n",
      "tensor([6.]) tensor([-241.9024])\n",
      "tensor([1.]) tensor([-1083.0909])\n",
      "tensor([1.]) tensor([-65.7557])\n",
      "tensor([19.]) tensor([-18.3977])\n",
      "tensor([6.]) tensor([109.7492])\n",
      "tensor([1.]) tensor([-22.4702])\n",
      "tensor([5.]) tensor([59.4067])\n",
      "tensor([571.]) tensor([2911.5610])\n",
      "tensor([3.]) tensor([8.4643])\n",
      "tensor([2.]) tensor([-16.7671])\n",
      "tensor([17.]) tensor([-88.9515])\n",
      "tensor([1.]) tensor([1531.3873])\n",
      "tensor([2.]) tensor([-1.8566])\n",
      "tensor([100.]) tensor([119.8838])\n",
      "tensor([1.]) tensor([-53.0516])\n",
      "tensor([4.]) tensor([26.2931])\n",
      "tensor([2.]) tensor([7.4293])\n",
      "tensor([5.]) tensor([-34.9738])\n",
      "tensor([15.]) tensor([253.9596])\n",
      "tensor([2.]) tensor([-19.7366])\n",
      "tensor([1.]) tensor([-10.1751])\n",
      "tensor([85.]) tensor([-109.7249])\n",
      "tensor([3.]) tensor([-23.6031])\n",
      "tensor([1.]) tensor([-267.6922])\n",
      "tensor([2.]) tensor([-16.3790])\n",
      "tensor([1.]) tensor([105.3808])\n",
      "tensor([3.]) tensor([36.1254])\n",
      "tensor([1.]) tensor([-378.0842])\n",
      "tensor([1.]) tensor([98.8027])\n",
      "tensor([17.]) tensor([876.8323])\n",
      "tensor([6.]) tensor([97.4033])\n",
      "tensor([7.]) tensor([99.1844])\n",
      "tensor([4.]) tensor([16.6388])\n",
      "tensor([1.]) tensor([11.3449])\n",
      "tensor([3.]) tensor([-7.8901])\n",
      "tensor([3282.]) tensor([705.6148])\n",
      "tensor([5.]) tensor([-18.8710])\n",
      "tensor([2.]) tensor([-33.3073])\n",
      "tensor([88.]) tensor([130.7319])\n",
      "tensor([16.]) tensor([-6.0422])\n",
      "tensor([1.]) tensor([-154.8291])\n",
      "tensor([2.]) tensor([78.6463])\n",
      "tensor([1573.]) tensor([1270.9865])\n",
      "tensor([3.]) tensor([-109.0177])\n",
      "tensor([296.]) tensor([251.0109])\n",
      "tensor([2.]) tensor([31.7438])\n",
      "tensor([5.]) tensor([7.3668])\n",
      "tensor([15.]) tensor([250.9308])\n",
      "tensor([5.]) tensor([57.3158])\n",
      "tensor([998.]) tensor([678.3096])\n",
      "tensor([42.]) tensor([-7914.2637])\n",
      "tensor([1.]) tensor([-347.7796])\n",
      "tensor([6.]) tensor([43.3594])\n",
      "tensor([1.]) tensor([2237.6125])\n",
      "tensor([1.]) tensor([-786.4074])\n",
      "tensor([137.]) tensor([1.8562])\n",
      "tensor([4.]) tensor([17.2812])\n",
      "tensor([29.]) tensor([70.4263])\n",
      "tensor([2.]) tensor([-344.6281])\n",
      "tensor([41.]) tensor([404.9983])\n",
      "tensor([2.]) tensor([-29.8729])\n",
      "tensor([1485.]) tensor([1341.4469])\n",
      "tensor([1058.]) tensor([389.7565])\n",
      "tensor([5.]) tensor([53.7067])\n",
      "tensor([2.]) tensor([-51.5222])\n",
      "tensor([5.]) tensor([98.5193])\n",
      "tensor([3.]) tensor([2.3379])\n",
      "tensor([4.]) tensor([10.9930])\n",
      "tensor([8.]) tensor([-41.8115])\n",
      "tensor([1.]) tensor([7.8164])\n",
      "tensor([2.]) tensor([-224.0685])\n",
      "tensor([3.]) tensor([31.2300])\n",
      "tensor([3.]) tensor([-1.3268])\n",
      "tensor([3.]) tensor([3.4429])\n",
      "tensor([9.]) tensor([-909.5657])\n",
      "tensor([5.]) tensor([94.4045])\n",
      "tensor([617.]) tensor([335.0761])\n",
      "tensor([2.]) tensor([-30.0886])\n",
      "tensor([6.]) tensor([182.3385])\n",
      "tensor([3038.]) tensor([1593.1198])\n",
      "tensor([368.]) tensor([31.1037])\n",
      "tensor([7.]) tensor([209.8383])\n",
      "tensor([2.]) tensor([-245.1769])\n",
      "tensor([81.]) tensor([227.4401])\n",
      "tensor([1.]) tensor([389.9220])\n",
      "tensor([1747.]) tensor([572.0410])\n",
      "tensor([28.]) tensor([123.4237])\n",
      "tensor([3.]) tensor([8.6438])\n",
      "tensor([15.]) tensor([-76.2751])\n",
      "tensor([13.]) tensor([240.1764])\n",
      "tensor([1.]) tensor([-6.6851])\n",
      "tensor([7.]) tensor([141.7001])\n",
      "tensor([47.]) tensor([-1865.7546])\n",
      "tensor([2.]) tensor([-369.0331])\n",
      "tensor([1.]) tensor([-5.5471])\n",
      "tensor([5.]) tensor([36.3089])\n",
      "tensor([32.]) tensor([-1185.8876])\n",
      "tensor([4.]) tensor([17.3907])\n",
      "tensor([3.]) tensor([-42.1887])\n",
      "tensor([6.]) tensor([74.7051])\n",
      "tensor([25.]) tensor([160.5419])\n",
      "tensor([6.]) tensor([-21.1945])\n",
      "tensor([2.]) tensor([194.7352])\n",
      "tensor([1.]) tensor([-11.3988])\n",
      "tensor([30.]) tensor([196.4253])\n",
      "tensor([3.]) tensor([-26.3221])\n",
      "tensor([1.]) tensor([164.6019])\n",
      "tensor([2.]) tensor([-32.3978])\n",
      "tensor([206.]) tensor([-244.3905])\n",
      "tensor([4.]) tensor([-27.7767])\n",
      "tensor([3.]) tensor([7.9076])\n",
      "tensor([7.]) tensor([103.8816])\n",
      "tensor([1.]) tensor([-31.2256])\n",
      "tensor([2.]) tensor([-8.8497])\n",
      "tensor([1.]) tensor([-10.6650])\n",
      "tensor([4.]) tensor([78.3764])\n",
      "tensor([42.]) tensor([203.5632])\n",
      "tensor([401.]) tensor([1003.9982])\n",
      "tensor([1.]) tensor([2.3272])\n",
      "tensor([1.]) tensor([-332.5814])\n",
      "tensor([121.]) tensor([177.8229])\n",
      "tensor([34.]) tensor([241.2770])\n",
      "tensor([1.]) tensor([-78.2531])\n",
      "tensor([3.]) tensor([58.4279])\n",
      "tensor([2.]) tensor([-561.9325])\n",
      "tensor([619.]) tensor([315.9522])\n",
      "tensor([2.]) tensor([-2.2300])\n",
      "tensor([7.]) tensor([167.5930])\n",
      "tensor([3.]) tensor([199.0400])\n",
      "tensor([1.]) tensor([-135.7934])\n",
      "tensor([51.]) tensor([-205.5138])\n",
      "tensor([1.]) tensor([-10.1751])\n",
      "tensor([1.]) tensor([4.9437])\n",
      "tensor([52.]) tensor([-126.1039])\n",
      "tensor([1.]) tensor([-10.1751])\n",
      "tensor([1.]) tensor([-132.0158])\n",
      "tensor([77.]) tensor([332.0512])\n",
      "tensor([5.]) tensor([124.5995])\n",
      "tensor([1.]) tensor([5091.5981])\n",
      "tensor([362.]) tensor([1284.8351])\n",
      "tensor([7.]) tensor([187.5049])\n",
      "tensor([5.]) tensor([7.4038])\n",
      "tensor([2.]) tensor([-830.8302])\n",
      "tensor([31.]) tensor([2061.9939])\n",
      "tensor([4.]) tensor([21.1733])\n",
      "tensor([1.]) tensor([-79.5713])\n",
      "tensor([2.]) tensor([-64.2485])\n",
      "tensor([1.]) tensor([-16.1296])\n",
      "tensor([3.]) tensor([-345.2368])\n",
      "tensor([1.]) tensor([-54.2630])\n",
      "tensor([3.]) tensor([8.8933])\n",
      "tensor([2.]) tensor([38.5955])\n",
      "tensor([1.]) tensor([-46.1634])\n",
      "tensor([111.]) tensor([334.0055])\n",
      "tensor([1.]) tensor([-46.1634])\n",
      "tensor([187.]) tensor([1190.0743])\n",
      "tensor([408.]) tensor([1338.3319])\n",
      "tensor([2028.]) tensor([250.1076])\n",
      "tensor([121.]) tensor([345.1308])\n",
      "tensor([3.]) tensor([8.9808])\n",
      "tensor([4.]) tensor([14.8742])\n",
      "tensor([8.]) tensor([-21.6186])\n",
      "tensor([21.]) tensor([31.5688])\n",
      "tensor([49.]) tensor([4.7160])\n",
      "tensor([1.]) tensor([-371.2704])\n",
      "tensor([25.]) tensor([280.8632])\n",
      "tensor([2.]) tensor([158.3991])\n",
      "tensor([373.]) tensor([1585.8544])\n",
      "tensor([1.]) tensor([-2.4115])\n",
      "tensor([8.]) tensor([-110.7234])\n",
      "tensor([4996.]) tensor([1347.6451])\n",
      "tensor([50.]) tensor([175.8634])\n",
      "tensor([6.]) tensor([36.5135])\n",
      "tensor([4.]) tensor([17.4273])\n",
      "tensor([14.]) tensor([123.0054])\n",
      "tensor([1.]) tensor([-122.6090])\n",
      "tensor([2.]) tensor([4.1629])\n",
      "tensor([5.]) tensor([-49.0542])\n",
      "tensor([82.]) tensor([230.6840])\n",
      "tensor([274.]) tensor([141.4907])\n",
      "tensor([1.]) tensor([-600.9139])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    for i in range(0,outputs.shape[0]):\n",
    "        print(y_test[i],outputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SIEMPRE EVITAR CONSIDERAR LOS GRADIENTES\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        # Debemos hacer nuevamente el reshape OJO\n",
    "        images = images.reshape(-1, 28*28).to(device) #Se envia el GPU si esta disponible...\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value, index\n",
    "        _, predictions = torch.max(outputs, 1) # obtener el max posible valor\n",
    "        n_samples += labels.shape[0] # numero de muestras por lote actual\n",
    "        n_correct += (predictions == labels).sum().item() #ver cuantas acertaron, si acerto suma 1 si no 0\n",
    "    # Medir % precision\n",
    "    acc = 100.0 * n_correct/n_samples\n",
    "    \n",
    "    print(f'accuracy = {acc}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
