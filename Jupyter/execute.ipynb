{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import StandardScaler#para escalar caracteristicas\n",
    "from sklearn.model_selection import train_test_split # separar mas facil la data de train y test\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from ast import literal_eval\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from functions.auxiliares import PaddingSameSize, MatrixFormat_To_Vector, RemoveOversizedMatrix, StandardSize_Padding, CNN_Features_Format, batch_format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Esto garantiza que se ejecutara en GPU si esta disponible\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_r = 40 ## Maximo numero de subconsultas\n",
    "max_c = 50 ## Maximo numero de subcarateristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unique_id', 'filename', 'sparql_file', 'profile', 'limit', 'ql_rt_msec', 'ql_rt_clocks', 'ql_rnd_rows', 'ql_seq_rows', 'ql_same_seg', 'ql_same_page', 'ql_disk_reads', 'ql_spec_disk_reads', 'ql_cl_wait_clocks', 'ql_c_msec', 'ql_c_disk', 'ql_c_clocks', 'ql_cl_messages', 'ql_c_cl_wait', 'matrix_format', 'binary_tree']\n",
      "shape df_raw: (3711, 21)\n",
      "shape df_clean: (2156, 21)\n",
      "Total df_clean:  2156\n",
      "Eliminados por Oversized: 31\n",
      "shape new_df_clean: (2125, 21)\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('D:/.Memoria/Test/Jupyter/test_example.csv')\n",
    "columns = list(df_raw.columns)\n",
    "print(columns)\n",
    "#  Eliminar los con tiempos de ejecución 0 o muy altos\n",
    "df_clean = shuffle(df_raw[(df_raw['ql_rt_msec'] > 0) & (df_raw['ql_rt_msec'] < 1e3)])\n",
    "df_clean.to_csv('D:/.Memoria/Test/Jupyter/test_example_clean.csv',index=False)\n",
    "\n",
    "### HAY QUE CONVERTIR ALGUNAS COLUMNAS Q ESTAN EN PORCENTAJE A FLOAT\n",
    "df_clean['ql_rt_clocks'] = df_clean['ql_rt_clocks'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_same_seg'] = df_clean['ql_same_seg'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_same_page'] = df_clean['ql_same_page'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_cl_wait_clocks'] = df_clean['ql_cl_wait_clocks'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_c_clocks'] = df_clean['ql_c_clocks'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_c_cl_wait'] = df_clean['ql_c_cl_wait'].apply(lambda x: float(x.strip('%'))/100)\n",
    "\n",
    "# Convertir MatrixFormat de STR a np.array\n",
    "df_clean['matrix_format'] = df_clean['matrix_format'].apply(lambda x: np.asarray(literal_eval(x)).astype(np.float32)) \n",
    "\n",
    "## shape de raw y clean\n",
    "print(f'shape df_raw: {df_raw.shape}')\n",
    "print(f'shape df_clean: {df_clean.shape}')\n",
    "\n",
    "\n",
    "new_df_clean,max_new_r,max_new_c,min_new_r,min_new_c,mean_new_r,mean_new_c = RemoveOversizedMatrix(df_clean,max_r,max_c)\n",
    "\n",
    "#num_standard_rows = max_new_r\n",
    "#num_standard_columns = max_new_c\n",
    "num_standard_rows = 20\n",
    "num_standard_columns = 36\n",
    "\n",
    "new_df_clean['matrix_format'] = df_clean['matrix_format'].apply(lambda x: StandardSize_Padding(x,num_standard_rows,num_standard_columns)) \n",
    "\n",
    "print(f'shape new_df_clean: {new_df_clean.shape}')\n",
    "\n",
    "msk = np.random.rand(len(new_df_clean)) <= 0.8\n",
    "df_train = new_df_clean[msk]\n",
    "df_test = new_df_clean[~msk]\n",
    "\n",
    "df_train.to_csv('D:/.Memoria/Test/Jupyter/test_example_clean_train.csv',index=False)\n",
    "df_test.to_csv('D:/.Memoria/Test/Jupyter/test_example_clean_test.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "shape X_numpy_train: (1699, 1)\n",
      "shape X_numpy_test: (426, 1)\n",
      "shape y_numpy_train: (1699,)\n",
      "shape y_numpy_test: (426,)\n",
      "-----------------------\n",
      "shape X_train: torch.Size([1699, 1, 20, 36])\n",
      "shape X_test: torch.Size([426, 1, 20, 36])\n",
      "shape y_train: torch.Size([1699, 1])\n",
      "shape y_test: torch.Size([426, 1])\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'matrix_format'\n",
    "] \n",
    "\n",
    "## FEATURES - TRAIN Y TEST\n",
    "X_df_train = df_train[features]\n",
    "X_df_test = df_test[features]\n",
    "X_numpy_train = X_df_train.to_numpy()\n",
    "X_numpy_test = X_df_test.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "## TARGETS - TRAIN Y TEST\n",
    "y_df_train = df_train['ql_rt_msec']\n",
    "y_df_test = df_test['ql_rt_msec']\n",
    "\n",
    "y_numpy_train = y_df_train.to_numpy().astype(np.float32)\n",
    "y_numpy_test = y_df_test.to_numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "print(\"-----------------------\")\n",
    "print(f'shape X_numpy_train: {X_numpy_train.shape}')\n",
    "print(f'shape X_numpy_test: {X_numpy_test.shape}')\n",
    "print(f'shape y_numpy_train: {y_numpy_train.shape}')\n",
    "print(f'shape y_numpy_test: {y_numpy_test.shape}')\n",
    "print(\"-----------------------\")\n",
    "\n",
    "\n",
    "# Pasarlos a Torch. \n",
    "#X_train = torch.from_numpy(X_numpy_train)\n",
    "#X_test = torch.from_numpy(X_numpy_test)\n",
    "\n",
    "#X_train = torch.tensor(df_train['matrix_format'].values)\n",
    "#X_test = torch.tensor(df_test['matrix_format'].values)\n",
    "\n",
    "\n",
    "X_train = CNN_Features_Format(X_numpy_train)\n",
    "X_test = CNN_Features_Format(X_numpy_test)\n",
    "\n",
    "y_train = torch.from_numpy(y_numpy_train)\n",
    "y_test = torch.from_numpy(y_numpy_test)\n",
    "\n",
    "\n",
    "# También pasar los targets de vector fila a vector columna\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "\n",
    "print(f'shape X_train: {X_train.shape}')\n",
    "print(f'shape X_test: {X_test.shape}')\n",
    "print(f'shape y_train: {y_train.shape}')\n",
    "print(f'shape y_test: {y_test.shape}')\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1, 20, 36])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([99, 1, 20, 36])\n",
      "torch.Size([99, 1])\n",
      "torch.Size([1699, 1, 20, 36])\n",
      "torch.Size([1699, 1])\n"
     ]
    }
   ],
   "source": [
    "#n_samples_train, n_features_train = X_train.shape\n",
    "#n_samples_test, n_features_test = X_test.shape\n",
    "#\n",
    "#hidden_size = 100000\n",
    "#input_size = n_features_train \n",
    "#print(f'n_samples_train: {n_samples_train}')\n",
    "#print(f'n_features_train: {n_features_train}')\n",
    "#print(f'n_samples_test: {n_samples_test}')\n",
    "#print(f'n_features_test: {n_features_test}')\n",
    "#print(f'learning_rate: {learning_rate}')\n",
    "#print(f'hidden_size: {hidden_size}')\n",
    "#print(f'input_size: {input_size}')\n",
    "learning_rate = 0.001\n",
    "batches_size = 100\n",
    "num_epochs = 10000\n",
    "num_batches = math.ceil(X_train.shape[0]/batches_size)\n",
    "batches = batch_format(X_train,y_train,batches_size)\n",
    "for i in range(num_batches):\n",
    "    print(batches[\"features\"][i].shape)\n",
    "    print(batches[\"labels\"][i].shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # SE DEFINEN LAS CAPAS A UTILIZAR, TANTO LAS CNN, FCL-ANN CY LAS DE POOLING\n",
    "        self.conv1 = nn.Conv2d(1, 6, (3,5),stride=(1,1)) \n",
    "        self.pool = nn.MaxPool2d((2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(6, 12, (3,5),stride=(1,1)) \n",
    "        self.fc1 = nn.Linear(12*3*6, 162)\n",
    "        self.fc2 = nn.Linear(162, 84)\n",
    "        self.fc3 = nn.Linear(84, 42)\n",
    "        self.fc4 = nn.Linear(42, 20)\n",
    "        self.fc5 = nn.Linear(20, 1)\n",
    "        \n",
    "        #Se pueden agregar mas capas o mas neurones, cambiar tamaños etc.. pero siempre debo terminar con\n",
    "        # una salida del tamaño que busco\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"input \",x.shape)\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=0.01, inplace=False)\n",
    "        #print(\"conv1 \",x.shape)\n",
    "        x = self.pool(x)\n",
    "        #print(\"pooling \",x.shape)\n",
    "        \n",
    "        \n",
    "        #print(\"input \",x.shape)\n",
    "        x = F.leaky_relu(self.conv2(x), negative_slope=0.01, inplace=False)\n",
    "        #print(\"conv2 \",x.shape)\n",
    "        x = self.pool(x)\n",
    "        #print(\"pooling2 \",x.shape)\n",
    "        \n",
    "        \n",
    "        x = x.view(-1,12*3*6)           \n",
    "        #print(\"view: \",x.shape)\n",
    "        x = F.leaky_relu(self.fc1(x), negative_slope=0.01, inplace=False)\n",
    "        #print(\"fc1: \",x.shape)\n",
    "        x = F.leaky_relu(self.fc2(x), negative_slope=0.01, inplace=False)\n",
    "        #print(\"fc2: \",x.shape)\n",
    "        x = F.leaky_relu(self.fc3(x), negative_slope=0.01, inplace=False)\n",
    "        #print(\"fc3: \",x.shape)\n",
    "        x = F.leaky_relu(self.fc4(x), negative_slope=0.01, inplace=False)\n",
    "        #print(\"fc4: \",x.shape)\n",
    "        x =self.fc5(x)\n",
    "        #print(\"fc5: \",x.shape)\n",
    "        #print(\"---------------------------------------------------------------\")\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss y Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [100/10000], loss = 1636.033203125\n",
      "epoch: [200/10000], loss = 815.4194946289062\n",
      "epoch: [300/10000], loss = 25.884057998657227\n",
      "epoch: [400/10000], loss = 16.920761108398438\n",
      "epoch: [500/10000], loss = 25928.912109375\n",
      "epoch: [600/10000], loss = 22183.037109375\n",
      "epoch: [700/10000], loss = 9931.1708984375\n",
      "epoch: [800/10000], loss = 3121.679931640625\n",
      "epoch: [900/10000], loss = 340.4971618652344\n",
      "epoch: [1000/10000], loss = 63.6439208984375\n",
      "epoch: [1100/10000], loss = 950.1453857421875\n",
      "epoch: [1200/10000], loss = 832.1869506835938\n",
      "epoch: [1300/10000], loss = 804.499267578125\n",
      "epoch: [1400/10000], loss = 779.28955078125\n",
      "epoch: [1500/10000], loss = 712.470458984375\n",
      "epoch: [1600/10000], loss = 16605.091796875\n",
      "epoch: [1700/10000], loss = 12500.5859375\n",
      "epoch: [1800/10000], loss = 1037.5615234375\n",
      "epoch: [1900/10000], loss = 651.7359008789062\n",
      "epoch: [2000/10000], loss = 319.89947509765625\n",
      "epoch: [2100/10000], loss = 288.06719970703125\n",
      "epoch: [2200/10000], loss = 282.5764465332031\n",
      "epoch: [2300/10000], loss = 69.55784606933594\n",
      "epoch: [2400/10000], loss = 1810.433349609375\n",
      "epoch: [2500/10000], loss = 834.7848510742188\n",
      "epoch: [2600/10000], loss = 102.2597885131836\n",
      "epoch: [2700/10000], loss = 78.30967712402344\n",
      "epoch: [2800/10000], loss = 60.37690734863281\n",
      "epoch: [2900/10000], loss = 538.12841796875\n",
      "epoch: [3000/10000], loss = 46.221683502197266\n",
      "epoch: [3100/10000], loss = 56.12510299682617\n",
      "epoch: [3200/10000], loss = 24.71175193786621\n",
      "epoch: [3300/10000], loss = 22.1932315826416\n",
      "epoch: [3400/10000], loss = 29.79875373840332\n",
      "epoch: [3500/10000], loss = 21.529706954956055\n",
      "epoch: [3600/10000], loss = 21.413454055786133\n",
      "epoch: [3700/10000], loss = 47.82775115966797\n",
      "epoch: [3800/10000], loss = 21.93659019470215\n",
      "epoch: [3900/10000], loss = 36.32461929321289\n",
      "epoch: [4000/10000], loss = 21.472869873046875\n",
      "epoch: [4100/10000], loss = 21.440919876098633\n",
      "epoch: [4200/10000], loss = 21.421016693115234\n",
      "epoch: [4300/10000], loss = 21.43231201171875\n",
      "epoch: [4400/10000], loss = 21.366159439086914\n",
      "epoch: [4500/10000], loss = 21.039257049560547\n",
      "epoch: [4600/10000], loss = 25.396474838256836\n",
      "epoch: [4700/10000], loss = 19.739412307739258\n",
      "epoch: [4800/10000], loss = 19.05119514465332\n",
      "epoch: [4900/10000], loss = 17.912675857543945\n",
      "epoch: [5000/10000], loss = 17.21312141418457\n",
      "epoch: [5100/10000], loss = 18.582761764526367\n",
      "epoch: [5200/10000], loss = 18.89485740661621\n",
      "epoch: [5300/10000], loss = 106.34249114990234\n",
      "epoch: [5400/10000], loss = 24.65862464904785\n",
      "epoch: [5500/10000], loss = 28.759490966796875\n",
      "epoch: [5600/10000], loss = 15.754251480102539\n",
      "epoch: [5700/10000], loss = 15.574782371520996\n",
      "epoch: [5800/10000], loss = 16.724811553955078\n",
      "epoch: [5900/10000], loss = 15.859968185424805\n",
      "epoch: [6000/10000], loss = 21.48579978942871\n",
      "epoch: [6100/10000], loss = 22.206247329711914\n",
      "epoch: [6200/10000], loss = 21.12137794494629\n",
      "epoch: [6300/10000], loss = 15.625617980957031\n",
      "epoch: [6400/10000], loss = 15.4747314453125\n",
      "epoch: [6500/10000], loss = 15.257411003112793\n",
      "epoch: [6600/10000], loss = 9.53616714477539\n",
      "epoch: [6700/10000], loss = 3.5106115341186523\n",
      "epoch: [6800/10000], loss = 2.78227162361145\n",
      "epoch: [6900/10000], loss = 2.7508132457733154\n",
      "epoch: [7000/10000], loss = 12.17029094696045\n",
      "epoch: [7100/10000], loss = 9.228734016418457\n",
      "epoch: [7200/10000], loss = 13.322331428527832\n",
      "epoch: [7300/10000], loss = 9.179383277893066\n",
      "epoch: [7400/10000], loss = 8.907684326171875\n",
      "epoch: [7500/10000], loss = 9.019862174987793\n",
      "epoch: [7600/10000], loss = 8.941354751586914\n",
      "epoch: [7700/10000], loss = 9.274643898010254\n",
      "epoch: [7800/10000], loss = 8.897425651550293\n",
      "epoch: [7900/10000], loss = 3.0365514755249023\n",
      "epoch: [8000/10000], loss = 2.7960450649261475\n",
      "epoch: [8100/10000], loss = 2.7462356090545654\n",
      "epoch: [8200/10000], loss = 2.682359457015991\n",
      "epoch: [8300/10000], loss = 19.87215805053711\n",
      "epoch: [8400/10000], loss = 8.439704895019531\n",
      "epoch: [8500/10000], loss = 8.377965927124023\n",
      "epoch: [8600/10000], loss = 3.47519850730896\n",
      "epoch: [8700/10000], loss = 4.20180082321167\n",
      "epoch: [8800/10000], loss = 2.968959093093872\n",
      "epoch: [8900/10000], loss = 19.248300552368164\n",
      "epoch: [9000/10000], loss = 13.775172233581543\n",
      "epoch: [9100/10000], loss = 11.835871696472168\n",
      "epoch: [9200/10000], loss = 11.297788619995117\n",
      "epoch: [9300/10000], loss = 12.481184005737305\n",
      "epoch: [9400/10000], loss = 8.884867668151855\n",
      "epoch: [9500/10000], loss = 7.728987216949463\n",
      "epoch: [9600/10000], loss = 7.072338581085205\n",
      "epoch: [9700/10000], loss = 4.855157375335693\n",
      "epoch: [9800/10000], loss = 1078.4036865234375\n",
      "epoch: [9900/10000], loss = 1042.282958984375\n",
      "epoch: [10000/10000], loss = 1078.22412109375\n"
     ]
    }
   ],
   "source": [
    "#print(num_batches)\n",
    "for epoch in range(num_epochs):\n",
    "    for bt in range(num_batches):\n",
    "        #print(batches[\"features\"][bt].shape)\n",
    "        #print(batches[\"labels\"][bt].shape)\n",
    "        y_hat = model(batches[\"features\"][i])\n",
    "        loss = criterion(y_hat,batches[\"labels\"][i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if bt+1 == num_batches and (epoch+1) % 100 == 0:\n",
    "            print(f'epoch: [{epoch+1}/{num_epochs}], loss = {loss.item()}')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([426, 1, 20, 36])\n",
      "torch.Size([426, 1])\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# BASICO\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(batches_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[57.4295],\n",
      "        [31.2158],\n",
      "        [22.5894],\n",
      "        [20.7062],\n",
      "        [ 8.3708]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.],\n",
      "        [4.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [4.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batches_size_test = 5\n",
    "num_batches_test = math.ceil(X_test.shape[0]/batches_size_test)\n",
    "batches_test = batch_format(X_test,y_test,batches_size_test)\n",
    "#for i in range(num_batches_test):\n",
    "#    print(batches_test[\"features\"][i].shape)\n",
    "#    print(batches_test[\"labels\"][i].shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_test.shape)\n",
    "\n",
    "y_pred = model(batches_test[\"features\"][0])\n",
    "y = batches_test[\"labels\"][0]\n",
    "print(y_pred)\n",
    "\n",
    "print(y)\n",
    "\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 57.42951202392578\n",
      "4.0 31.215810775756836\n",
      "1.0 22.589359283447266\n",
      "3.0 20.706201553344727\n",
      "4.0 8.370789527893066\n",
      "2.0 320.5621643066406\n",
      "44.0 92935.34375\n",
      "10.0 22.023801803588867\n",
      "2.0 1.0915131568908691\n",
      "1.0 23.834793090820312\n",
      "33.0 -10.315242767333984\n",
      "2.0 8.28476619720459\n",
      "1.0 1.2791361808776855\n",
      "11.0 82.8336181640625\n",
      "5.0 2.7809224128723145\n",
      "3.0 3.4349470138549805\n",
      "15.0 24.00014305114746\n",
      "1.0 9.619932174682617\n",
      "59.0 38.67776107788086\n",
      "3.0 2.755800247192383\n",
      "1.0 25.013633728027344\n",
      "52.0 53.96715545654297\n",
      "386.0 8.664472579956055\n",
      "263.0 -3.5603909492492676\n",
      "2.0 1.1949982643127441\n",
      "22.0 0.4723701477050781\n",
      "2.0 0.7541012763977051\n",
      "1.0 -12.968559265136719\n",
      "4.0 7.981889247894287\n",
      "6.0 8.063091278076172\n",
      "1.0 456.29461669921875\n",
      "3.0 5.5072503089904785\n",
      "1.0 0.974769115447998\n",
      "1.0 1.0754036903381348\n",
      "1.0 9.772748947143555\n",
      "83.0 31.99833106994629\n",
      "2.0 8.445605278015137\n",
      "2.0 8.399554252624512\n",
      "1.0 0.6466431617736816\n",
      "448.0 -3.7841315269470215\n",
      "3.0 0.9272513389587402\n",
      "3.0 1.0908203125\n",
      "2.0 3.703005313873291\n",
      "22.0 7.273335933685303\n",
      "4.0 18.068944931030273\n",
      "1.0 1.8165526390075684\n",
      "3.0 4.977083206176758\n",
      "17.0 61.42659378051758\n",
      "3.0 3.7020859718322754\n",
      "78.0 4.020705223083496\n",
      "1.0 -1.3618731498718262\n",
      "74.0 13.140342712402344\n",
      "1.0 -26.00156021118164\n",
      "6.0 8578.015625\n",
      "2.0 3.434873104095459\n",
      "3.0 1.0977740287780762\n",
      "26.0 67.19677734375\n",
      "48.0 16.219953536987305\n",
      "1.0 -20.452062606811523\n",
      "8.0 7.783751964569092\n",
      "1.0 -7.475252628326416\n",
      "1.0 2.248722553253174\n",
      "4.0 10.305639266967773\n",
      "514.0 -3.8292040824890137\n",
      "5.0 8.083964347839355\n",
      "4.0 9.153831481933594\n",
      "159.0 -53.31825637817383\n",
      "3.0 7.881316661834717\n",
      "3.0 0.22473478317260742\n",
      "5.0 3.104048252105713\n",
      "49.0 8.50815486907959\n",
      "42.0 4.535861492156982\n",
      "5.0 2.765552043914795\n",
      "44.0 -26.411529541015625\n",
      "4.0 0.16263389587402344\n",
      "4.0 8.534167289733887\n",
      "14.0 7.822751998901367\n",
      "4.0 5.067227840423584\n",
      "2.0 2.7216601371765137\n",
      "1.0 1.2990174293518066\n",
      "57.0 536.6904907226562\n",
      "425.0 997.07275390625\n",
      "6.0 6.048771858215332\n",
      "49.0 8.38247013092041\n",
      "19.0 11.71950912475586\n",
      "4.0 2.8164005279541016\n",
      "1.0 1.4849505424499512\n",
      "783.0 8.076303482055664\n",
      "8.0 -0.4560856819152832\n",
      "62.0 -2.5269827842712402\n",
      "3.0 -0.059551239013671875\n",
      "5.0 4.072868824005127\n",
      "1.0 1.0366020202636719\n",
      "5.0 6.442169666290283\n",
      "4.0 0.26868104934692383\n",
      "18.0 7.243922710418701\n",
      "2.0 8.248160362243652\n",
      "3.0 8.284647941589355\n",
      "2.0 6.7654128074646\n",
      "2.0 8.03964614868164\n",
      "10.0 27.183517456054688\n",
      "1.0 0.41749143600463867\n",
      "54.0 7.837391376495361\n",
      "2.0 1.0706219673156738\n",
      "24.0 7.722067832946777\n",
      "14.0 12.036029815673828\n",
      "28.0 38.92466354370117\n",
      "1.0 2.1590285301208496\n",
      "1.0 0.5269045829772949\n",
      "678.0 -135.5137481689453\n",
      "2.0 8.250510215759277\n",
      "1.0 0.15291738510131836\n",
      "8.0 -0.15734004974365234\n",
      "11.0 114.1297607421875\n",
      "7.0 7.856779098510742\n",
      "415.0 24.119962692260742\n",
      "1.0 23.191118240356445\n",
      "36.0 139.26318359375\n",
      "85.0 26.820173263549805\n",
      "555.0 443.1441345214844\n",
      "2.0 -2.0753140449523926\n",
      "4.0 6.414063453674316\n",
      "1.0 16.799198150634766\n",
      "2.0 8.253255844116211\n",
      "306.0 178.0543670654297\n",
      "80.0 994.1018676757812\n",
      "3.0 1.0881752967834473\n",
      "2.0 1.7283730506896973\n",
      "3.0 0.9320311546325684\n",
      "3.0 3.4417943954467773\n",
      "3.0 8.04059886932373\n",
      "16.0 26.09463882446289\n",
      "3.0 -0.5119194984436035\n",
      "3.0 -0.25588369369506836\n",
      "4.0 2.8169913291931152\n",
      "48.0 5.004622936248779\n",
      "1.0 0.9755053520202637\n",
      "2.0 0.9890570640563965\n",
      "3.0 8.238504409790039\n",
      "295.0 284.4752502441406\n",
      "28.0 4.090327739715576\n",
      "20.0 14.385345458984375\n",
      "32.0 -15.166604995727539\n",
      "6.0 14.55494499206543\n",
      "34.0 46.53535842895508\n",
      "1.0 13.2822265625\n",
      "1.0 58.67512893676758\n",
      "2.0 18.573251724243164\n",
      "1.0 21.577919006347656\n",
      "152.0 8.198211669921875\n",
      "11.0 2.7777762413024902\n",
      "5.0 4.8981122970581055\n",
      "4.0 2.9174399375915527\n",
      "2.0 -71.88951873779297\n",
      "1.0 14.92567253112793\n",
      "598.0 27.662073135375977\n",
      "10.0 12.96731948852539\n",
      "65.0 251.81239318847656\n",
      "5.0 6.554075241088867\n",
      "1.0 0.7664685249328613\n",
      "2.0 4.873998641967773\n",
      "2.0 0.44573974609375\n",
      "2.0 0.13184690475463867\n",
      "4.0 8.287349700927734\n",
      "6.0 0.787783145904541\n",
      "166.0 7.013639450073242\n",
      "94.0 1.8944497108459473\n",
      "1.0 -14.243743896484375\n",
      "4.0 8.266050338745117\n",
      "22.0 8.541458129882812\n",
      "1.0 -11.555187225341797\n",
      "4.0 8.287344932556152\n",
      "28.0 361.5009460449219\n",
      "841.0 71.67088317871094\n",
      "18.0 1.2846264839172363\n",
      "1.0 -1247.12744140625\n",
      "8.0 8.314667701721191\n",
      "5.0 -0.0805058479309082\n",
      "3.0 8.248160362243652\n",
      "4.0 8.291479110717773\n",
      "50.0 57.783695220947266\n",
      "1.0 0.8997912406921387\n",
      "77.0 76.18804931640625\n",
      "1.0 8.903963088989258\n",
      "5.0 -9.992794036865234\n",
      "3.0 1.0526938438415527\n",
      "87.0 26.037452697753906\n",
      "4.0 3.3463220596313477\n",
      "5.0 4.881294250488281\n",
      "13.0 28.367046356201172\n",
      "3.0 8.168432235717773\n",
      "2.0 5.412754058837891\n",
      "156.0 -3.6879096031188965\n",
      "4.0 2.0482640266418457\n",
      "5.0 4.882338047027588\n",
      "137.0 329.7308044433594\n",
      "687.0 8.396474838256836\n",
      "17.0 2.581732749938965\n",
      "287.0 24.863601684570312\n",
      "3.0 3.0923943519592285\n",
      "1.0 2.6971068382263184\n",
      "5.0 0.7955574989318848\n",
      "1.0 -5.534538745880127\n",
      "7.0 2.481740951538086\n",
      "4.0 8.24404239654541\n",
      "1.0 38.120853424072266\n",
      "1.0 3.8073601722717285\n",
      "1.0 1.951673984527588\n",
      "1.0 290.6262512207031\n",
      "3.0 8.248162269592285\n",
      "86.0 6.028852939605713\n",
      "5.0 3.588517665863037\n",
      "1.0 -7.475252628326416\n",
      "49.0 138.5251922607422\n",
      "3.0 0.8385119438171387\n",
      "1.0 -21.2105655670166\n",
      "3.0 1.323002815246582\n",
      "10.0 -12.600177764892578\n",
      "1.0 -6.25577974319458\n",
      "1.0 -9.90182876586914\n",
      "97.0 1416.420654296875\n",
      "1.0 9.952507019042969\n",
      "2.0 0.7358431816101074\n",
      "17.0 7.736206531524658\n",
      "4.0 -0.08647871017456055\n",
      "3.0 2.2900772094726562\n",
      "2.0 8.315933227539062\n",
      "1.0 0.46166372299194336\n",
      "5.0 8.425948143005371\n",
      "19.0 7.267724990844727\n",
      "5.0 -0.08478355407714844\n",
      "1.0 13.146369934082031\n",
      "15.0 26.094324111938477\n",
      "1.0 54.05338668823242\n",
      "1.0 -19.493778228759766\n",
      "4.0 8.37722110748291\n",
      "1.0 2.8511838912963867\n",
      "57.0 -3.545344829559326\n",
      "998.0 7.956878662109375\n",
      "30.0 470.0677185058594\n",
      "211.0 252.47474670410156\n",
      "1.0 0.3704710006713867\n",
      "1.0 7.729349136352539\n",
      "1.0 0.4586653709411621\n",
      "1.0 4.621973991394043\n",
      "557.0 -2.537353992462158\n",
      "15.0 12.625007629394531\n",
      "709.0 9.721269607543945\n",
      "8.0 2.7216601371765137\n",
      "1.0 1.1650824546813965\n",
      "76.0 29.133302688598633\n",
      "51.0 8.119525909423828\n",
      "7.0 4.994599342346191\n",
      "6.0 7.6866679191589355\n",
      "3.0 4.602376461029053\n",
      "19.0 1.387122631072998\n",
      "2.0 -6.35416841506958\n",
      "67.0 95.26445770263672\n",
      "91.0 146.34852600097656\n",
      "4.0 8.283278465270996\n",
      "556.0 -5.558935642242432\n",
      "21.0 8.341930389404297\n",
      "6.0 7.671944618225098\n",
      "3.0 -0.4946560859680176\n",
      "3.0 8.356128692626953\n",
      "3.0 0.26844167709350586\n",
      "1.0 1.1956281661987305\n",
      "5.0 10.566000938415527\n",
      "25.0 7.904571056365967\n",
      "4.0 997.1019287109375\n",
      "53.0 12.644643783569336\n",
      "1.0 14.92567253112793\n",
      "20.0 8.791601181030273\n",
      "52.0 14.787847518920898\n",
      "5.0 4.8805317878723145\n",
      "1.0 0.4537057876586914\n",
      "2.0 8.73719310760498\n",
      "1.0 -16.950946807861328\n",
      "4.0 7.630008220672607\n",
      "1.0 8.337149620056152\n",
      "16.0 7.953153610229492\n",
      "6.0 4.902078151702881\n",
      "1.0 8.29079532623291\n",
      "1.0 22.7302303314209\n",
      "273.0 -3.613914966583252\n",
      "1.0 3.8073601722717285\n",
      "70.0 120.38955688476562\n",
      "51.0 19.187950134277344\n",
      "1.0 0.1812419891357422\n",
      "3.0 8.244987487792969\n",
      "10.0 29.588281631469727\n",
      "2.0 0.520453929901123\n",
      "2.0 8.276063919067383\n",
      "511.0 997.0725708007812\n",
      "39.0 9.692426681518555\n",
      "3.0 3.5573668479919434\n",
      "4.0 8.196020126342773\n",
      "1.0 3.366955280303955\n",
      "862.0 -4.095205783843994\n",
      "1.0 8.285076141357422\n",
      "15.0 29.814189910888672\n",
      "30.0 4.630690574645996\n",
      "2.0 13.68886947631836\n",
      "42.0 -16.92839241027832\n",
      "4.0 8.430047988891602\n",
      "4.0 0.07472419738769531\n",
      "9.0 12.035600662231445\n",
      "7.0 2.512244701385498\n",
      "1.0 -8.691993713378906\n",
      "1.0 46.52236557006836\n",
      "4.0 5.984975814819336\n",
      "3.0 1.0360379219055176\n",
      "1.0 0.867363452911377\n",
      "2.0 265.7756042480469\n",
      "3.0 -0.5349087715148926\n",
      "2.0 8.283172607421875\n",
      "12.0 11.222648620605469\n",
      "14.0 128.7899169921875\n",
      "408.0 6.379580974578857\n",
      "6.0 -3.452803134918213\n",
      "23.0 114511.5234375\n",
      "5.0 2.830699920654297\n",
      "4.0 6.453153610229492\n",
      "5.0 2.9464240074157715\n",
      "127.0 -3.696465015411377\n",
      "3.0 1.0218157768249512\n",
      "484.0 -2.698211193084717\n",
      "3.0 11.890334129333496\n",
      "4.0 6.457162857055664\n",
      "1.0 -7.475252628326416\n",
      "11.0 11.277633666992188\n",
      "1.0 8.126323699951172\n",
      "52.0 7.457474231719971\n",
      "4.0 6.519608974456787\n",
      "14.0 -6.090939044952393\n",
      "6.0 34.3008918762207\n",
      "462.0 7.507154941558838\n",
      "2.0 0.9642367362976074\n",
      "86.0 28.524036407470703\n",
      "1.0 -168.62623596191406\n",
      "5.0 8.271662712097168\n",
      "4.0 0.6765155792236328\n",
      "1.0 49.659767150878906\n",
      "6.0 4.531802654266357\n",
      "276.0 997.07275390625\n",
      "399.0 22.67816162109375\n",
      "259.0 930.2453002929688\n",
      "6.0 8.102632522583008\n",
      "8.0 8.314681053161621\n",
      "58.0 7.564233303070068\n",
      "2.0 3.9643712043762207\n",
      "11.0 2.7655558586120605\n",
      "4.0 8.302827835083008\n",
      "103.0 29.636404037475586\n",
      "1.0 91.19852447509766\n",
      "3.0 1.4594292640686035\n",
      "2.0 8.3334379196167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0 3.5894341468811035\n",
      "141.0 47.18703079223633\n",
      "2.0 1.0715570449829102\n",
      "7.0 19.195083618164062\n",
      "3.0 8.54167366027832\n",
      "5.0 6.022917747497559\n",
      "4.0 4.864897727966309\n",
      "2.0 0.44577550888061523\n",
      "947.0 210.99253845214844\n",
      "174.0 308.4110107421875\n",
      "1.0 0.4557523727416992\n",
      "2.0 7.735346794128418\n",
      "213.0 8.386078834533691\n",
      "5.0 -0.14954805374145508\n",
      "2.0 4.242612838745117\n",
      "1.0 -7.475252628326416\n",
      "1.0 8.396169662475586\n",
      "277.0 6.808466911315918\n",
      "11.0 7.574275016784668\n",
      "3.0 4.890743732452393\n",
      "1.0 29.133302688598633\n",
      "808.0 -3.696981906890869\n",
      "2.0 7.6142401695251465\n",
      "25.0 16.371665954589844\n",
      "6.0 -5.740767955780029\n",
      "2.0 -20.60934829711914\n",
      "18.0 5.9705810546875\n",
      "3.0 7.9905195236206055\n",
      "4.0 0.7893390655517578\n",
      "457.0 4.083683013916016\n",
      "4.0 8.09863567352295\n",
      "219.0 3.429037570953369\n",
      "2.0 2.6473398208618164\n",
      "16.0 7.60629415512085\n",
      "4.0 8.255711555480957\n",
      "20.0 353.0633239746094\n",
      "16.0 7.057888031005859\n",
      "70.0 0.6502056121826172\n",
      "25.0 6.904642581939697\n",
      "6.0 6.453691005706787\n",
      "47.0 32.26020050048828\n",
      "5.0 -2.04264497756958\n",
      "3.0 1.0618553161621094\n",
      "5.0 0.7905211448669434\n",
      "1.0 0.32761144638061523\n",
      "1.0 -0.0594019889831543\n",
      "1.0 1.1585407257080078\n",
      "3.0 1.0195121765136719\n",
      "2.0 8.280167579650879\n",
      "810.0 17.676111221313477\n",
      "1.0 8.42933464050293\n",
      "1.0 30.798994064331055\n",
      "1.0 0.6621460914611816\n",
      "7.0 4.906279563903809\n",
      "4.0 1.6067023277282715\n",
      "2.0 0.29169130325317383\n",
      "4.0 252.0946044921875\n",
      "1.0 0.794135570526123\n",
      "1.0 -0.9092669486999512\n",
      "2.0 8.28943157196045\n",
      "21.0 7.7096405029296875\n",
      "3.0 -5.435312747955322\n",
      "40.0 373.8445129394531\n",
      "2.0 5.026870250701904\n",
      "4.0 2.291666030883789\n",
      "1.0 3.1014723777770996\n",
      "124.0 2.4677891731262207\n",
      "242.0 -3.73875093460083\n",
      "84.0 28.465465545654297\n",
      "achuntes: [361/426.0]\n",
      "accuracy: 84.74178403755869\n"
     ]
    }
   ],
   "source": [
    "tol = 100 # milisegundos de tolerancia\n",
    "num_aciertos = 0\n",
    "num_test = float(y_test.shape[0])\n",
    "with torch.no_grad():\n",
    "    for bt in range(num_batches_test):\n",
    "        #print(batches[\"features\"][bt].shape)\n",
    "        #print(batches[\"labels\"][bt].shape)\n",
    "        y_pred_tensor = model(batches_test[\"features\"][bt])\n",
    "        y_tensor = batches_test[\"labels\"][bt]\n",
    "        for i in range(y_tensor.shape[0]):\n",
    "            y_pred = y_pred_tensor[i].item()\n",
    "            y = y_tensor[i].item()\n",
    "            print(y, y_pred)\n",
    "            if abs(y_pred-y) < tol:\n",
    "                num_aciertos += 1 \n",
    "            \n",
    "    accuracy = num_aciertos/num_test\n",
    "\n",
    "print(f'achuntes: [{num_aciertos}/{num_test}]')\n",
    "print(f'accuracy: {accuracy*100}')\n",
    "      \n",
    "      \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
