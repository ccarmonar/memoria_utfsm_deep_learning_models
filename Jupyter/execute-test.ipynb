{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import StandardScaler#para escalar caracteristicas\n",
    "from sklearn.model_selection import train_test_split # separar mas facil la data de train y test\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from ast import literal_eval\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from scipy.signal import convolve2d\n",
    "from functions.auxiliares import PaddingSameSize, MatrixFormat_To_Vector, RemoveOversizedMatrix, StandardSize_Padding, CNN_Features_Format, batch_format, KernelSize, StandardSize_InitialConvolution, StandardSize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Esto garantiza que se ejecutara en GPU si esta disponible\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_r = 40 ## Maximo numero de subconsultas\n",
    "max_c = 50 ## Maximo numero de subcarateristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('D:/.Memoria/Test/Jupyter/test_example.csv')\n",
    "columns = list(df_raw.columns)\n",
    "print(columns)\n",
    "#  Eliminar los con tiempos de ejecución 0 o muy altos\n",
    "df_clean = shuffle(df_raw[(df_raw['ql_rt_msec'] > 0) & (df_raw['ql_rt_msec'] < 1e3)])\n",
    "df_clean.to_csv('D:/.Memoria/Test/Jupyter/test_example_clean.csv',index=False)\n",
    "\n",
    "### HAY QUE CONVERTIR ALGUNAS COLUMNAS Q ESTAN EN PORCENTAJE A FLOAT\n",
    "df_clean['ql_rt_clocks'] = df_clean['ql_rt_clocks'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_same_seg'] = df_clean['ql_same_seg'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_same_page'] = df_clean['ql_same_page'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_cl_wait_clocks'] = df_clean['ql_cl_wait_clocks'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_c_clocks'] = df_clean['ql_c_clocks'].apply(lambda x: float(x.strip('%'))/100)\n",
    "df_clean['ql_c_cl_wait'] = df_clean['ql_c_cl_wait'].apply(lambda x: float(x.strip('%'))/100)\n",
    "\n",
    "# Convertir MatrixFormat de STR a np.array\n",
    "df_clean['matrix_format'] = df_clean['matrix_format'].apply(lambda x: np.asarray(literal_eval(x)).astype(np.float32)) \n",
    "\n",
    "## shape de raw y clean\n",
    "print(f'shape df_raw: {df_raw.shape}')\n",
    "print(f'shape df_clean: {df_clean.shape}')\n",
    "\n",
    "\n",
    "new_df_clean,max_new_r,max_new_c,min_new_r,min_new_c,mean_new_r,mean_new_c = RemoveOversizedMatrix(df_clean,max_r,max_c)\n",
    "\n",
    "#num_standard_rows = max_new_r\n",
    "#num_standard_columns = max_new_c\n",
    "num_standard_rows = 20\n",
    "num_standard_columns = 36\n",
    "\n",
    "new_df_clean['matrix_format'] = df_clean['matrix_format'].apply(lambda x: StandardSize_Padding(x,num_standard_rows,num_standard_columns)) \n",
    "\n",
    "print(f'shape new_df_clean: {new_df_clean.shape}')\n",
    "\n",
    "msk = np.random.rand(len(new_df_clean)) <= 0.8\n",
    "df_train = new_df_clean[msk]\n",
    "df_test = new_df_clean[~msk]\n",
    "\n",
    "df_train.to_csv('D:/.Memoria/Test/Jupyter/test_example_clean_train.csv',index=False)\n",
    "df_test.to_csv('D:/.Memoria/Test/Jupyter/test_example_clean_test.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'matrix_format'\n",
    "] \n",
    "\n",
    "## FEATURES - TRAIN Y TEST\n",
    "X_df_train = df_train[features]\n",
    "X_df_test = df_test[features]\n",
    "X_numpy_train = X_df_train.to_numpy()\n",
    "X_numpy_test = X_df_test.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "## TARGETS - TRAIN Y TEST\n",
    "y_df_train = df_train['ql_rt_msec']\n",
    "y_df_test = df_test['ql_rt_msec']\n",
    "\n",
    "y_numpy_train = y_df_train.to_numpy().astype(np.float32)\n",
    "y_numpy_test = y_df_test.to_numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "print(\"-----------------------\")\n",
    "print(f'shape X_numpy_train: {X_numpy_train.shape}')\n",
    "print(f'shape X_numpy_test: {X_numpy_test.shape}')\n",
    "print(f'shape y_numpy_train: {y_numpy_train.shape}')\n",
    "print(f'shape y_numpy_test: {y_numpy_test.shape}')\n",
    "print(\"-----------------------\")\n",
    "\n",
    "\n",
    "# Pasarlos a Torch. \n",
    "#X_train = torch.from_numpy(X_numpy_train)\n",
    "#X_test = torch.from_numpy(X_numpy_test)\n",
    "\n",
    "#X_train = torch.tensor(df_train['matrix_format'].values)\n",
    "#X_test = torch.tensor(df_test['matrix_format'].values)\n",
    "\n",
    "\n",
    "X_train = CNN_Features_Format(X_numpy_train)\n",
    "X_test = CNN_Features_Format(X_numpy_test)\n",
    "\n",
    "y_train = torch.from_numpy(y_numpy_train)\n",
    "y_test = torch.from_numpy(y_numpy_test)\n",
    "\n",
    "\n",
    "# También pasar los targets de vector fila a vector columna\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "\n",
    "print(f'shape X_train: {X_train.shape}')\n",
    "print(f'shape X_test: {X_test.shape}')\n",
    "print(f'shape y_train: {y_train.shape}')\n",
    "print(f'shape y_test: {y_test.shape}')\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_samples_train, n_features_train = X_train.shape\n",
    "#n_samples_test, n_features_test = X_test.shape\n",
    "#\n",
    "#hidden_size = 100000\n",
    "#input_size = n_features_train \n",
    "#print(f'n_samples_train: {n_samples_train}')\n",
    "#print(f'n_features_train: {n_features_train}')\n",
    "#print(f'n_samples_test: {n_samples_test}')\n",
    "#print(f'n_features_test: {n_features_test}')\n",
    "#print(f'learning_rate: {learning_rate}')\n",
    "#print(f'hidden_size: {hidden_size}')\n",
    "#print(f'input_size: {input_size}')\n",
    "learning_rate = 0.001\n",
    "batches_size = 100\n",
    "num_epochs = 10000\n",
    "num_batches = math.ceil(X_train.shape[0]/batches_size)\n",
    "batches = batch_format(X_train,y_train,batches_size)\n",
    "for i in range(num_batches):\n",
    "    print(batches[\"features\"][i].shape)\n",
    "    print(batches[\"labels\"][i].shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # SE DEFINEN LAS CAPAS A UTILIZAR, TANTO LAS CNN, FCL-ANN CY LAS DE POOLING\n",
    "        self.conv1 = nn.Conv2d(1, 6, (3,5),stride=(1,1)) \n",
    "        self.pool = nn.MaxPool2d((2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(6, 12, (3,5),stride=(1,1)) \n",
    "        self.fc1 = nn.Linear(12*3*6, 162)\n",
    "        self.fc2 = nn.Linear(162, 84)\n",
    "        self.fc3 = nn.Linear(84, 42)\n",
    "        self.fc4 = nn.Linear(42, 20)\n",
    "        self.fc5 = nn.Linear(20, 1)\n",
    "        \n",
    "        #Se pueden agregar mas capas o mas neurones, cambiar tamaños etc.. pero siempre debo terminar con\n",
    "        # una salida del tamaño que busco\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"input \",x.shape)\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=0.01, inplace=False)\n",
    "        #print(\"conv1 \",x.shape)\n",
    "        x = self.pool(x)\n",
    "        #print(\"pooling \",x.shape)\n",
    "        \n",
    "        \n",
    "        #print(\"input \",x.shape)\n",
    "        x = F.leaky_relu(self.conv2(x), negative_slope=0.01, inplace=False)\n",
    "        #print(\"conv2 \",x.shape)\n",
    "        x = self.pool(x)\n",
    "        #print(\"pooling2 \",x.shape)\n",
    "        \n",
    "        \n",
    "        x = x.view(-1,12*3*6)           \n",
    "        #print(\"view: \",x.shape)\n",
    "        x = F.leaky_relu(self.fc1(x), negative_slope=0.01, inplace=False)\n",
    "        #print(\"fc1: \",x.shape)\n",
    "        x = F.leaky_relu(self.fc2(x), negative_slope=0.01, inplace=False)\n",
    "        #print(\"fc2: \",x.shape)\n",
    "        x = F.leaky_relu(self.fc3(x), negative_slope=0.01, inplace=False)\n",
    "        #print(\"fc3: \",x.shape)\n",
    "        x = F.leaky_relu(self.fc4(x), negative_slope=0.01, inplace=False)\n",
    "        #print(\"fc4: \",x.shape)\n",
    "        x =self.fc5(x)\n",
    "        #print(\"fc5: \",x.shape)\n",
    "        #print(\"---------------------------------------------------------------\")\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss y Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(num_batches)\n",
    "for epoch in range(num_epochs):\n",
    "    for bt in range(num_batches):\n",
    "        #print(batches[\"features\"][bt].shape)\n",
    "        #print(batches[\"labels\"][bt].shape)\n",
    "        y_hat = model(batches[\"features\"][i])\n",
    "        loss = criterion(y_hat,batches[\"labels\"][i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if bt+1 == num_batches and (epoch+1) % 100 == 0:\n",
    "            print(f'epoch: [{epoch+1}/{num_epochs}], loss = {loss.item()}')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASICO\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(batches_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batches_size_test = 5\n",
    "num_batches_test = math.ceil(X_test.shape[0]/batches_size_test)\n",
    "batches_test = batch_format(X_test,y_test,batches_size_test)\n",
    "#for i in range(num_batches_test):\n",
    "#    print(batches_test[\"features\"][i].shape)\n",
    "#    print(batches_test[\"labels\"][i].shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_test.shape)\n",
    "\n",
    "y_pred = model(batches_test[\"features\"][0])\n",
    "y = batches_test[\"labels\"][0]\n",
    "print(y_pred)\n",
    "\n",
    "print(y)\n",
    "\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 100 # milisegundos de tolerancia\n",
    "num_aciertos = 0\n",
    "num_test = float(y_test.shape[0])\n",
    "with torch.no_grad():\n",
    "    for bt in range(num_batches_test):\n",
    "        #print(batches[\"features\"][bt].shape)\n",
    "        #print(batches[\"labels\"][bt].shape)\n",
    "        y_pred_tensor = model(batches_test[\"features\"][bt])\n",
    "        y_tensor = batches_test[\"labels\"][bt]\n",
    "        for i in range(y_tensor.shape[0]):\n",
    "            y_pred = y_pred_tensor[i].item()\n",
    "            y = y_tensor[i].item()\n",
    "            print(y, y_pred)\n",
    "            if abs(y_pred-y) < tol:\n",
    "                num_aciertos += 1 \n",
    "            \n",
    "    accuracy = num_aciertos/num_test\n",
    "\n",
    "print(f'achuntes: [{num_aciertos}/{num_test}]')\n",
    "print(f'accuracy: {accuracy*100}')\n",
    "      \n",
    "      \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
